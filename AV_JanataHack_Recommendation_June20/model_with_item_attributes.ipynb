{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, joblib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "LOCAL_DIR = '/Users/varunn/Documents/'\n",
    "DATA_DIR = os.path.join(LOCAL_DIR, 'AV_Data')\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "INTERIM_DIR = os.path.join(DATA_DIR, 'interim')\n",
    "CHALLENGE_DATA_FN = os.path.join(TRAIN_DIR, 'challenge_data.csv')\n",
    "TRAIN_DATA_FN = os.path.join(TRAIN_DIR, 'train.csv')\n",
    "TEST_DATA_FN = os.path.join(DATA_DIR, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data used for training baseline_model\n",
    "dev_fn = os.path.join(INTERIM_DIR, 'baseline_dev_df.csv')\n",
    "val_fn = os.path.join(INTERIM_DIR, 'baseline_val_df.csv')\n",
    "val_actual_items_dct_fn = os.path.join(INTERIM_DIR,\n",
    "                                       'val_actual_items_dct.json')\n",
    "seen_items_dct_fn = os.path.join(INTERIM_DIR, 'seen_items_dct.json')\n",
    "seen_items_dct_all_fn = os.path.join(INTERIM_DIR,\n",
    "                                     'seen_items_dct_all.json')\n",
    "dev_df = pd.read_csv(dev_fn)\n",
    "val_df = pd.read_csv(val_fn)\n",
    "val_actual_items_dct = json.load(open(val_actual_items_dct_fn))\n",
    "seen_items_dct = json.load(open(seen_items_dct_fn))\n",
    "seen_items_dct_all = json.load(open(seen_items_dct_all_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ids to int in dicts\n",
    "val_actual_items_dct = {int(idx): val for idx, val in\n",
    "                        val_actual_items_dct.items()}\n",
    "seen_items_dct_all = {int(idx): val for idx, val in\n",
    "                      seen_items_dct_all.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create item_attr_dct for adding the item features to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# read mapping dcts\n",
    "cat_cols = ['user_id', 'challenge_sequence', 'challenge',\n",
    "            'programming_language', 'challenge_series_ID',\n",
    "            'author_ID', 'author_gender', 'author_org_ID',\n",
    "            'category_id']\n",
    "d = {}\n",
    "for col in cat_cols:\n",
    "    inp_fn = os.path.join(INTERIM_DIR, '{}2idx.json'.format(col))\n",
    "    d[col] = json.load(open(inp_fn))\n",
    "\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>challenge_ID</th>\n",
       "      <th>programming_language</th>\n",
       "      <th>challenge_series_ID</th>\n",
       "      <th>total_submissions</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>author_ID</th>\n",
       "      <th>author_gender</th>\n",
       "      <th>author_org_ID</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CI23478</td>\n",
       "      <td>2</td>\n",
       "      <td>SI2445</td>\n",
       "      <td>37.0</td>\n",
       "      <td>06-05-2006</td>\n",
       "      <td>AI563576</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CI23479</td>\n",
       "      <td>2</td>\n",
       "      <td>SI2435</td>\n",
       "      <td>48.0</td>\n",
       "      <td>17-10-2002</td>\n",
       "      <td>AI563577</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100002</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CI23480</td>\n",
       "      <td>1</td>\n",
       "      <td>SI2435</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16-10-2002</td>\n",
       "      <td>AI563578</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CI23481</td>\n",
       "      <td>1</td>\n",
       "      <td>SI2710</td>\n",
       "      <td>236.0</td>\n",
       "      <td>19-09-2003</td>\n",
       "      <td>AI563579</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100004</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CI23482</td>\n",
       "      <td>2</td>\n",
       "      <td>SI2440</td>\n",
       "      <td>137.0</td>\n",
       "      <td>21-03-2002</td>\n",
       "      <td>AI563580</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  challenge_ID  programming_language challenge_series_ID  total_submissions  \\\n",
       "0      CI23478                     2              SI2445               37.0   \n",
       "1      CI23479                     2              SI2435               48.0   \n",
       "2      CI23480                     1              SI2435               15.0   \n",
       "3      CI23481                     1              SI2710              236.0   \n",
       "4      CI23482                     2              SI2440              137.0   \n",
       "\n",
       "  publish_date author_ID author_gender author_org_ID  category_id  \n",
       "0   06-05-2006  AI563576             M     AOI100001          NaN  \n",
       "1   17-10-2002  AI563577             M     AOI100002         32.0  \n",
       "2   16-10-2002  AI563578             M     AOI100003          NaN  \n",
       "3   19-09-2003  AI563579             M     AOI100004         70.0  \n",
       "4   21-03-2002  AI563580             M     AOI100005          NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read challenge data\n",
    "challenge_data_fn = os.path.join(TRAIN_DIR, 'challenge_data.csv')\n",
    "df_challenge = pd.read_csv(challenge_data_fn)\n",
    "df_challenge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_challenge.rename(columns={'challenge_ID': 'challenge'}, inplace=True)\n",
    "df_challenge.fillna(value={'challenge_series_ID': 'missing',\n",
    "                           'author_ID': 'missing',\n",
    "                           'author_gender': 'missing',\n",
    "                           'author_org_ID': 'missing'}, inplace=True)\n",
    "df_challenge.fillna(value={\n",
    "    'total_submissions': 0, 'programming_language': 0,\n",
    "    'category_id': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "challenge\n",
      "programming_language\n",
      "challenge_series_ID\n",
      "author_ID\n",
      "author_gender\n",
      "author_org_ID\n",
      "category_id\n"
     ]
    }
   ],
   "source": [
    "# mapping values to ids\n",
    "cols = [x for x in list(df_challenge.columns) if x not in\n",
    "        ('publish_date', 'total_submissions')]\n",
    "\n",
    "for col in cols:\n",
    "    print(col)\n",
    "    df_challenge[col] = df_challenge[col].apply(lambda x: d[col][str(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5606"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# item_attr_dct\n",
    "ordered_cols = ['programming_language', 'challenge_series_ID',\n",
    "                'author_ID', 'author_gender', 'author_org_ID',\n",
    "                'category_id', 'total_submissions']\n",
    "df_challenge['attr_lst'] = df_challenge[ordered_cols].apply(\n",
    "    lambda x: list(x), axis=1)\n",
    "\n",
    "item_attr_dct = dict(zip(df_challenge['challenge'],\n",
    "                         df_challenge['attr_lst']))\n",
    "len(item_attr_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "out_fn = os.path.join(INTERIM_DIR, 'item_attr_dct.json')\n",
    "json.dump(item_attr_dct, open(out_fn, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation for MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping challenge_sequence to id\n",
    "dev_df['challenge_sequence'] = dev_df['challenge_sequence'].apply(\n",
    "    lambda x: d['challenge_sequence'][str(x)])\n",
    "val_df['challenge_sequence'] = val_df['challenge_sequence'].apply(\n",
    "    lambda x: d['challenge_sequence'][str(x)])\n",
    "\n",
    "# mapping attrs to item id\n",
    "for i, col in enumerate(ordered_cols):\n",
    "    dev_df[col] = dev_df['challenge'].apply(lambda x: item_attr_dct[x][i])\n",
    "    val_df[col] = val_df['challenge'].apply(lambda x: item_attr_dct[x][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "dev_fn = os.path.join(INTERIM_DIR, 'mlp_dev_df.csv')\n",
    "val_fn = os.path.join(INTERIM_DIR, 'mlp_val_df.csv')\n",
    "dev_df.to_csv(dev_fn, index=False)\n",
    "val_df.to_csv(val_fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train    883057\n",
      "test     397320\n",
      "Name: sample, dtype: int64\n",
      "39732\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_sequence</th>\n",
       "      <th>user_id</th>\n",
       "      <th>challenge_sequence</th>\n",
       "      <th>challenge</th>\n",
       "      <th>sample</th>\n",
       "      <th>programming_language</th>\n",
       "      <th>challenge_series_ID</th>\n",
       "      <th>author_ID</th>\n",
       "      <th>author_gender</th>\n",
       "      <th>author_org_ID</th>\n",
       "      <th>category_id</th>\n",
       "      <th>total_submissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4576_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14723.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4576_2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>377</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4576_3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1439</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>43409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4576_4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>185</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8897.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4576_5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>455</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>15086.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_sequence  user_id  challenge_sequence  challenge sample  \\\n",
       "0        4576_1        0                   0        236  train   \n",
       "1        4576_2        0                   1        377  train   \n",
       "2        4576_3        0                   2       1439  train   \n",
       "3        4576_4        0                   3        185  train   \n",
       "4        4576_5        0                   4        455  train   \n",
       "\n",
       "   programming_language  challenge_series_ID  author_ID  author_gender  \\\n",
       "0                   1.0                 39.0      190.0            0.0   \n",
       "1                   1.0                 25.0      247.0            0.0   \n",
       "2                   1.0                111.0     1012.0            2.0   \n",
       "3                   1.0                 27.0      148.0            0.0   \n",
       "4                   1.0                 25.0      207.0            0.0   \n",
       "\n",
       "   author_org_ID  category_id  total_submissions  \n",
       "0          128.0         28.0            14723.0  \n",
       "1            5.0         28.0            20993.0  \n",
       "2          580.0         56.0            43409.0  \n",
       "3           97.0         36.0             8897.0  \n",
       "4          148.0         37.0            15086.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dev_df['sample'].value_counts())\n",
    "print(dev_df[dev_df['sample'] == 'test']['user_id'].nunique())\n",
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "dev_fn = os.path.join(INTERIM_DIR, 'mlp_dev_df.csv')\n",
    "val_fn = os.path.join(INTERIM_DIR, 'mlp_val_df.csv')\n",
    "val_actual_items_dct_fn = os.path.join(INTERIM_DIR,\n",
    "                                       'val_actual_items_dct.json')\n",
    "seen_items_dct_fn = os.path.join(INTERIM_DIR, 'seen_items_dct.json')\n",
    "seen_items_dct_all_fn = os.path.join(INTERIM_DIR,\n",
    "                                     'seen_items_dct_all.json')\n",
    "item_attr_dct_fn = os.path.join(INTERIM_DIR, 'item_attr_dct.json')\n",
    "dev_df = pd.read_csv(dev_fn)\n",
    "val_df = pd.read_csv(val_fn)\n",
    "val_actual_items_dct = json.load(open(val_actual_items_dct_fn))\n",
    "seen_items_dct = json.load(open(seen_items_dct_fn))\n",
    "seen_items_dct_all = json.load(open(seen_items_dct_all_fn))\n",
    "item_attr_dct = json.load(open(item_attr_dct_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ids to int in dicts\n",
    "val_actual_items_dct = {int(idx): val for idx, val in\n",
    "                        val_actual_items_dct.items()}\n",
    "seen_items_dct = {int(idx): val for idx, val in\n",
    "                  seen_items_dct.items()}\n",
    "seen_items_dct_all = {int(idx): val for idx, val in\n",
    "                      seen_items_dct_all.items()}\n",
    "item_attr_dct = {int(idx): val for idx, val in item_attr_dct.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# read mapping dcts\n",
    "cat_cols = ['user_id', 'challenge_sequence', 'challenge',\n",
    "            'programming_language', 'challenge_series_ID',\n",
    "            'author_ID', 'author_gender', 'author_org_ID',\n",
    "            'category_id']\n",
    "d = {}\n",
    "for col in cat_cols:\n",
    "    inp_fn = os.path.join(INTERIM_DIR, '{}2idx.json'.format(col))\n",
    "    d[col] = json.load(open(inp_fn))\n",
    "\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "N_USERS = len(d['user_id'])\n",
    "N_ITEMS = len(d['challenge'])\n",
    "N_CHALLENGES_PER_USER = len(d['challenge_sequence'])\n",
    "USE_ITEM_ATTR = False\n",
    "N_PL = len(d['programming_language'])\n",
    "N_CSI = len(d['challenge_series_ID'])\n",
    "N_AID = len(d['author_ID'])\n",
    "N_AG = len(d['author_gender'])\n",
    "N_AOID = len(d['author_org_ID'])\n",
    "N_CID = len(d['category_id'])\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loader\n",
    "\n",
    "from torchmlp import PairwiseInteractionsMLP\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dev_loader = PairwiseInteractionsMLP(\n",
    "    dev_df, N_ITEMS, N_CHALLENGES_PER_USER, USE_ITEM_ATTR, \n",
    "    seen_items_dct_all, item_attr_dct, seed=1)\n",
    "dev_loader = DataLoader(dev_loader, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_loader = PairwiseInteractionsMLP(\n",
    "    val_df, N_ITEMS, N_CHALLENGES_PER_USER, USE_ITEM_ATTR,\n",
    "    seen_items_dct_all, item_attr_dct, seed=1)\n",
    "val_loader = DataLoader(val_loader, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom itertools import islice\\n\\nfor pos_cat, pos_num, neg_cat, neg_num in islice(dev_loader, 1):\\n    print(pos_cat)\\n    print('\\n')\\n    print(pos_num)\\n    print('\\n')\\n    print(neg_cat)\\n    print('\\n')\\n    print(neg_num)\\n    print('\\n')\\n    user = pos_cat.numpy()[:, 0]\\n    print(user)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from itertools import islice\n",
    "\n",
    "for pos_cat, pos_num, neg_cat, neg_num in islice(dev_loader, 1):\n",
    "    print(pos_cat)\n",
    "    print('\\n')\n",
    "    print(pos_num)\n",
    "    print('\\n')\n",
    "    print(neg_cat)\n",
    "    print('\\n')\n",
    "    print(neg_num)\n",
    "    print('\\n')\n",
    "    user = pos_cat.numpy()[:, 0]\n",
    "    print(user)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network\n",
    "\n",
    "def choose_embedding_size(cat_cols, cat_num_values, min_emb_dim=100):\n",
    "    \"\"\"\n",
    "    cat_cols: list of categorical columns\n",
    "    cat_num_values: list of number of unique values for each categorical column\n",
    "    \"\"\"\n",
    "\n",
    "    embedded_cols = dict(zip(cat_cols, cat_num_values))\n",
    "    print(embedded_cols)\n",
    "    embedding_sizes = [(n_categories,\n",
    "                        min(min_emb_dim, (n_categories+1)//2))\n",
    "                       for _, n_categories in embedded_cols.items()]\n",
    "    return embedding_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': 109264, 'challenge': 5606}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(109264, 50), (5606, 50)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if USE_ITEM_ATTR:\n",
    "    cat_cols = ['user_id', 'challenge', 'programming_language',\n",
    "                'challenge_series_ID', 'author_ID', 'author_gender',\n",
    "                'author_org_ID', 'category_id', 'challenge_sequence']\n",
    "    cat_num_values = [N_USERS, N_ITEMS, N_PL, N_CSI, N_AID, N_AG, N_AOID,\n",
    "                      N_CID, N_CHALLENGES_PER_USER+1]\n",
    "else:\n",
    "    cat_cols = ['user_id', 'challenge']\n",
    "    cat_num_values = [N_USERS, N_ITEMS]\n",
    "embedding_sizes = choose_embedding_size(cat_cols, cat_num_values, 50)\n",
    "embedding_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmlp import BPRModuleMLP\n",
    "model = BPRModuleMLP(embedding_sizes, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPRModuleMLP(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(109264, 50)\n",
       "    (1): Embedding(5606, 50)\n",
       "  )\n",
       "  (lin1): Linear(in_features=101, out_features=1, bias=True)\n",
       "  (bn1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (emb_drop): Dropout(p=0.6, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training class\n",
    "\n",
    "from trainingmlp import StepMLP\n",
    "from torchmf import bpr_loss\n",
    "net = StepMLP(model=model, n_items=N_ITEMS, item_attr_dct=item_attr_dct,\n",
    "              n_challenges_per_user=N_CHALLENGES_PER_USER,\n",
    "              use_item_attr=USE_ITEM_ATTR,\n",
    "              actual_items_dct=val_actual_items_dct,\n",
    "              seen_items_dct=seen_items_dct, loss_function=bpr_loss,\n",
    "              lr=0.03, weight_decay=0.05, batch_size=BATCH_SIZE,\n",
    "              num_predictions=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280377 \t 20859 \t 2560\n"
     ]
    }
   ],
   "source": [
    "train_size, test_size = dev_df.shape[0], val_df.shape[0]\n",
    "print(train_size, '\\t', test_size, '\\t', train_size//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2560 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2561it [1:29:34,  1.96s/it]                          \n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation begins...\n",
      "validation with mapk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [04:17,  5.70s/it]                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'train_loss': tensor([0.0012]), 'val_mapk': 0.00015181296642536395, 'val_loss': tensor(0.0004)}\n",
      "time taken: 93.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "net.batch_fit(train_loader=dev_loader, test_loader=val_loader,\n",
    "              train_size=train_size, test_size=test_size, calc_mapk=True,\n",
    "              epochs=1)\n",
    "print('time taken: %0.2f' % ((time.time() - start)/60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "\n",
    "def recommend(model_class, user, k:int = 10):\n",
    "    \"\"\"Recommends the top-k items to a specific user.\"\"\"\n",
    "    model_class.model.eval()\n",
    "\n",
    "    item_lst = [x for x in range(model_class.n_items) if x not in\n",
    "                model_class.seen_items_dct[user]]\n",
    "    user_value = [user]\n",
    "    cat_values, num_values = [], []\n",
    "    start = time.time()\n",
    "    for i, item in enumerate(item_lst):\n",
    "        item_value = [model_class.item_attr_dct[item][i] for i, col in\n",
    "                      enumerate(model_class.item_cols)]\n",
    "        num_value = [model_class.item_attr_dct[item][6]]\n",
    "        if model_class.use_item_attr:\n",
    "            joint_value = [model_class.n_challenges_per_user]\n",
    "            cat_value = user_value + [item] + item_value + joint_value\n",
    "        else:\n",
    "            cat_value = user_value + [item]\n",
    "        cat_values.append(cat_value)\n",
    "        num_values.append(num_value)\n",
    "\n",
    "    cat_values = tensor(cat_values)\n",
    "    cat_values = cat_values.long()\n",
    "    num_values = tensor(num_values)\n",
    "    num_values = num_values.double()\n",
    "    scores = model_class.model.calc_pred(cat_values, num_values)\n",
    "    scores = torch.sigmoid(scores)\n",
    "    scores = scores.squeeze()\n",
    "    sorted_scores = scores.argsort().tolist()\n",
    "    return sorted_scores[::-1][:k]\n",
    "\n",
    "\n",
    "def recommend_dot(model_class, user, k:int = 10):\n",
    "    \"\"\"Recommends the top-k items to a specific user.\"\"\"\n",
    "    model_class.model.eval()\n",
    "    \n",
    "    u = model_class.model.embeddings[0].weight[user, :]\n",
    "    u = u.reshape((1, u.shape[0]))\n",
    "    x_ui = torch.mm(u, model_class.model.embeddings[1].weight.t())\n",
    "    pred = x_ui.squeeze().argsort().tolist()\n",
    "    items_seen = model_class.seen_items_dct[user]\n",
    "    sorted_pred = [x for x in pred if x not in items_seen]\n",
    "    return sorted_pred[::-1][:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscores, sorted_scores, rec_items = recommend(net, 19, 3)\\nprint(rec_items)\\nscores = scores.detach().numpy()\\nscores.sort()\\nprint(scores[::-1])\\n'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "scores, sorted_scores, rec_items = recommend(net, 19, 3)\n",
    "print(rec_items)\n",
    "scores = scores.detach().numpy()\n",
    "scores.sort()\n",
    "print(scores[::-1])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import mapk\n",
    "\n",
    "\n",
    "def get_mapk(actual_items_dct, recommended_items_dct, k):\n",
    "\n",
    "    actuals, preds = [], []\n",
    "    for user in actual_items_dct:\n",
    "        actual_item_lst = actual_items_dct[user]\n",
    "        pred_item_lst = recommended_items_dct[user]\n",
    "        actuals.append(actual_item_lst)\n",
    "        preds.append(pred_item_lst)\n",
    "\n",
    "    return mapk(actuals, preds, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num completed:  0\n",
      "time taken: 0.00\n",
      "num completed:  500\n",
      "time taken: 0.25\n",
      "num completed:  1000\n",
      "time taken: 0.51\n",
      "num completed:  1500\n",
      "time taken: 0.77\n",
      "num completed:  2000\n",
      "time taken: 1.08\n",
      "num completed:  2500\n",
      "time taken: 1.35\n",
      "num completed:  3000\n",
      "time taken: 1.63\n",
      "num completed:  3500\n",
      "time taken: 1.89\n",
      "num completed:  4000\n",
      "time taken: 2.14\n",
      "num completed:  4500\n",
      "time taken: 2.42\n",
      "num completed:  5000\n",
      "time taken: 2.68\n",
      "num completed:  5500\n",
      "time taken: 2.96\n",
      "num completed:  6000\n",
      "time taken: 3.23\n",
      "num completed:  6500\n",
      "time taken: 3.51\n"
     ]
    }
   ],
   "source": [
    "# recommend\n",
    "val_users = list(val_actual_items_dct.keys())\n",
    "\n",
    "recommended_items_dct = {}\n",
    "start = time.time()\n",
    "for i, user in enumerate(val_users):\n",
    "    if i % 500 == 0:\n",
    "        print('num completed: ', i)\n",
    "        print('time taken: %0.2f' % ((time.time() - start)/60.))\n",
    "    recommended_items_dct[user] = recommend(net, user, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num completed:  0\n",
      "time taken: 0.00\n",
      "num completed:  500\n",
      "time taken: 0.01\n",
      "num completed:  1000\n",
      "time taken: 0.03\n",
      "num completed:  1500\n",
      "time taken: 0.05\n",
      "num completed:  2000\n",
      "time taken: 0.06\n",
      "num completed:  2500\n",
      "time taken: 0.08\n",
      "num completed:  3000\n",
      "time taken: 0.10\n",
      "num completed:  3500\n",
      "time taken: 0.12\n",
      "num completed:  4000\n",
      "time taken: 0.13\n",
      "num completed:  4500\n",
      "time taken: 0.15\n",
      "num completed:  5000\n",
      "time taken: 0.16\n",
      "num completed:  5500\n",
      "time taken: 0.18\n",
      "num completed:  6000\n",
      "time taken: 0.19\n",
      "num completed:  6500\n",
      "time taken: 0.21\n"
     ]
    }
   ],
   "source": [
    "# recommend_dot\n",
    "val_users = list(val_actual_items_dct.keys())\n",
    "\n",
    "recommended_items_dct2 = {}\n",
    "start = time.time()\n",
    "for i, user in enumerate(val_users):\n",
    "    if i % 500 == 0:\n",
    "        print('num completed: ', i)\n",
    "        print('time taken: %0.2f' % ((time.time() - start)/60.))\n",
    "    recommended_items_dct2[user] = recommend_dot(net, user, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00015181296642536395\n",
      "0.0005593109289355513\n"
     ]
    }
   ],
   "source": [
    "print(get_mapk(val_actual_items_dct, recommended_items_dct, 3))\n",
    "print(get_mapk(val_actual_items_dct, recommended_items_dct2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1647, 1646, 497]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_actual_items_dct[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
