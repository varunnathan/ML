{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "1. To predict the next 3 challenges the user will be interested in solving\n",
    "\n",
    "## Methodology\n",
    "1. A simple feedforward NN with entity embeddings for challenge and user\n",
    "2. Objective/Loss function - BPR (good for ranking problems)\n",
    "3. Features - Only user id and challenge\n",
    "4. Sampling - Combine train & test samples. Create a val sample by keeping aside the last 3 challenges taken by x% of the users in the train sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, joblib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "LOCAL_DIR = '/Users/varunn/Documents/'\n",
    "DATA_DIR = os.path.join(LOCAL_DIR, 'AV_Data')\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "INTERIM_DIR = os.path.join(DATA_DIR, 'interim')\n",
    "CHALLENGE_DATA_FN = os.path.join(TRAIN_DIR, 'challenge_data.csv')\n",
    "TRAIN_DATA_FN = os.path.join(TRAIN_DIR, 'train.csv')\n",
    "TEST_DATA_FN = os.path.join(DATA_DIR, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_train = pd.read_csv(TRAIN_DATA_FN)\n",
    "df_test = pd.read_csv(TEST_DATA_FN)\n",
    "df_challenge = pd.read_csv(CHALLENGE_DATA_FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "\n",
      "(903916, 4)\n",
      "  user_sequence  user_id  challenge_sequence challenge\n",
      "0        4576_1     4576                   1   CI23714\n",
      "1        4576_2     4576                   2   CI23855\n",
      "2        4576_3     4576                   3   CI24917\n",
      "3        4576_4     4576                   4   CI23663\n",
      "4        4576_5     4576                   5   CI23933\n",
      "\n",
      "\n",
      "Num Users: 69532\n",
      "Num Challenges: 5348\n",
      "Num Challenges per User: 13\n"
     ]
    }
   ],
   "source": [
    "print('Train\\n')\n",
    "print(df_train.shape)\n",
    "print(df_train.head())\n",
    "print('\\n')\n",
    "\n",
    "n_users = df_train['user_id'].nunique()\n",
    "n_challenges = df_train['challenge'].nunique()\n",
    "n_challenge_per_user = df_train.groupby('user_id')['challenge'].nunique(\n",
    "    ).mean()\n",
    "print('Num Users: %d' % (n_users))\n",
    "print('Num Challenges: %d' % (n_challenges))\n",
    "print('Num Challenges per User: %d' % (n_challenge_per_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "\n",
      "(397320, 4)\n",
      "  user_sequence  user_id  challenge_sequence challenge\n",
      "0        4577_1     4577                   1   CI23855\n",
      "1        4577_2     4577                   2   CI23933\n",
      "2        4577_3     4577                   3   CI24917\n",
      "3        4577_4     4577                   4   CI24915\n",
      "4        4577_5     4577                   5   CI23714\n",
      "\n",
      "\n",
      "Num Users: 39732\n",
      "Num Challenges: 4477\n",
      "Num Challenges per User: 10\n"
     ]
    }
   ],
   "source": [
    "print('Test\\n')\n",
    "print(df_test.shape)\n",
    "print(df_test.head())\n",
    "print('\\n')\n",
    "\n",
    "n_users = df_test['user_id'].nunique()\n",
    "n_challenges = df_test['challenge'].nunique()\n",
    "n_challenge_per_user = df_test.groupby('user_id')['challenge'].nunique(\n",
    "    ).mean()\n",
    "print('Num Users: %d' % (n_users))\n",
    "print('Num Challenges: %d' % (n_challenges))\n",
    "print('Num Challenges per User: %d' % (n_challenge_per_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check if the users in test are in train\n",
      "39732 \n",
      "\n",
      "check if the challenges in test are in train\n",
      "154 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('check if the users in test are in train')\n",
    "train_users = set(df_train['user_id'].unique().tolist())\n",
    "test_users = set(df_test['user_id'].unique().tolist())\n",
    "\n",
    "print(len(test_users - train_users), '\\n')\n",
    "\n",
    "print('check if the challenges in test are in train')\n",
    "train_users = set(df_train['challenge'].unique().tolist())\n",
    "test_users = set(df_test['challenge'].unique().tolist())\n",
    "\n",
    "print(len(test_users - train_users), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num challenges: 5606\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>challenge_ID</th>\n",
       "      <th>programming_language</th>\n",
       "      <th>challenge_series_ID</th>\n",
       "      <th>total_submissions</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>author_ID</th>\n",
       "      <th>author_gender</th>\n",
       "      <th>author_org_ID</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CI23478</td>\n",
       "      <td>2</td>\n",
       "      <td>SI2445</td>\n",
       "      <td>37.0</td>\n",
       "      <td>06-05-2006</td>\n",
       "      <td>AI563576</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CI23479</td>\n",
       "      <td>2</td>\n",
       "      <td>SI2435</td>\n",
       "      <td>48.0</td>\n",
       "      <td>17-10-2002</td>\n",
       "      <td>AI563577</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100002</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CI23480</td>\n",
       "      <td>1</td>\n",
       "      <td>SI2435</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16-10-2002</td>\n",
       "      <td>AI563578</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CI23481</td>\n",
       "      <td>1</td>\n",
       "      <td>SI2710</td>\n",
       "      <td>236.0</td>\n",
       "      <td>19-09-2003</td>\n",
       "      <td>AI563579</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100004</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CI23482</td>\n",
       "      <td>2</td>\n",
       "      <td>SI2440</td>\n",
       "      <td>137.0</td>\n",
       "      <td>21-03-2002</td>\n",
       "      <td>AI563580</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  challenge_ID  programming_language challenge_series_ID  total_submissions  \\\n",
       "0      CI23478                     2              SI2445               37.0   \n",
       "1      CI23479                     2              SI2435               48.0   \n",
       "2      CI23480                     1              SI2435               15.0   \n",
       "3      CI23481                     1              SI2710              236.0   \n",
       "4      CI23482                     2              SI2440              137.0   \n",
       "\n",
       "  publish_date author_ID author_gender author_org_ID  category_id  \n",
       "0   06-05-2006  AI563576             M     AOI100001          NaN  \n",
       "1   17-10-2002  AI563577             M     AOI100002         32.0  \n",
       "2   16-10-2002  AI563578             M     AOI100003          NaN  \n",
       "3   19-09-2003  AI563579             M     AOI100004         70.0  \n",
       "4   21-03-2002  AI563580             M     AOI100005          NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# challenge data\n",
    "n_challenges = df_challenge['challenge_ID'].nunique()\n",
    "print('num challenges: %d' % (n_challenges))\n",
    "df_challenge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "challenge_ID\n",
      "num unique values: 5606\n",
      "\n",
      "\n",
      "programming_language\n",
      "num unique values: 3\n",
      "\n",
      "\n",
      "challenge_series_ID\n",
      "num unique values: 435\n",
      "\n",
      "\n",
      "total_submissions\n",
      "num unique values: 1067\n",
      "\n",
      "\n",
      "publish_date\n",
      "num unique values: 1145\n",
      "\n",
      "\n",
      "author_ID\n",
      "num unique values: 3484\n",
      "\n",
      "\n",
      "author_gender\n",
      "num unique values: 2\n",
      "\n",
      "\n",
      "author_org_ID\n",
      "num unique values: 1717\n",
      "\n",
      "\n",
      "category_id\n",
      "num unique values: 194\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of unique values\n",
    "cols = list(df_challenge.columns)\n",
    "for col in cols:\n",
    "    print(col)\n",
    "    print('num unique values: %d' % (df_challenge[col].nunique()))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903916, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    903916.0\n",
       "mean          1.0\n",
       "std           0.0\n",
       "min           1.0\n",
       "25%           1.0\n",
       "50%           1.0\n",
       "75%           1.0\n",
       "max           1.0\n",
       "Name: num_times_challenge_taken, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of interactions between a user and a challenge\n",
    "tmp = df_train.groupby(['user_id', 'challenge'])['user_sequence'].count(\n",
    "    ).rename('num_times_challenge_taken').reset_index()\n",
    "print(tmp.shape)\n",
    "tmp['num_times_challenge_taken'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "1. id mapping for categorical variables\n",
    "2. Normalization for numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "CATEGORICAL_VARS = ['user_id', 'challenge_sequence', 'challenge',\n",
    "                    'programming_language', 'challenge_series_ID',\n",
    "                    'author_ID', 'author_gender', 'author_org_ID',\n",
    "                    'category_id']\n",
    "NUMERIC_VARS = ['total_submissions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1301236, 5)\n"
     ]
    }
   ],
   "source": [
    "# append train and test data to create a unified dataset\n",
    "cols = ['user_sequence', 'user_id', 'challenge_sequence', 'challenge',\n",
    "        'sample']\n",
    "df_train['sample'] = 'train'\n",
    "df_test['sample'] = 'test'\n",
    "df = pd.concat([df_train[cols], df_test[cols]], axis=0)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col: user_id\n",
      "109264 \t 109264\n",
      "save\n",
      "\n",
      "\n",
      "Col: challenge_sequence\n",
      "13 \t 13\n",
      "save\n",
      "\n",
      "\n",
      "Col: challenge\n",
      "5606 \t 5606\n",
      "save\n",
      "\n",
      "\n",
      "Col: programming_language\n",
      "3 \t 3\n",
      "save\n",
      "\n",
      "\n",
      "Col: challenge_series_ID\n",
      "436 \t 436\n",
      "save\n",
      "\n",
      "\n",
      "Col: author_ID\n",
      "3485 \t 3485\n",
      "save\n",
      "\n",
      "\n",
      "Col: author_gender\n",
      "3 \t 3\n",
      "save\n",
      "\n",
      "\n",
      "Col: author_org_ID\n",
      "1718 \t 1718\n",
      "save\n",
      "\n",
      "\n",
      "Col: category_id\n",
      "195 \t 195\n",
      "save\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# id mapping for categorical variables\n",
    "df_challenge.rename(columns={'challenge_ID': 'challenge'}, inplace=True)\n",
    "\n",
    "for col in CATEGORICAL_VARS:\n",
    "    print('Col: %s' % (col))\n",
    "    if col in ('user_id', 'challenge_sequence'):\n",
    "        values = df[col].unique().tolist()\n",
    "    else:\n",
    "        values = df_challenge[col].unique().tolist()\n",
    "    value2idx = {value: idx for idx, value in enumerate(values)}\n",
    "    idx2value = {idx: value for idx, value in enumerate(values)}\n",
    "    \n",
    "    print(len(value2idx), '\\t', len(idx2value))\n",
    "    \n",
    "    print('save')\n",
    "    value2idx_fn = os.path.join(INTERIM_DIR, '{}2idx.json'.format(col))\n",
    "    idx2value_fn = os.path.join(INTERIM_DIR, 'idx2{}.json'.format(col))\n",
    "    json.dump(value2idx, open(value2idx_fn, 'w'))\n",
    "    json.dump(idx2value, open(idx2value_fn, 'w'))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling for baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "TEST_USER_PROPORTION = 0.1\n",
    "SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col: user_id\n",
      "Col: challenge\n"
     ]
    }
   ],
   "source": [
    "# mapping discrete cols to mapped id cols\n",
    "\n",
    "baseline_df = df.copy()\n",
    "\n",
    "for col in ['user_id', 'challenge']:\n",
    "    print('Col: %s' % (col))\n",
    "    value2idx_fn = os.path.join(INTERIM_DIR, '{}2idx.json'.format(col))\n",
    "    d = json.load(open(value2idx_fn))\n",
    "    baseline_df[col] = baseline_df[col].apply(lambda x: d[str(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280377, 5) \t (20859, 5)\n",
      "109264 \t 6953\n"
     ]
    }
   ],
   "source": [
    "# sampling\n",
    "\n",
    "mask = baseline_df['sample'] == 'train'\n",
    "users = baseline_df.loc[mask, 'user_id'].unique().tolist()\n",
    "np.random.seed(SEED)\n",
    "users = list(np.random.permutation(users))\n",
    "num_val_users = int(TEST_USER_PROPORTION*len(users))\n",
    "val_users = users[:num_val_users]\n",
    "\n",
    "mask1 = baseline_df['user_id'].isin(val_users)\n",
    "mask2 = baseline_df['challenge_sequence'].isin([11, 12, 13])\n",
    "val_df = baseline_df.loc[mask1&mask2, :]\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "dev_df = baseline_df.loc[~(mask1&mask2), :]\n",
    "dev_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(dev_df.shape, '\\t', val_df.shape)\n",
    "print(dev_df['user_id'].nunique(), '\\t', val_df['user_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6953\n"
     ]
    }
   ],
   "source": [
    "# get actual items dct on val sample for mapk calculation\n",
    "tmp = val_df.groupby('user_id')['challenge'].apply(list).rename(\n",
    "    'challenge_lst').reset_index()\n",
    "val_actual_items_dct = dict(zip(tmp['user_id'], tmp['challenge_lst']))\n",
    "print(len(val_actual_items_dct))\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109264\n"
     ]
    }
   ],
   "source": [
    "# get seen items dct for mapk calculation\n",
    "tmp = dev_df.groupby('user_id')['challenge'].apply(list).rename(\n",
    "    'challenge_lst').reset_index()\n",
    "seen_items_dct = dict(zip(tmp['user_id'], tmp['challenge_lst']))\n",
    "print(len(seen_items_dct))\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "dev_fn = os.path.join(INTERIM_DIR, 'baseline_dev_df.csv')\n",
    "val_fn = os.path.join(INTERIM_DIR, 'baseline_val_df.csv')\n",
    "val_actual_items_dct_fn = os.path.join(INTERIM_DIR,\n",
    "                                       'val_actual_items_dct.json')\n",
    "seen_items_dct_fn = os.path.join(INTERIM_DIR, 'seen_items_dct.json')\n",
    "dev_df.to_csv(dev_fn, index=False)\n",
    "val_df.to_csv(val_fn, index=False)\n",
    "json.dump(val_actual_items_dct, open(val_actual_items_dct_fn, 'w'))\n",
    "json.dump(seen_items_dct, open(seen_items_dct_fn, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
