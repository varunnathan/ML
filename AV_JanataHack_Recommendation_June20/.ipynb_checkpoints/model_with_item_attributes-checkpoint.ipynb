{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, joblib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "LOCAL_DIR = '/Users/varunn/Documents/'\n",
    "DATA_DIR = os.path.join(LOCAL_DIR, 'AV_Data')\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "INTERIM_DIR = os.path.join(DATA_DIR, 'interim')\n",
    "CHALLENGE_DATA_FN = os.path.join(TRAIN_DIR, 'challenge_data.csv')\n",
    "TRAIN_DATA_FN = os.path.join(TRAIN_DIR, 'train.csv')\n",
    "TEST_DATA_FN = os.path.join(DATA_DIR, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data used for training baseline_model\n",
    "dev_fn = os.path.join(INTERIM_DIR, 'baseline_dev_df.csv')\n",
    "val_fn = os.path.join(INTERIM_DIR, 'baseline_val_df.csv')\n",
    "val_actual_items_dct_fn = os.path.join(INTERIM_DIR,\n",
    "                                       'val_actual_items_dct.json')\n",
    "seen_items_dct_fn = os.path.join(INTERIM_DIR, 'seen_items_dct.json')\n",
    "seen_items_dct_all_fn = os.path.join(INTERIM_DIR,\n",
    "                                     'seen_items_dct_all.json')\n",
    "dev_df = pd.read_csv(dev_fn)\n",
    "val_df = pd.read_csv(val_fn)\n",
    "val_actual_items_dct = json.load(open(val_actual_items_dct_fn))\n",
    "seen_items_dct = json.load(open(seen_items_dct_fn))\n",
    "seen_items_dct_all = json.load(open(seen_items_dct_all_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ids to int in dicts\n",
    "val_actual_items_dct = {int(idx): val for idx, val in\n",
    "                        val_actual_items_dct.items()}\n",
    "seen_items_dct_all = {int(idx): val for idx, val in\n",
    "                      seen_items_dct_all.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create item_attr_dct for adding the item features to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# read mapping dcts\n",
    "cat_cols = ['user_id', 'challenge_sequence', 'challenge',\n",
    "            'programming_language', 'challenge_series_ID',\n",
    "            'author_ID', 'author_gender', 'author_org_ID',\n",
    "            'category_id']\n",
    "d = {}\n",
    "for col in cat_cols:\n",
    "    inp_fn = os.path.join(INTERIM_DIR, '{}2idx.json'.format(col))\n",
    "    d[col] = json.load(open(inp_fn))\n",
    "\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>challenge_ID</th>\n",
       "      <th>programming_language</th>\n",
       "      <th>challenge_series_ID</th>\n",
       "      <th>total_submissions</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>author_ID</th>\n",
       "      <th>author_gender</th>\n",
       "      <th>author_org_ID</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CI23478</td>\n",
       "      <td>2</td>\n",
       "      <td>SI2445</td>\n",
       "      <td>37.0</td>\n",
       "      <td>06-05-2006</td>\n",
       "      <td>AI563576</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CI23479</td>\n",
       "      <td>2</td>\n",
       "      <td>SI2435</td>\n",
       "      <td>48.0</td>\n",
       "      <td>17-10-2002</td>\n",
       "      <td>AI563577</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100002</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CI23480</td>\n",
       "      <td>1</td>\n",
       "      <td>SI2435</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16-10-2002</td>\n",
       "      <td>AI563578</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CI23481</td>\n",
       "      <td>1</td>\n",
       "      <td>SI2710</td>\n",
       "      <td>236.0</td>\n",
       "      <td>19-09-2003</td>\n",
       "      <td>AI563579</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100004</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CI23482</td>\n",
       "      <td>2</td>\n",
       "      <td>SI2440</td>\n",
       "      <td>137.0</td>\n",
       "      <td>21-03-2002</td>\n",
       "      <td>AI563580</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  challenge_ID  programming_language challenge_series_ID  total_submissions  \\\n",
       "0      CI23478                     2              SI2445               37.0   \n",
       "1      CI23479                     2              SI2435               48.0   \n",
       "2      CI23480                     1              SI2435               15.0   \n",
       "3      CI23481                     1              SI2710              236.0   \n",
       "4      CI23482                     2              SI2440              137.0   \n",
       "\n",
       "  publish_date author_ID author_gender author_org_ID  category_id  \n",
       "0   06-05-2006  AI563576             M     AOI100001          NaN  \n",
       "1   17-10-2002  AI563577             M     AOI100002         32.0  \n",
       "2   16-10-2002  AI563578             M     AOI100003          NaN  \n",
       "3   19-09-2003  AI563579             M     AOI100004         70.0  \n",
       "4   21-03-2002  AI563580             M     AOI100005          NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read challenge data\n",
    "challenge_data_fn = os.path.join(TRAIN_DIR, 'challenge_data.csv')\n",
    "df_challenge = pd.read_csv(challenge_data_fn)\n",
    "df_challenge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_challenge.rename(columns={'challenge_ID': 'challenge'}, inplace=True)\n",
    "df_challenge.fillna(value={'challenge_series_ID': 'missing',\n",
    "                           'author_ID': 'missing',\n",
    "                           'author_gender': 'missing',\n",
    "                           'author_org_ID': 'missing'}, inplace=True)\n",
    "df_challenge.fillna(value={\n",
    "    'total_submissions': 0, 'programming_language': 0,\n",
    "    'category_id': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "challenge\n",
      "programming_language\n",
      "challenge_series_ID\n",
      "author_ID\n",
      "author_gender\n",
      "author_org_ID\n",
      "category_id\n"
     ]
    }
   ],
   "source": [
    "# mapping values to ids\n",
    "cols = [x for x in list(df_challenge.columns) if x not in\n",
    "        ('publish_date', 'total_submissions')]\n",
    "\n",
    "for col in cols:\n",
    "    print(col)\n",
    "    df_challenge[col] = df_challenge[col].apply(lambda x: d[col][str(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5606"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# item_attr_dct\n",
    "ordered_cols = ['programming_language', 'challenge_series_ID',\n",
    "                'author_ID', 'author_gender', 'author_org_ID',\n",
    "                'category_id', 'total_submissions']\n",
    "df_challenge['attr_lst'] = df_challenge[ordered_cols].apply(\n",
    "    lambda x: list(x), axis=1)\n",
    "\n",
    "item_attr_dct = dict(zip(df_challenge['challenge'],\n",
    "                         df_challenge['attr_lst']))\n",
    "len(item_attr_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "out_fn = os.path.join(INTERIM_DIR, 'item_attr_dct.json')\n",
    "json.dump(item_attr_dct, open(out_fn, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation for MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping challenge_sequence to id\n",
    "dev_df['challenge_sequence'] = dev_df['challenge_sequence'].apply(\n",
    "    lambda x: d['challenge_sequence'][str(x)])\n",
    "val_df['challenge_sequence'] = val_df['challenge_sequence'].apply(\n",
    "    lambda x: d['challenge_sequence'][str(x)])\n",
    "\n",
    "# mapping attrs to item id\n",
    "for i, col in enumerate(ordered_cols):\n",
    "    dev_df[col] = dev_df['challenge'].apply(lambda x: item_attr_dct[x][i])\n",
    "    val_df[col] = val_df['challenge'].apply(lambda x: item_attr_dct[x][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "dev_fn = os.path.join(INTERIM_DIR, 'mlp_dev_df.csv')\n",
    "val_fn = os.path.join(INTERIM_DIR, 'mlp_val_df.csv')\n",
    "dev_df.to_csv(dev_fn, index=False)\n",
    "val_df.to_csv(val_fn, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "dev_fn = os.path.join(INTERIM_DIR, 'mlp_dev_df.csv')\n",
    "val_fn = os.path.join(INTERIM_DIR, 'mlp_val_df.csv')\n",
    "val_actual_items_dct_fn = os.path.join(INTERIM_DIR,\n",
    "                                       'val_actual_items_dct.json')\n",
    "seen_items_dct_fn = os.path.join(INTERIM_DIR, 'seen_items_dct.json')\n",
    "seen_items_dct_all_fn = os.path.join(INTERIM_DIR,\n",
    "                                     'seen_items_dct_all.json')\n",
    "item_attr_dct_fn = os.path.join(INTERIM_DIR, 'item_attr_dct.json')\n",
    "dev_df = pd.read_csv(dev_fn)\n",
    "val_df = pd.read_csv(val_fn)\n",
    "val_actual_items_dct = json.load(open(val_actual_items_dct_fn))\n",
    "seen_items_dct = json.load(open(seen_items_dct_fn))\n",
    "seen_items_dct_all = json.load(open(seen_items_dct_all_fn))\n",
    "item_attr_dct = json.load(open(item_attr_dct_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ids to int in dicts\n",
    "val_actual_items_dct = {int(idx): val for idx, val in\n",
    "                        val_actual_items_dct.items()}\n",
    "seen_items_dct = {int(idx): val for idx, val in\n",
    "                  seen_items_dct.items()}\n",
    "seen_items_dct_all = {int(idx): val for idx, val in\n",
    "                      seen_items_dct_all.items()}\n",
    "item_attr_dct = {int(idx): val for idx, val in item_attr_dct.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# read mapping dcts\n",
    "cat_cols = ['user_id', 'challenge_sequence', 'challenge',\n",
    "            'programming_language', 'challenge_series_ID',\n",
    "            'author_ID', 'author_gender', 'author_org_ID',\n",
    "            'category_id']\n",
    "d = {}\n",
    "for col in cat_cols:\n",
    "    inp_fn = os.path.join(INTERIM_DIR, '{}2idx.json'.format(col))\n",
    "    d[col] = json.load(open(inp_fn))\n",
    "\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "N_USERS = len(d['user_id'])\n",
    "N_ITEMS = len(d['challenge'])\n",
    "N_CHALLENGES_PER_USER = len(d['challenge_sequence'])\n",
    "N_PL = len(d['programming_language'])\n",
    "N_CSI = len(d['challenge_series_ID'])\n",
    "N_AID = len(d['author_ID'])\n",
    "N_AG = len(d['author_gender'])\n",
    "N_AOID = len(d['author_org_ID'])\n",
    "N_CID = len(d['category_id'])\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loader\n",
    "\n",
    "from torchmlp import PairwiseInteractionsMLP\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dev_loader = PairwiseInteractionsMLP(\n",
    "    dev_df, N_ITEMS, N_CHALLENGES_PER_USER, seen_items_dct_all,\n",
    "    item_attr_dct, seed=1)\n",
    "dev_loader = DataLoader(dev_loader, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_loader = PairwiseInteractionsMLP(\n",
    "    val_df, N_ITEMS, N_CHALLENGES_PER_USER, seen_items_dct_all,\n",
    "    item_attr_dct, seed=1)\n",
    "val_loader = DataLoader(val_loader, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom itertools import islice\\n\\nfor pos_cat, pos_num, neg_cat, neg_num in islice(dev_loader, 1):\\n    print(pos_cat)\\n    print('\\n')\\n    print(pos_num)\\n    print('\\n')\\n    print(neg_cat)\\n    print('\\n')\\n    print(neg_num)\\n    print('\\n')\\n    user = pos_cat.numpy()[:, 0]\\n    print(user)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from itertools import islice\n",
    "\n",
    "for pos_cat, pos_num, neg_cat, neg_num in islice(dev_loader, 1):\n",
    "    print(pos_cat)\n",
    "    print('\\n')\n",
    "    print(pos_num)\n",
    "    print('\\n')\n",
    "    print(neg_cat)\n",
    "    print('\\n')\n",
    "    print(neg_num)\n",
    "    print('\\n')\n",
    "    user = pos_cat.numpy()[:, 0]\n",
    "    print(user)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network\n",
    "\n",
    "def choose_embedding_size(cat_cols, cat_num_values, min_emb_dim=100):\n",
    "    \"\"\"\n",
    "    cat_cols: list of categorical columns\n",
    "    cat_num_values: list of number of unique values for each categorical column\n",
    "    \"\"\"\n",
    "\n",
    "    embedded_cols = dict(zip(cat_cols, cat_num_values))\n",
    "    print(embedded_cols)\n",
    "    embedding_sizes = [(n_categories,\n",
    "                        min(min_emb_dim, (n_categories+1)//2))\n",
    "                       for _, n_categories in embedded_cols.items()]\n",
    "    return embedding_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': 109264, 'challenge': 5606, 'programming_language': 3, 'challenge_series_ID': 436, 'author_ID': 3485, 'author_gender': 3, 'author_org_ID': 1718, 'category_id': 195, 'challenge_sequence': 14}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(109264, 50),\n",
       " (5606, 50),\n",
       " (3, 2),\n",
       " (436, 50),\n",
       " (3485, 50),\n",
       " (3, 2),\n",
       " (1718, 50),\n",
       " (195, 50),\n",
       " (14, 7)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = ['user_id', 'challenge', 'programming_language',\n",
    "            'challenge_series_ID', 'author_ID', 'author_gender',\n",
    "            'author_org_ID', 'category_id', 'challenge_sequence']\n",
    "cat_num_values = [N_USERS, N_ITEMS, N_PL, N_CSI, N_AID, N_AG, N_AOID,\n",
    "                  N_CID, N_CHALLENGES_PER_USER+1]\n",
    "embedding_sizes = choose_embedding_size(cat_cols, cat_num_values, 50)\n",
    "embedding_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmlp import BPRModuleMLP\n",
    "model = BPRModuleMLP(embedding_sizes, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPRModuleMLP(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(109264, 50)\n",
       "    (1): Embedding(5606, 50)\n",
       "    (2): Embedding(3, 2)\n",
       "    (3): Embedding(436, 50)\n",
       "    (4): Embedding(3485, 50)\n",
       "    (5): Embedding(3, 2)\n",
       "    (6): Embedding(1718, 50)\n",
       "    (7): Embedding(195, 50)\n",
       "    (8): Embedding(14, 7)\n",
       "  )\n",
       "  (lin1): Linear(in_features=312, out_features=300, bias=True)\n",
       "  (lin2): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (lin3): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (bn1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (emb_drop): Dropout(p=0.6, inplace=False)\n",
       "  (drops): Dropout(p=0.6, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training class\n",
    "\n",
    "from trainingmlp import StepMLP\n",
    "from torchmf import bpr_loss\n",
    "net = StepMLP(model=model, n_items=N_ITEMS, item_attr_dct=item_attr_dct,\n",
    "              n_challenges_per_user=N_CHALLENGES_PER_USER,\n",
    "              actual_items_dct=val_actual_items_dct,\n",
    "              seen_items_dct=seen_items_dct, loss_function=bpr_loss,\n",
    "              lr=0.03, weight_decay=0.05, batch_size=BATCH_SIZE,\n",
    "              num_predictions=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280377 \t 20859 \t 2560\n"
     ]
    }
   ],
   "source": [
    "train_size, test_size = dev_df.shape[0], val_df.shape[0]\n",
    "print(train_size, '\\t', test_size, '\\t', train_size//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2560 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2561it [1:41:43,  2.21s/it]                          \n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation begins...\n",
      "validation with mapk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 5/41 [39:31<4:45:03, 475.10s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-dd0c34e36e95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m net.batch_fit(train_loader=dev_loader, test_loader=val_loader,\n\u001b[1;32m      5\u001b[0m               \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_mapk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m               epochs=2)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time taken: %0.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m60.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ML/AV_JanataHack_Recommendation_June20/training.py\u001b[0m in \u001b[0;36mbatch_fit\u001b[0;34m(self, train_loader, test_loader, train_size, test_size, epochs, calc_mapk)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'validation with mapk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 val_loss, val_mapk = self._validation(\n\u001b[0;32m---> 84\u001b[0;31m                     test_loader, test_size, calc_mapk)\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_mapk'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_mapk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ML/AV_JanataHack_Recommendation_June20/trainingmlp.py\u001b[0m in \u001b[0;36m_validation\u001b[0;34m(self, data_loader, data_size, calc_mapk)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0muser_lst_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0musers_processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0musers_processed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_lst_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mrecommended_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_lst_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_lst_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecommended_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommended_items_dct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ML/AV_JanataHack_Recommendation_June20/trainingmlp.py\u001b[0m in \u001b[0;36mrecommend_batch\u001b[0;34m(self, user_list)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecommend_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         return [self.recommend(user, self.num_predictions) for user in\n\u001b[0;32m--> 130\u001b[0;31m                 user_list]\n\u001b[0m",
      "\u001b[0;32m~/Documents/ML/AV_JanataHack_Recommendation_June20/trainingmlp.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecommend_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         return [self.recommend(user, self.num_predictions) for user in\n\u001b[0m\u001b[1;32m    130\u001b[0m                 user_list]\n",
      "\u001b[0;32m~/Documents/ML/AV_JanataHack_Recommendation_June20/trainingmlp.py\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(self, user, k)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mcat_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mcat_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ML/AV_JanataHack_Recommendation_June20/torchmlp.py\u001b[0m in \u001b[0;36mcalc_pred\u001b[0;34m(self, x_cat, x_cont)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "net.batch_fit(train_loader=dev_loader, test_loader=val_loader,\n",
    "              train_size=train_size, test_size=test_size, calc_mapk=True,\n",
    "              epochs=2)\n",
    "print('time taken: %0.2f' % ((time.time() - start)/60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "\n",
    "def recommend(model_class, user_lst, k:int = 10):\n",
    "    \"\"\"Recommends the top-k items to a specific user.\"\"\"\n",
    "    model_class.model.eval()\n",
    "\n",
    "    for user in user_lst:\n",
    "        item_lst = [x for x in range(model_class.n_items) if x not in\n",
    "                    model_class.seen_items_dct[user]]\n",
    "        user_value = [user]\n",
    "        cat_values, num_values = [], []\n",
    "        start = time.time()\n",
    "        for i, item in enumerate(item_lst):\n",
    "            if i % 1000 == 0:\n",
    "                print('num completed: ', i)\n",
    "                print('time taken: %0.2f' % ((time.time() - start)/60.))\n",
    "            item_value = [model_class.item_attr_dct[item][i] for i, col in\n",
    "                          enumerate(model_class.item_cols)]\n",
    "            num_value = [model_class.item_attr_dct[item][6]]\n",
    "            joint_value = [model_class.n_challenges_per_user]\n",
    "            cat_value = user_value + [item] + item_value + joint_value\n",
    "            cat_values.append(cat_value)\n",
    "            num_values.append(num_value)\n",
    "\n",
    "    cat_values = tensor(cat_values)\n",
    "    cat_values = cat_values.long()\n",
    "    num_values = tensor(num_values)\n",
    "    num_values = num_values.double()\n",
    "    scores = model_class.model.calc_pred(cat_values, num_values)\n",
    "    scores = scores.squeeze()\n",
    "    sorted_scores = scores.argsort().tolist()\n",
    "    return sorted_scores[::-1][:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num completed:  0\n",
      "time taken: 0.00\n",
      "num completed:  1000\n",
      "time taken: 0.00\n",
      "num completed:  2000\n",
      "time taken: 0.00\n",
      "num completed:  3000\n",
      "time taken: 0.00\n",
      "num completed:  4000\n",
      "time taken: 0.00\n",
      "num completed:  5000\n",
      "time taken: 0.00\n",
      "CPU times: user 264 ms, sys: 54.9 ms, total: 319 ms\n",
      "Wall time: 123 ms\n"
     ]
    }
   ],
   "source": [
    "%time rec_items = recommend(net, 0, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5592, 1860, 1861]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6666666666666667"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.150*40000)/3600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
