{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "1. To predict the next 3 challenges the user will be interested in solving\n",
    "\n",
    "## Methodology\n",
    "1. A simple feedforward NN with entity embeddings for challenge and user\n",
    "2. Objective/Loss function - BPR (good for ranking problems)\n",
    "3. Features - Only user id and challenge\n",
    "4. Sampling - Combine train & test samples. Create a val sample by keeping aside the last 3 challenges taken by x% of the users in the train sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, joblib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "LOCAL_DIR = '/Users/varunn/Documents/'\n",
    "DATA_DIR = os.path.join(LOCAL_DIR, 'AV_Data')\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "INTERIM_DIR = os.path.join(DATA_DIR, 'interim')\n",
    "CHALLENGE_DATA_FN = os.path.join(TRAIN_DIR, 'challenge_data.csv')\n",
    "TRAIN_DATA_FN = os.path.join(TRAIN_DIR, 'train.csv')\n",
    "TEST_DATA_FN = os.path.join(DATA_DIR, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_train = pd.read_csv(TRAIN_DATA_FN)\n",
    "df_test = pd.read_csv(TEST_DATA_FN)\n",
    "df_challenge = pd.read_csv(CHALLENGE_DATA_FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "\n",
      "(903916, 4)\n",
      "  user_sequence  user_id  challenge_sequence challenge\n",
      "0        4576_1     4576                   1   CI23714\n",
      "1        4576_2     4576                   2   CI23855\n",
      "2        4576_3     4576                   3   CI24917\n",
      "3        4576_4     4576                   4   CI23663\n",
      "4        4576_5     4576                   5   CI23933\n",
      "\n",
      "\n",
      "Num Users: 69532\n",
      "Num Challenges: 5348\n",
      "Num Challenges per User: 13\n"
     ]
    }
   ],
   "source": [
    "print('Train\\n')\n",
    "print(df_train.shape)\n",
    "print(df_train.head())\n",
    "print('\\n')\n",
    "\n",
    "n_users = df_train['user_id'].nunique()\n",
    "n_challenges = df_train['challenge'].nunique()\n",
    "n_challenge_per_user = df_train.groupby('user_id')['challenge'].nunique(\n",
    "    ).mean()\n",
    "print('Num Users: %d' % (n_users))\n",
    "print('Num Challenges: %d' % (n_challenges))\n",
    "print('Num Challenges per User: %d' % (n_challenge_per_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "\n",
      "(397320, 4)\n",
      "  user_sequence  user_id  challenge_sequence challenge\n",
      "0        4577_1     4577                   1   CI23855\n",
      "1        4577_2     4577                   2   CI23933\n",
      "2        4577_3     4577                   3   CI24917\n",
      "3        4577_4     4577                   4   CI24915\n",
      "4        4577_5     4577                   5   CI23714\n",
      "\n",
      "\n",
      "Num Users: 39732\n",
      "Num Challenges: 4477\n",
      "Num Challenges per User: 10\n"
     ]
    }
   ],
   "source": [
    "print('Test\\n')\n",
    "print(df_test.shape)\n",
    "print(df_test.head())\n",
    "print('\\n')\n",
    "\n",
    "n_users = df_test['user_id'].nunique()\n",
    "n_challenges = df_test['challenge'].nunique()\n",
    "n_challenge_per_user = df_test.groupby('user_id')['challenge'].nunique(\n",
    "    ).mean()\n",
    "print('Num Users: %d' % (n_users))\n",
    "print('Num Challenges: %d' % (n_challenges))\n",
    "print('Num Challenges per User: %d' % (n_challenge_per_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check if the users in test are in train\n",
      "39732 \n",
      "\n",
      "check if the challenges in test are in train\n",
      "154 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('check if the users in test are in train')\n",
    "train_users = set(df_train['user_id'].unique().tolist())\n",
    "test_users = set(df_test['user_id'].unique().tolist())\n",
    "\n",
    "print(len(test_users - train_users), '\\n')\n",
    "\n",
    "print('check if the challenges in test are in train')\n",
    "train_users = set(df_train['challenge'].unique().tolist())\n",
    "test_users = set(df_test['challenge'].unique().tolist())\n",
    "\n",
    "print(len(test_users - train_users), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num challenges: 5606\n",
      "shape:  (5606, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>challenge_ID</th>\n",
       "      <th>programming_language</th>\n",
       "      <th>challenge_series_ID</th>\n",
       "      <th>total_submissions</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>author_ID</th>\n",
       "      <th>author_gender</th>\n",
       "      <th>author_org_ID</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CI23478</td>\n",
       "      <td>2</td>\n",
       "      <td>SI2445</td>\n",
       "      <td>37.0</td>\n",
       "      <td>06-05-2006</td>\n",
       "      <td>AI563576</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CI23479</td>\n",
       "      <td>2</td>\n",
       "      <td>SI2435</td>\n",
       "      <td>48.0</td>\n",
       "      <td>17-10-2002</td>\n",
       "      <td>AI563577</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100002</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CI23480</td>\n",
       "      <td>1</td>\n",
       "      <td>SI2435</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16-10-2002</td>\n",
       "      <td>AI563578</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CI23481</td>\n",
       "      <td>1</td>\n",
       "      <td>SI2710</td>\n",
       "      <td>236.0</td>\n",
       "      <td>19-09-2003</td>\n",
       "      <td>AI563579</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100004</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CI23482</td>\n",
       "      <td>2</td>\n",
       "      <td>SI2440</td>\n",
       "      <td>137.0</td>\n",
       "      <td>21-03-2002</td>\n",
       "      <td>AI563580</td>\n",
       "      <td>M</td>\n",
       "      <td>AOI100005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  challenge_ID  programming_language challenge_series_ID  total_submissions  \\\n",
       "0      CI23478                     2              SI2445               37.0   \n",
       "1      CI23479                     2              SI2435               48.0   \n",
       "2      CI23480                     1              SI2435               15.0   \n",
       "3      CI23481                     1              SI2710              236.0   \n",
       "4      CI23482                     2              SI2440              137.0   \n",
       "\n",
       "  publish_date author_ID author_gender author_org_ID  category_id  \n",
       "0   06-05-2006  AI563576             M     AOI100001          NaN  \n",
       "1   17-10-2002  AI563577             M     AOI100002         32.0  \n",
       "2   16-10-2002  AI563578             M     AOI100003          NaN  \n",
       "3   19-09-2003  AI563579             M     AOI100004         70.0  \n",
       "4   21-03-2002  AI563580             M     AOI100005          NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# challenge data\n",
    "n_challenges = df_challenge['challenge_ID'].nunique()\n",
    "print('num challenges: %d' % (n_challenges))\n",
    "print('shape: ', df_challenge.shape)\n",
    "df_challenge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "challenge_ID               0\n",
       "programming_language       0\n",
       "challenge_series_ID       12\n",
       "total_submissions        352\n",
       "publish_date               0\n",
       "author_ID                 39\n",
       "author_gender             97\n",
       "author_org_ID            248\n",
       "category_id             1841\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_challenge.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "challenge_ID\n",
      "num unique values: 5606\n",
      "\n",
      "\n",
      "programming_language\n",
      "num unique values: 3\n",
      "\n",
      "\n",
      "challenge_series_ID\n",
      "num unique values: 435\n",
      "\n",
      "\n",
      "total_submissions\n",
      "num unique values: 1067\n",
      "\n",
      "\n",
      "publish_date\n",
      "num unique values: 1145\n",
      "\n",
      "\n",
      "author_ID\n",
      "num unique values: 3484\n",
      "\n",
      "\n",
      "author_gender\n",
      "num unique values: 2\n",
      "\n",
      "\n",
      "author_org_ID\n",
      "num unique values: 1717\n",
      "\n",
      "\n",
      "category_id\n",
      "num unique values: 194\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of unique values\n",
    "cols = list(df_challenge.columns)\n",
    "for col in cols:\n",
    "    print(col)\n",
    "    print('num unique values: %d' % (df_challenge[col].nunique()))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903916, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    903916.0\n",
       "mean          1.0\n",
       "std           0.0\n",
       "min           1.0\n",
       "25%           1.0\n",
       "50%           1.0\n",
       "75%           1.0\n",
       "max           1.0\n",
       "Name: num_times_challenge_taken, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of interactions between a user and a challenge\n",
    "tmp = df_train.groupby(['user_id', 'challenge'])['user_sequence'].count(\n",
    "    ).rename('num_times_challenge_taken').reset_index()\n",
    "print(tmp.shape)\n",
    "tmp['num_times_challenge_taken'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "1. id mapping for categorical variables\n",
    "2. Normalization for numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "CATEGORICAL_VARS = ['user_id', 'challenge_sequence', 'challenge',\n",
    "                    'programming_language', 'challenge_series_ID',\n",
    "                    'author_ID', 'author_gender', 'author_org_ID',\n",
    "                    'category_id']\n",
    "NUMERIC_VARS = ['total_submissions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1301236, 5)\n"
     ]
    }
   ],
   "source": [
    "# append train and test data to create a unified dataset\n",
    "cols = ['user_sequence', 'user_id', 'challenge_sequence', 'challenge',\n",
    "        'sample']\n",
    "df_train['sample'] = 'train'\n",
    "df_test['sample'] = 'test'\n",
    "df = pd.concat([df_train[cols], df_test[cols]], axis=0)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "challenge               0\n",
      "programming_language    0\n",
      "challenge_series_ID     0\n",
      "total_submissions       0\n",
      "publish_date            0\n",
      "author_ID               0\n",
      "author_gender           0\n",
      "author_org_ID           0\n",
      "category_id             0\n",
      "dtype: int64\n",
      "Col: user_id\n",
      "109264 \t 109264\n",
      "save\n",
      "\n",
      "\n",
      "Col: challenge_sequence\n",
      "13 \t 13\n",
      "save\n",
      "\n",
      "\n",
      "Col: challenge\n",
      "5606 \t 5606\n",
      "save\n",
      "\n",
      "\n",
      "Col: programming_language\n",
      "3 \t 3\n",
      "save\n",
      "\n",
      "\n",
      "Col: challenge_series_ID\n",
      "436 \t 436\n",
      "save\n",
      "\n",
      "\n",
      "Col: author_ID\n",
      "3485 \t 3485\n",
      "save\n",
      "\n",
      "\n",
      "Col: author_gender\n",
      "3 \t 3\n",
      "save\n",
      "\n",
      "\n",
      "Col: author_org_ID\n",
      "1718 \t 1718\n",
      "save\n",
      "\n",
      "\n",
      "Col: category_id\n",
      "195 \t 195\n",
      "save\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# id mapping for categorical variables\n",
    "df_challenge.rename(columns={'challenge_ID': 'challenge'}, inplace=True)\n",
    "df_challenge.fillna(value={'challenge_series_ID': 'missing',\n",
    "                           'author_ID': 'missing',\n",
    "                           'author_gender': 'missing',\n",
    "                           'author_org_ID': 'missing'}, inplace=True)\n",
    "df_challenge.fillna(value={\n",
    "    'total_submissions': 0, 'programming_language': 0,\n",
    "    'category_id': 0}, inplace=True)\n",
    "print(df_challenge.isnull().sum())\n",
    "\n",
    "for col in CATEGORICAL_VARS:\n",
    "    print('Col: %s' % (col))\n",
    "    if col in ('user_id', 'challenge_sequence'):\n",
    "        values = df[col].unique().tolist()\n",
    "    else:\n",
    "        values = df_challenge[col].unique().tolist()\n",
    "    value2idx = {value: idx for idx, value in enumerate(values)}\n",
    "    idx2value = {idx: value for idx, value in enumerate(values)}\n",
    "    \n",
    "    print(len(value2idx), '\\t', len(idx2value))\n",
    "    \n",
    "    print('save')\n",
    "    value2idx_fn = os.path.join(INTERIM_DIR, '{}2idx.json'.format(col))\n",
    "    idx2value_fn = os.path.join(INTERIM_DIR, 'idx2{}.json'.format(col))\n",
    "    json.dump(value2idx, open(value2idx_fn, 'w'))\n",
    "    json.dump(idx2value, open(idx2value_fn, 'w'))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling for baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "TEST_USER_PROPORTION = 0.1\n",
    "SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col: user_id\n",
      "Col: challenge\n"
     ]
    }
   ],
   "source": [
    "# mapping discrete cols to mapped id cols\n",
    "\n",
    "baseline_df = df.copy()\n",
    "\n",
    "for col in ['user_id', 'challenge']:\n",
    "    print('Col: %s' % (col))\n",
    "    value2idx_fn = os.path.join(INTERIM_DIR, '{}2idx.json'.format(col))\n",
    "    d = json.load(open(value2idx_fn))\n",
    "    baseline_df[col] = baseline_df[col].apply(lambda x: d[str(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280377, 5) \t (20859, 5)\n",
      "109264 \t 6953\n"
     ]
    }
   ],
   "source": [
    "# sampling\n",
    "\n",
    "mask = baseline_df['sample'] == 'train'\n",
    "users = baseline_df.loc[mask, 'user_id'].unique().tolist()\n",
    "np.random.seed(SEED)\n",
    "users = list(np.random.permutation(users))\n",
    "num_val_users = int(TEST_USER_PROPORTION*len(users))\n",
    "val_users = users[:num_val_users]\n",
    "\n",
    "mask1 = baseline_df['user_id'].isin(val_users)\n",
    "mask2 = baseline_df['challenge_sequence'].isin([11, 12, 13])\n",
    "val_df = baseline_df.loc[mask1&mask2, :]\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "dev_df = baseline_df.loc[~(mask1&mask2), :]\n",
    "dev_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(dev_df.shape, '\\t', val_df.shape)\n",
    "print(dev_df['user_id'].nunique(), '\\t', val_df['user_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6953\n"
     ]
    }
   ],
   "source": [
    "# get actual items dct on val sample for mapk calculation\n",
    "tmp = val_df.groupby('user_id')['challenge'].apply(list).rename(\n",
    "    'challenge_lst').reset_index()\n",
    "val_actual_items_dct = dict(zip(tmp['user_id'], tmp['challenge_lst']))\n",
    "print(len(val_actual_items_dct))\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109264\n"
     ]
    }
   ],
   "source": [
    "# get seen items dct for mapk calculation\n",
    "tmp = dev_df.groupby('user_id')['challenge'].apply(list).rename(\n",
    "    'challenge_lst').reset_index()\n",
    "seen_items_dct = dict(zip(tmp['user_id'], tmp['challenge_lst']))\n",
    "print(len(seen_items_dct))\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109264\n"
     ]
    }
   ],
   "source": [
    "# get seen items dct for mapk calculation\n",
    "tmp = baseline_df.groupby('user_id')['challenge'].apply(list).rename(\n",
    "    'challenge_lst').reset_index()\n",
    "seen_items_dct_all = dict(zip(tmp['user_id'], tmp['challenge_lst']))\n",
    "print(len(seen_items_dct_all))\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "dev_fn = os.path.join(INTERIM_DIR, 'baseline_dev_df.csv')\n",
    "val_fn = os.path.join(INTERIM_DIR, 'baseline_val_df.csv')\n",
    "val_actual_items_dct_fn = os.path.join(INTERIM_DIR,\n",
    "                                       'val_actual_items_dct.json')\n",
    "seen_items_dct_fn = os.path.join(INTERIM_DIR, 'seen_items_dct.json')\n",
    "seen_items_dct_all_fn = os.path.join(INTERIM_DIR, 'seen_items_dct_all.json')\n",
    "dev_df.to_csv(dev_fn, index=False)\n",
    "val_df.to_csv(val_fn, index=False)\n",
    "json.dump(val_actual_items_dct, open(val_actual_items_dct_fn, 'w'))\n",
    "json.dump(seen_items_dct, open(seen_items_dct_fn, 'w'))\n",
    "json.dump(seen_items_dct_all, open(seen_items_dct_all_fn, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "N_USERS = 109264\n",
    "N_ITEMS = 5606\n",
    "BATCH_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "dev_fn = os.path.join(INTERIM_DIR, 'baseline_dev_df.csv')\n",
    "val_fn = os.path.join(INTERIM_DIR, 'baseline_val_df.csv')\n",
    "val_actual_items_dct_fn = os.path.join(INTERIM_DIR,\n",
    "                                       'val_actual_items_dct.json')\n",
    "seen_items_dct_fn = os.path.join(INTERIM_DIR, 'seen_items_dct.json')\n",
    "dev_df = pd.read_csv(dev_fn)\n",
    "val_df = pd.read_csv(val_fn)\n",
    "val_actual_items_dct = json.load(open(val_actual_items_dct_fn))\n",
    "seen_items_dct = json.load(open(seen_items_dct_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ids to int in dicts\n",
    "val_actual_items_dct = {int(idx): val for idx, val in\n",
    "                        val_actual_items_dct.items()}\n",
    "seen_items_dct = {int(idx): val for idx, val in seen_items_dct.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loader\n",
    "\n",
    "from torchmf import PairwiseInteractions\n",
    "from scipy import sparse as sp\n",
    "\n",
    "def get_interactions(data, n_users, n_items):\n",
    "\n",
    "    interactions = np.zeros((n_users, n_items))\n",
    "    for _, row in data.iterrows():\n",
    "        interactions[row['user_id'], row['challenge']] = 1\n",
    "    return sp.coo_matrix(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 39s, sys: 3.74 s, total: 2min 42s\n",
      "Wall time: 2min 43s\n",
      "CPU times: user 8.28 s, sys: 1.96 s, total: 10.2 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%time dev_interactions = get_interactions(dev_df, N_USERS, N_ITEMS)\n",
    "%time val_interactions = get_interactions(val_df, N_USERS, N_ITEMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.1 ms, sys: 9.04 ms, total: 30.1 ms\n",
      "Wall time: 28.4 ms\n",
      "CPU times: user 91 µs, sys: 1 µs, total: 92 µs\n",
      "Wall time: 97 µs\n",
      "CPU times: user 1.65 ms, sys: 450 µs, total: 2.1 ms\n",
      "Wall time: 1.88 ms\n",
      "CPU times: user 45 µs, sys: 1 µs, total: 46 µs\n",
      "Wall time: 49.1 µs\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "%time dev_loader = PairwiseInteractions(dev_interactions)\n",
    "%time dev_loader = DataLoader(dev_loader, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "%time val_loader = PairwiseInteractions(val_interactions)\n",
    "%time val_loader = DataLoader(val_loader, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network\n",
    "\n",
    "from torchmf import BPRModule\n",
    "model = BPRModule(n_users=N_USERS, n_items=N_ITEMS, n_factors=100,\n",
    "                  dropout_p=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPRModule(\n",
       "  (pred_model): BaseModule(\n",
       "    (user_biases): Embedding(109264, 1)\n",
       "    (item_biases): Embedding(5606, 1)\n",
       "    (user_embeddings): Embedding(109264, 100)\n",
       "    (item_embeddings): Embedding(5606, 100)\n",
       "    (dropout): Dropout(p=0.7, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training class\n",
    "\n",
    "from training import Step\n",
    "from torchmf import bpr_loss\n",
    "net = Step(model=model, actual_items_dct=val_actual_items_dct,\n",
    "           seen_items_dct=seen_items_dct, loss_function=bpr_loss,\n",
    "           lr=0.03, weight_decay=0.05, batch_size=BATCH_SIZE,\n",
    "           num_predictions=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280377 \t 20859 \t 2560\n"
     ]
    }
   ],
   "source": [
    "train_size, test_size = dev_df.shape[0], val_df.shape[0]\n",
    "print(train_size, '\\t', test_size, '\\t', train_size//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2560 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2561it [19:04,  1.48it/s]                          \n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation begins...\n",
      "validation with mapk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:23,  1.82it/s]                        \n",
      "  0%|          | 0/2560 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'train_loss': tensor([0.1106]), 'val_mapk': 0.01197724403534845, 'val_loss': tensor(0.1179)}\n",
      "Training begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2561it [28:37,  1.37it/s]                          \n",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation begins...\n",
      "validation with mapk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:22,  1.89it/s]                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 2, 'train_loss': tensor([0.1024]), 'val_mapk': 0.011697588570880674, 'val_loss': tensor(0.1177)}\n",
      "time taken: 2907.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "net.batch_fit(train_loader=dev_loader, test_loader=val_loader,\n",
    "              train_size=train_size, test_size=test_size, calc_mapk=True,\n",
    "              epochs=2)\n",
    "print('time taken: %0.2f' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'epoch': 1,\n",
       "  'train_loss': tensor([0.1308]),\n",
       "  'val_mapk': 0.012025184972114354,\n",
       "  'val_loss': tensor(0.1374)},\n",
       " {'epoch': 2,\n",
       "  'train_loss': tensor([0.1229]),\n",
       "  'val_mapk': 0.011841411381178387,\n",
       "  'val_loss': tensor(0.1384)},\n",
       " {'epoch': 3,\n",
       "  'train_loss': tensor([0.1228]),\n",
       "  'val_mapk': 0.011681608258625372,\n",
       "  'val_loss': tensor(0.1381)}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = dev_df.iloc[0]\n",
    "row['challenge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
