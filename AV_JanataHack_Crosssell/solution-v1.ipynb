{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, joblib, math, time\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from itertools import combinations\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "import operator\n",
    "\n",
    "# GLOBALS\n",
    "LOCAL_ROOT = '/kaggle/input/jha-cross-sell/'\n",
    "OUT_DIR = '/kaggle/working/'\n",
    "TRAIN_FN = os.path.join(LOCAL_ROOT, 'train.csv')\n",
    "TEST_FN = os.path.join(LOCAL_ROOT, 'test.csv')\n",
    "SUBMISSION_FN = os.path.join(LOCAL_ROOT, 'sample_submission_iA3afxn.csv')\n",
    "\n",
    "\n",
    "def getCountVar(compute_df, count_df, var_name, count_var):\n",
    "    \"\"\"\n",
    "    compute_df : Data frame for which the count encoding should be done\n",
    "    count_df : Data frame from which the counts should be taken\n",
    "    var_name : categorical variable for count encoding\n",
    "    count_var : some other variable from the dataset (used as dummy variable to get count)\n",
    "    \"\"\"\n",
    "    grouped_df = count_df.groupby(var_name, as_index=False)[count_var].agg('count')\n",
    "    grouped_df.columns = [var_name, \"var_count\"]\n",
    "    merged_df = pd.merge(compute_df, grouped_df, how=\"left\", on=var_name)\n",
    "    merged_df.fillna(-1, inplace=True)\n",
    "    return list(merged_df[\"var_count\"])\n",
    "\n",
    "\n",
    "def getDVEncodeVar(compute_df, target_df, var_name, target_var):\n",
    "    if type(var_name) != type([]):\n",
    "        var_name = [var_name]\n",
    "    grouped_df = target_df.groupby(var_name)[target_var].agg([\"mean\"]).reset_index()\n",
    "    grouped_df.columns = var_name + [\"mean_value\"]\n",
    "    merged_df = pd.merge(compute_df, grouped_df, how=\"left\", on=var_name)\n",
    "    merged_df.fillna(-1, inplace=True)\n",
    "    return list(merged_df[\"mean_value\"])\n",
    "\n",
    "\n",
    "def do_target_encode(train_df, test_df, cols_to_encode, target_col, encode_type, n_splits=3):\n",
    "        \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True,\n",
    "                               random_state=2020)\n",
    "    for col in cols_to_encode:\n",
    "        train_enc_values = np.zeros(train_df.shape[0])\n",
    "        test_enc_values = 0\n",
    "        for dev_index, val_index in kf.split(train_df):\n",
    "            new_train_df = train_df[[col, target_col]]\n",
    "            dev_X, val_X = new_train_df.iloc[dev_index], new_train_df.iloc[val_index]\n",
    "            \n",
    "            if encode_type == 'dv':\n",
    "                train_enc_values[val_index] =  np.array( \n",
    "                    getDVEncodeVar(val_X[[col]], dev_X, col, target_col))\n",
    "                test_enc_values += np.array( \n",
    "                    getDVEncodeVar(test_df[[col]], dev_X, col, target_col))\n",
    "            elif encode_type == 'count':\n",
    "                train_enc_values[val_index] =  np.array( \n",
    "                    getCountVar(val_X[[col]], dev_X, col, target_col))\n",
    "                test_enc_values += np.array( \n",
    "                    getCountVar(test_df[[col]], dev_X, col, target_col))\n",
    "        \n",
    "        test_enc_values /= n_splits\n",
    "        train_df[col + \"_{}_enc_{}\".format(encode_type, target_col)] = train_enc_values\n",
    "        test_df[col + \"_{}_enc_{}\".format(encode_type, target_col)] = test_enc_values\n",
    "        \n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def create_feature_map(features):\n",
    "    out_fn = os.path.join(OUT_DIR, 'xgb.fmap')\n",
    "    outfile = open(out_fn, 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, test_X2=None,\n",
    "           feature_names=None, seed_val=0, rounds=500, dep=8, eta=0.05):\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"binary:logistic\"\n",
    "    params['eval_metric'] = \"auc\"\n",
    "    params[\"eta\"] = eta\n",
    "    params[\"subsample\"] = 0.7\n",
    "    params[\"min_child_weight\"] = 1\n",
    "    params[\"colsample_bytree\"] = 0.7\n",
    "    params[\"max_depth\"] = dep\n",
    "\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"seed\"] = seed_val\n",
    "    # params[\"max_delta_step\"] = 2\n",
    "    # params[\"gamma\"] = 0.5\n",
    "    num_rounds = rounds\n",
    "\n",
    "    plst = list(params.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [(xgtrain, 'train'), (xgtest, 'test')]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist,\n",
    "                          early_stopping_rounds=100, verbose_eval=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    if feature_names is not None:\n",
    "        create_feature_map(feature_names)\n",
    "        xgb_model_fn = os.path.join(OUT_DIR, 'xgbmodel.txt')\n",
    "        xgb_fmap_fn = os.path.join(OUT_DIR, 'xgb.fmap')\n",
    "        xgb_imp_fn = os.path.join(OUT_DIR, 'imp_feat.txt')\n",
    "        model.dump_model(xgb_model_fn, xgb_fmap_fn, with_stats=True)\n",
    "        importance = model.get_fscore(fmap=xgb_fmap_fn)\n",
    "        importance = sorted(importance.items(), key=operator.itemgetter(1),\n",
    "                            reverse=True)\n",
    "        imp_df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "        imp_df['fscore'] = imp_df['fscore'] / imp_df['fscore'].sum()\n",
    "        imp_df.to_csv(xgb_imp_fn, index=False)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest,\n",
    "                                ntree_limit=model.best_ntree_limit)\n",
    "    if test_X2 is not None:\n",
    "        pred_test_y2 = model.predict(xgb.DMatrix(test_X2),\n",
    "                                     ntree_limit=model.best_ntree_limit)\n",
    "    else:\n",
    "        pred_test_y2 = None\n",
    "\n",
    "    loss = 0\n",
    "    if test_y is not None:\n",
    "        loss = metrics.roc_auc_score(test_y, pred_test_y)\n",
    "\n",
    "    return pred_test_y, loss, pred_test_y2\n",
    "\n",
    "\n",
    "def runLGB(train_X, train_y, test_X, test_y=None, test_X2=None,\n",
    "           feature_names=None, seed_val=0, rounds=500, dep=8, eta=0.05):\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"binary\"\n",
    "    params['metric'] = \"auc\"\n",
    "    params['seed'] = seed_val\n",
    "    params[\"max_depth\"] = dep\n",
    "    params[\"num_leaves\"] = 70\n",
    "    params[\"min_data_in_leaf\"] = 20\n",
    "    params[\"learning_rate\"] = eta\n",
    "    params[\"bagging_fraction\"] = 0.7\n",
    "    params[\"feature_fraction\"] = 0.7\n",
    "    params[\"bagging_freq\"] = 5\n",
    "    params[\"bagging_seed\"] = seed_val\n",
    "    params[\"verbosity\"] = 0\n",
    "    num_rounds = rounds\n",
    "\n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        lgtest = lgb.Dataset(test_X, label=test_y)\n",
    "        model = lgb.train(params, lgtrain, num_rounds, valid_sets=[lgtest],\n",
    "                          early_stopping_rounds=100, verbose_eval=20)\n",
    "    else:\n",
    "        lgtest = lgb.DMatrix(test_X)\n",
    "        model = lgb.train(params, lgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(test_X,\n",
    "                                num_iteration=model.best_iteration)\n",
    "    \n",
    "    if test_X2 is not None:\n",
    "        pred_test_y2 = model.predict(test_X2,\n",
    "                                     num_iteration=model.best_iteration)\n",
    "    else:\n",
    "        pred_test_y2 = None\n",
    "        \n",
    "    loss = 0\n",
    "    if test_y is not None:\n",
    "        loss = metrics.roc_auc_score(test_y, pred_test_y)\n",
    "\n",
    "    return pred_test_y, loss, pred_test_y2\n",
    "\n",
    "\n",
    "def trainModel(train_X, train_y, test_X, n_splits, model_name, feats, **params):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=2020)\n",
    "    cv_scores = []\n",
    "    pred_test_full = 0\n",
    "    pred_val_full = np.zeros(train_X.shape[0])\n",
    "    for dev_index, val_index in kf.split(train_X):\n",
    "        dev_X, val_X = train_X.iloc[dev_index, :], train_X.iloc[val_index, :]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "\n",
    "        if model_name == \"XGB\":\n",
    "            pred_val, acc, pred_test = runXGB(\n",
    "             dev_X, dev_y, val_X, val_y, test_X, rounds=params['rounds'],\n",
    "             dep=params['depth'], eta=params['eta'], feature_names=feats)\n",
    "        elif model_name == \"LGB\":\n",
    "            pred_val, acc, pred_test = runLGB(\n",
    "             dev_X, dev_y, val_X, val_y, test_X, rounds=params['rounds'],\n",
    "             dep=params['depth'], eta=params['eta'])\n",
    "        \n",
    "        cv_scores.append(acc)\n",
    "        pred_val_full[val_index] = pred_val\n",
    "        pred_test_full = pred_test_full + pred_test\n",
    "\n",
    "    pred_test_full /= n_splits\n",
    "    auc = metrics.roc_auc_score(train_y, pred_val_full)\n",
    "    return pred_val_full, auc, pred_test_full, cv_scores\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('JHA Cross Sell Competition...\\n')\n",
    "    \n",
    "    print('read data\\n')\n",
    "    df_train = pd.read_csv(TRAIN_FN)\n",
    "    df_test = pd.read_csv(TEST_FN)\n",
    "    \n",
    "    print('concat train and test\\n')\n",
    "    df_train['sample'] = 'train'\n",
    "    df_test['sample'] = 'test'\n",
    "    df_test['Response'] = None\n",
    "\n",
    "    cols = list(df_train.columns)\n",
    "    df = pd.concat([df_train[cols], df_test[cols]], axis=0)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print('mapping for categorical vars\\n')\n",
    "    cat_vars = ['Gender', 'Driving_License', 'Region_Code',\n",
    "                'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage',\n",
    "                'Policy_Sales_Channel']\n",
    "    le_pipes = []\n",
    "    for var in cat_vars:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[var].values)\n",
    "\n",
    "        df[var] = le.transform(df[var].values)\n",
    "        le_pipes.append((var, le))\n",
    "\n",
    "    print('categorize Age\\n')\n",
    "    min_age = int(math.ceil(df['Age'].min()/10.0))*10\n",
    "    max_age = int(math.ceil(df['Age'].max()/10.0))*10 + 10\n",
    "    age_map = list(range(min_age, max_age, 10))\n",
    "    df['Age_bucket'] = None\n",
    "    for i, v in enumerate(age_map):\n",
    "        mask1 = df['Age_bucket'].isnull()\n",
    "        mask2 = df['Age'] < v\n",
    "        df.loc[mask1&mask2, 'Age_bucket'] = i\n",
    "    \n",
    "    df['Age_bucket'] = df['Age_bucket'].astype(int)\n",
    "    assert df['Age_bucket'].isnull().sum() == 0\n",
    "    print(df.groupby('Age_bucket')['Age'].describe())\n",
    "    cat_vars.append('Age_bucket')\n",
    "    df['Response'] = df['Response'].astype(float)\n",
    "    \n",
    "    print('Ratio of Annual_Premium and Vintage\\n')\n",
    "    mask = df['Vintage'] != 0\n",
    "    df.loc[mask, 'Annual_Premium_RATIO_Vintage'] = list(map(\n",
    "        lambda x, y: 1.*x/y, df.loc[mask, 'Annual_Premium'],\n",
    "        df.loc[mask, 'Vintage']))\n",
    "    df.loc[~mask, 'Annual_Premium_RATIO_Vintage'] = -1\n",
    "    print(df['Annual_Premium_RATIO_Vintage'].describe())\n",
    "    \n",
    "    print('encoding cat_vars by aggregating numeric vars\\n')\n",
    "    num_vars = ['Age', 'Annual_Premium', 'Vintage', 'Annual_Premium_RATIO_Vintage']\n",
    "    for cat_var in cat_vars:\n",
    "        for num_var in num_vars:\n",
    "            for func in ['mean', 'sum', 'min', 'max', 'nunique', 'std']:\n",
    "                feat_name = '_'.join([func, num_var, 'per', cat_var])\n",
    "                print(feat_name)\n",
    "                df[feat_name] = df.groupby([cat_var])[num_var].transform(func)\n",
    "                print('\\n')\n",
    "                \n",
    "    print('count encodings for cat vars\\n')\n",
    "    for cat_var in cat_vars:\n",
    "        print(cat_var)\n",
    "        df[cat_var+'_count'] = df.groupby(cat_var)['Age'].transform('count')\n",
    "        \n",
    "    print('encoding cat_vars interactions by aggregating numeric vars\\n')\n",
    "    iter_cat_vars = list(combinations(cat_vars, 2))\n",
    "    for f1, f2 in iter_cat_vars:\n",
    "        for num_var in num_vars:\n",
    "            for func in ['mean', 'sum', 'min', 'max', 'nunique', 'std']:\n",
    "                feat_name = '_'.join([func, num_var, 'per', f1, f2])\n",
    "                print(feat_name)\n",
    "                df[feat_name] = df.groupby([f1, f2])[num_var].transform(func)\n",
    "                print('\\n')\n",
    "    \n",
    "    print('rank features\\n')\n",
    "    for col in ['Region_Code', 'Policy_Sales_Channel', 'Age_bucket']:\n",
    "        for func in ['first', 'average', 'max', 'min']:\n",
    "            feat_name = 'rank_{}_{}'.format(col, func)\n",
    "            if feat_name in df:\n",
    "                continue\n",
    "            print(feat_name)\n",
    "            df[feat_name] = df.groupby(col)[col].rank(method=func, ascending=True)\n",
    "            \n",
    "    print('rank features based on interactions\\n')\n",
    "    for f1, f2 in [('Policy_Sales_Channel', 'Region_Code')]:\n",
    "        for func in ['first', 'average', 'max', 'min']:\n",
    "            feat_name = 'rank_{}_{}_{}'.format(f1, f2, func)\n",
    "            print(feat_name)\n",
    "            df[feat_name] = df.groupby([f1, f2])[f1].rank(method=func, ascending=True)\n",
    "            \n",
    "    print('rank features based on interactions and numeric vars aggregation\\n')\n",
    "    for f1, f2 in [('Policy_Sales_Channel', 'Region_Code')]:\n",
    "        for col in ['Age', 'Annual_Premium', 'Vintage', 'Annual_Premium_RATIO_Vintage']:\n",
    "            for func in ['first', 'average', 'max', 'min']:\n",
    "                feat_name = 'rank_{}_{}_{}_{}'.format(f1, f2, col, func)\n",
    "                print(feat_name)\n",
    "                df[feat_name] = df.groupby([f1, f2])[col].rank(method=func, ascending=True)\n",
    "                \n",
    "    print('split df into train and test\\n')\n",
    "    mask = df['sample'] == 'train'\n",
    "    df_train = df.loc[mask, :]\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_test = df.loc[~mask, :]\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "    df_test.drop('Response', axis=1, inplace=True)\n",
    "    \n",
    "    print('release memory\\n')\n",
    "    del df\n",
    "    \n",
    "    print('DV encodings\\n')\n",
    "    df_train, df_test = do_target_encode(df_train, df_test, cat_vars, 'Response', 'dv', 3)\n",
    "    \n",
    "    print('shape ', df_train.shape, '\\t', df_test.shape)\n",
    "    \n",
    "    print('drop certain columns\\n')\n",
    "    drop_cols = cat_vars + ['sample']\n",
    "    df_train.drop(drop_cols, axis=1, inplace=True)\n",
    "    df_test.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "    print('shape ', df_train.shape, '\\t', df_test.shape)\n",
    "    \n",
    "    print('prefix for features\\n')\n",
    "    FEAT_PREFIX = 'JHA'\n",
    "    cols = list(df_train.columns)\n",
    "    new_cols = [FEAT_PREFIX + '_'+ col if col not in ('id', 'Response') else col for col in cols]\n",
    "    rename_dct = dict(zip(cols, new_cols))\n",
    "    df_train.rename(columns=rename_dct, inplace=True)\n",
    "    df_test.rename(columns=rename_dct, inplace=True)\n",
    "    \n",
    "    df_train['Response'] = df_train['Response'].astype(int)\n",
    "    \n",
    "    print('prepare data for modelling\\n')\n",
    "    feat_cols = [x for x in list(df_train.columns) if x.startswith(FEAT_PREFIX)]\n",
    "    print('# features: ', len(feat_cols))\n",
    "    x_train = df_train[feat_cols]\n",
    "    y_train = df_train['Response']\n",
    "    x_test = df_test[feat_cols]\n",
    "    test_ids = df_test['id'].values\n",
    "    print('shape ', x_train.shape, x_test.shape)\n",
    "    \n",
    "    print('release memory\\n')\n",
    "    del df_train, df_test\n",
    "    \n",
    "    print('modelling begins...\\n')\n",
    "    print('XGB\\n')\n",
    "    params = {'rounds': 500, 'depth': 6, 'eta': 0.05}\n",
    "    start = time.time()\n",
    "    pred_val_full, auc, pred_test_full, cv_scores = trainModel(x_train, y_train, x_test, 3, \"XGB\", feat_cols, **params)\n",
    "    print('time taken: %0.2f' % (time.time() - start))\n",
    "    \n",
    "    print('cv scores: ', cv_scores)\n",
    "    print('Final CV AUC: ', auc)\n",
    "    \n",
    "    print('submission\\n')\n",
    "    out_df = pd.DataFrame({\"id\": test_ids})\n",
    "    out_df[\"Response\"] = pred_test_full\n",
    "    out_fn = os.path.join(OUT_DIR, 'pred_test_v4_xgb.csv')\n",
    "    out_df.to_csv(out_fn, index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
