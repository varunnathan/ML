{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Interest Network\n",
    "\n",
    "https://arxiv.org/pdf/1706.06978.pdf\n",
    "\n",
    "https://github.com/shenweichen/DeepCTR-Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from deepctr_torch.inputs import (DenseFeat, SparseFeat, VarLenSparseFeat,\n",
    "                                  get_feature_names)\n",
    "from deepctr_torch.models.din import DIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"src/\")\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare history movieIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.87 s, sys: 3.19 s, total: 10.1 s\n",
      "Wall time: 11.1 s\n",
      "CPU times: user 50.9 ms, sys: 36.6 ms, total: 87.4 ms\n",
      "Wall time: 89.5 ms\n"
     ]
    }
   ],
   "source": [
    "# read raw ratings data\n",
    "%time df_train = pd.read_hdf(TRAIN_FN.format(1), key='stage')\n",
    "%time df_test = pd.read_hdf(TEST_FN.format(1), key='stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userid mapping\n",
      "movieid mapping\n"
     ]
    }
   ],
   "source": [
    "# read user2idx and item2idx\n",
    "print('userid mapping')\n",
    "user2idx = json.load(open(USER2IDX_FN))\n",
    "df_train['mapped_user'] = df_train['User'].apply(\n",
    "    lambda x: user2idx[str(x)])\n",
    "df_test['mapped_user'] = df_test['User'].apply(\n",
    "    lambda x: user2idx[str(x)])\n",
    "del user2idx\n",
    "\n",
    "print('movieid mapping')\n",
    "item2idx = json.load(open(ITEM2IDX_FN))\n",
    "df_train['mapped_movie'] = df_train['Movie'].apply(\n",
    "    lambda x: item2idx[str(x)])\n",
    "df_test['mapped_movie'] = df_test['Movie'].apply(\n",
    "    lambda x: item2idx[str(x)])\n",
    "del item2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sort_values(by=['mapped_user', 'Date'], ascending=[True, True],\n",
    "                     inplace=True)\n",
    "df_test.sort_values(by=['mapped_user', 'Date'], ascending=[True, True],\n",
    "                     inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_last_timestamp(df):\n",
    "    user, movie = 'mapped_user', 'mapped_movie'\n",
    "    last = df[[user, movie]].groupby(\n",
    "        by=user, as_index=False).tail(1).copy()\n",
    "    last['last'] = 1\n",
    "    df = pd.merge(df, last, how='left', on=[user, movie])\n",
    "    df.loc[~df['last'].isnull(), 'last'] = 1\n",
    "    df.loc[df['last'].isnull(), 'last'] = 0\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = mark_last_timestamp(df_train)\n",
    "df_test = mark_last_timestamp(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17770\n"
     ]
    }
   ],
   "source": [
    "item2idx = json.load(open(ITEM2IDX_FN))\n",
    "candidate_movie_ids = list(item2idx.values())\n",
    "del item2idx\n",
    "print(len(candidate_movie_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_sampling(candidates, filters, length):\n",
    "    max_len = len(candidates)\n",
    "    \n",
    "    res = []\n",
    "    for i in range(length):\n",
    "        while(1):\n",
    "            c = candidates[np.random.randint(0, max_len)]\n",
    "            if c not in filters:\n",
    "                res.append(str(c))\n",
    "                filters.add(c)\n",
    "                break\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_hist_movie_ids(df, candidates, max_len=10):\n",
    "    hist_movie_ids = list()\n",
    "    neg_hist_movie_ids = list()\n",
    "    for _, group in df.groupby(by='mapped_user'):\n",
    "        tmp_hist_movie_ids = list()\n",
    "        for _, row in group.iterrows():\n",
    "            # keep high rated movies\n",
    "            if row['Rating'] >= 4 and row['last'] == 0:\n",
    "                tmp_hist_movie_ids.append(str(int(row['mapped_movie'])))\n",
    "        # keep latest high rated movies\n",
    "        tmp_hist_movie_ids.reverse()\n",
    "        tmp_hist_movie_ids = tmp_hist_movie_ids[:max_len]\n",
    "        # revert to timestamp order\n",
    "        tmp_hist_movie_ids.reverse()\n",
    "        tmp_neg_hist_movie_ids = neg_sampling(\n",
    "            candidates, set(hist_movie_ids), len(tmp_hist_movie_ids))\n",
    "        hist_movie_ids.append('|'.join(tmp_hist_movie_ids))\n",
    "        neg_hist_movie_ids.append('|'.join(tmp_neg_hist_movie_ids))\n",
    "    return hist_movie_ids, neg_hist_movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "time taken: 14240.11\n",
      "test\n",
      "time taken: 295.01\n"
     ]
    }
   ],
   "source": [
    "print('train')\n",
    "start = time.time()\n",
    "train_hist_movie_ids, train_neg_hist_movie_ids = get_hist_movie_ids(\n",
    "    df_train, candidate_movie_ids, 10)\n",
    "print('time taken: %0.2f' % (time.time() - start))\n",
    "\n",
    "print('test')\n",
    "start = time.time()\n",
    "test_hist_movie_ids, test_neg_hist_movie_ids = get_hist_movie_ids(\n",
    "    df_test, candidate_movie_ids, 10)\n",
    "print('time taken: %0.2f' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469941 469941 4314|4431|405|2685|132|2657|2642|527|2456|413\n",
      "\n",
      "\n",
      "143001 143001 ['', '', '', '', '', '2464|3712', '2912', '', '4066', '', '', '', '3488|4097|2313', '3714', '', '', '', '787', '', '']\n"
     ]
    }
   ],
   "source": [
    "print(len(train_hist_movie_ids), len(train_neg_hist_movie_ids),\n",
    "      train_hist_movie_ids[0])\n",
    "print('\\n')\n",
    "print(len(test_hist_movie_ids), len(test_neg_hist_movie_ids),\n",
    "      test_hist_movie_ids[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/varunn/.virtualenvs/rasa/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/varunn/.virtualenvs/rasa/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/varunn/.virtualenvs/rasa/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/varunn/.virtualenvs/rasa/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "df_train1 = df_train[df_train['last'] == 1]\n",
    "df_train1['histHighRatedMovieIds'] = train_hist_movie_ids\n",
    "df_train1['negHistMovieIds'] = train_neg_hist_movie_ids\n",
    "\n",
    "df_test1 = df_test[df_test['last'] == 1]\n",
    "df_test1['histHighRatedMovieIds'] = test_hist_movie_ids\n",
    "df_test1['negHistMovieIds'] = test_neg_hist_movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(469941, 13) (143001, 13)\n",
      "469941 469941\n",
      "143001 143001\n"
     ]
    }
   ],
   "source": [
    "print(df_train1.shape, df_test1.shape)\n",
    "print(df_train1['mapped_user'].nunique(),\n",
    "      df_train['mapped_user'].nunique())\n",
    "print(df_test1['mapped_user'].nunique(),\n",
    "      df_test['mapped_user'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/varunn/.virtualenvs/rasa/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/varunn/.virtualenvs/rasa/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for col in ['histHighRatedMovieIds', 'negHistMovieIds']:\n",
    "    df_train1[col] = df_train1[col].apply(lambda x: x.split('|'))\n",
    "    df_test1[col] = df_test1[col].apply(lambda x: x.split('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mask_value(inp_lst, zero_val, max_len=10):\n",
    "    out_lst = []\n",
    "    for inp in inp_lst:\n",
    "        if inp == '':\n",
    "            out = 0\n",
    "        elif int(inp) == 0:\n",
    "            out = zero_val\n",
    "        elif int(inp) != 0:\n",
    "            out = int(inp)\n",
    "        out_lst.append(out)\n",
    "    length = len(out_lst)\n",
    "    if length == max_len:\n",
    "        return out_lst\n",
    "    else:\n",
    "        return out_lst + [0]*(max_len - length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - mapping zero in mapped_movie\n",
      "1\n",
      "test - mapping zero in mapped_movie\n",
      "1\n",
      "mapping zero in histHighRatedMovieIds and negHistMovieIds\n",
      "Col:  histHighRatedMovieIds\n",
      "\n",
      "\n",
      "Train:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/varunn/.virtualenvs/rasa/lib/python3.6/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/Users/varunn/.virtualenvs/rasa/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/varunn/.virtualenvs/rasa/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Col:  negHistMovieIds\n",
      "\n",
      "\n",
      "Train:\n",
      "\n",
      "\n",
      "\n",
      "Test:\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mask value = 0. So, replace movie id 0 with the max(candidate_movie_ids)\n",
    "\n",
    "print('train - mapping zero in mapped_movie')\n",
    "mask = df_train1['mapped_movie'] == 0\n",
    "df_train1.loc[mask, 'mapped_movie'] = max(candidate_movie_ids)+1\n",
    "print(df_train1['mapped_movie'].min())\n",
    "\n",
    "print('test - mapping zero in mapped_movie')\n",
    "mask = df_test1['mapped_movie'] == 0\n",
    "df_test1.loc[mask, 'mapped_movie'] = max(candidate_movie_ids)+1\n",
    "print(df_test1['mapped_movie'].min())\n",
    "\n",
    "print('mapping zero in histHighRatedMovieIds and negHistMovieIds')\n",
    "for col in ['histHighRatedMovieIds', 'negHistMovieIds']:\n",
    "    print('Col: ', col)\n",
    "    print('\\n')\n",
    "    print('Train:\\n')\n",
    "    df_train1[col] = df_train1[col].apply(\n",
    "        lambda x: add_mask_value(x, max(candidate_movie_ids)+1))\n",
    "    print('\\n')\n",
    "    print('Test:\\n')\n",
    "    df_test1[col] = df_test1[col].apply(\n",
    "        lambda x: add_mask_value(x, max(candidate_movie_ids)+1))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save dictionary for later use\n",
    "train_histHighRatedMovieIds = dict(zip(df_train1['mapped_user'],\n",
    "    df_train1['histHighRatedMovieIds']))\n",
    "test_histHighRatedMovieIds = dict(zip(df_test1['mapped_user'],\n",
    "    df_test1['histHighRatedMovieIds']))\n",
    "\n",
    "train_negHistMovieIds = dict(zip(df_train1['mapped_user'],\n",
    "    df_train1['negHistMovieIds']))\n",
    "test_negHistMovieIds = dict(zip(df_test1['mapped_user'],\n",
    "    df_test1['negHistMovieIds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_histHighRatedMovieIds\n",
      "\n",
      "train_negHistMovieIds\n",
      "\n",
      "test_histHighRatedMovieIds\n",
      "\n",
      "test_negHistMovieIds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "print('train_histHighRatedMovieIds\\n')\n",
    "out_fn = os.path.join(MOVIE_METADATA_DIR,\n",
    "                      'train_histHighRatedMovieIds.json')\n",
    "json.dump(train_histHighRatedMovieIds, open(out_fn, 'w'))\n",
    "\n",
    "print('train_negHistMovieIds\\n')\n",
    "out_fn = os.path.join(MOVIE_METADATA_DIR,\n",
    "                      'train_negHistMovieIds.json')\n",
    "json.dump(train_negHistMovieIds, open(out_fn, 'w'))\n",
    "\n",
    "print('test_histHighRatedMovieIds\\n')\n",
    "out_fn = os.path.join(MOVIE_METADATA_DIR,\n",
    "                      'test_histHighRatedMovieIds.json')\n",
    "json.dump(test_histHighRatedMovieIds, open(out_fn, 'w'))\n",
    "\n",
    "print('test_negHistMovieIds\\n')\n",
    "out_fn = os.path.join(MOVIE_METADATA_DIR,\n",
    "                      'test_negHistMovieIds.json')\n",
    "json.dump(test_negHistMovieIds, open(out_fn, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "N_USERS = 480189\n",
    "N_ITEMS = 17770\n",
    "HIST_LEN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train and test data\n",
    "train_fn = os.path.join(PREPARED_DATA_DIR, 'user_train_data_1.h5')\n",
    "df_train = pd.read_hdf(train_fn, key='stage')\n",
    "\n",
    "test_fn = os.path.join(PREPARED_DATA_DIR, 'user_test_data_1.h5')\n",
    "df_test = pd.read_hdf(test_fn, key='stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22851074, 20)\n",
      "(240538, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Rating_class</th>\n",
       "      <th>days_since_first_user_rating</th>\n",
       "      <th>sqrt_days_since_first_user_rating</th>\n",
       "      <th>rating_age_days_user</th>\n",
       "      <th>rating_age_weeks_user</th>\n",
       "      <th>rating_age_months_user</th>\n",
       "      <th>mean_ratings_user</th>\n",
       "      <th>num_ratings_user</th>\n",
       "      <th>days_since_first_item_rating</th>\n",
       "      <th>sqrt_days_since_first_item_rating</th>\n",
       "      <th>rating_age_days_item</th>\n",
       "      <th>rating_age_weeks_item</th>\n",
       "      <th>rating_age_months_item</th>\n",
       "      <th>mean_ratings_movie</th>\n",
       "      <th>weighted_mean_ratings_movie</th>\n",
       "      <th>num_ratings_movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161459</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2004-07-17</td>\n",
       "      <td>2138</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>4.795832</td>\n",
       "      <td>251</td>\n",
       "      <td>35.857143</td>\n",
       "      <td>8.366667</td>\n",
       "      <td>3.396365</td>\n",
       "      <td>28</td>\n",
       "      <td>1611</td>\n",
       "      <td>40.137264</td>\n",
       "      <td>2143</td>\n",
       "      <td>306.142857</td>\n",
       "      <td>71.433333</td>\n",
       "      <td>3.526814</td>\n",
       "      <td>3.527663</td>\n",
       "      <td>21220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2004-03-14</td>\n",
       "      <td>3253</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>617</td>\n",
       "      <td>88.142857</td>\n",
       "      <td>20.566667</td>\n",
       "      <td>4.333700</td>\n",
       "      <td>163</td>\n",
       "      <td>395</td>\n",
       "      <td>19.874607</td>\n",
       "      <td>1052</td>\n",
       "      <td>150.285714</td>\n",
       "      <td>35.066667</td>\n",
       "      <td>2.977046</td>\n",
       "      <td>2.979649</td>\n",
       "      <td>59554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191296</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2005-12-23</td>\n",
       "      <td>1154</td>\n",
       "      <td>0</td>\n",
       "      <td>453</td>\n",
       "      <td>21.283797</td>\n",
       "      <td>455</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>15.166667</td>\n",
       "      <td>3.955031</td>\n",
       "      <td>108</td>\n",
       "      <td>507</td>\n",
       "      <td>22.516660</td>\n",
       "      <td>514</td>\n",
       "      <td>73.428571</td>\n",
       "      <td>17.133333</td>\n",
       "      <td>3.818879</td>\n",
       "      <td>3.790705</td>\n",
       "      <td>1695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27266</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2004-09-26</td>\n",
       "      <td>1201</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3.872983</td>\n",
       "      <td>429</td>\n",
       "      <td>61.285714</td>\n",
       "      <td>14.300000</td>\n",
       "      <td>3.757806</td>\n",
       "      <td>124</td>\n",
       "      <td>1754</td>\n",
       "      <td>41.880783</td>\n",
       "      <td>2215</td>\n",
       "      <td>316.428571</td>\n",
       "      <td>73.833333</td>\n",
       "      <td>3.771652</td>\n",
       "      <td>3.771080</td>\n",
       "      <td>74899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175666</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2004-08-03</td>\n",
       "      <td>4377</td>\n",
       "      <td>0</td>\n",
       "      <td>446</td>\n",
       "      <td>21.118712</td>\n",
       "      <td>835</td>\n",
       "      <td>119.285714</td>\n",
       "      <td>27.833333</td>\n",
       "      <td>3.280928</td>\n",
       "      <td>51</td>\n",
       "      <td>565</td>\n",
       "      <td>23.769729</td>\n",
       "      <td>1080</td>\n",
       "      <td>154.285714</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>3.488060</td>\n",
       "      <td>3.518392</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     User  Rating       Date  Movie  Rating_class  \\\n",
       "0  161459     4.0 2004-07-17   2138             0   \n",
       "1   87375     2.0 2004-03-14   3253             0   \n",
       "2  191296     2.0 2005-12-23   1154             0   \n",
       "3   27266     5.0 2004-09-26   1201             1   \n",
       "4  175666     3.0 2004-08-03   4377             0   \n",
       "\n",
       "   days_since_first_user_rating  sqrt_days_since_first_user_rating  \\\n",
       "0                            23                           4.795832   \n",
       "1                            13                           3.605551   \n",
       "2                           453                          21.283797   \n",
       "3                            15                           3.872983   \n",
       "4                           446                          21.118712   \n",
       "\n",
       "   rating_age_days_user  rating_age_weeks_user  rating_age_months_user  \\\n",
       "0                   251              35.857143                8.366667   \n",
       "1                   617              88.142857               20.566667   \n",
       "2                   455              65.000000               15.166667   \n",
       "3                   429              61.285714               14.300000   \n",
       "4                   835             119.285714               27.833333   \n",
       "\n",
       "   mean_ratings_user  num_ratings_user  days_since_first_item_rating  \\\n",
       "0           3.396365                28                          1611   \n",
       "1           4.333700               163                           395   \n",
       "2           3.955031               108                           507   \n",
       "3           3.757806               124                          1754   \n",
       "4           3.280928                51                           565   \n",
       "\n",
       "   sqrt_days_since_first_item_rating  rating_age_days_item  \\\n",
       "0                          40.137264                  2143   \n",
       "1                          19.874607                  1052   \n",
       "2                          22.516660                   514   \n",
       "3                          41.880783                  2215   \n",
       "4                          23.769729                  1080   \n",
       "\n",
       "   rating_age_weeks_item  rating_age_months_item  mean_ratings_movie  \\\n",
       "0             306.142857               71.433333            3.526814   \n",
       "1             150.285714               35.066667            2.977046   \n",
       "2              73.428571               17.133333            3.818879   \n",
       "3             316.428571               73.833333            3.771652   \n",
       "4             154.285714               36.000000            3.488060   \n",
       "\n",
       "   weighted_mean_ratings_movie  num_ratings_movie  \n",
       "0                     3.527663              21220  \n",
       "1                     2.979649              59554  \n",
       "2                     3.790705               1695  \n",
       "3                     3.771080              74899  \n",
       "4                     3.518392                670  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add histmovieids to the dataframes\n",
    "inp_fn = os.path.join(MOVIE_METADATA_DIR,\n",
    "                      'train_histHighRatedMovieIds.json')\n",
    "train_histHighRatedMovieIds = json.load(open(inp_fn))\n",
    "\n",
    "inp_fn = os.path.join(MOVIE_METADATA_DIR,\n",
    "                      'test_histHighRatedMovieIds.json')\n",
    "test_histHighRatedMovieIds = json.load(open(inp_fn))\n",
    "\n",
    "df_train['histHighRatedMovieIds'] = df_train['User'].apply(\n",
    "    lambda x: train_histHighRatedMovieIds[str(x)])\n",
    "df_test['histHighRatedMovieIds'] = df_test['User'].apply(\n",
    "    lambda x: test_histHighRatedMovieIds[str(x)])\n",
    "del train_histHighRatedMovieIds, test_histHighRatedMovieIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - mapping zero in Movie col\n",
      "0\n",
      "1\n",
      "test - mapping zero in Movie col\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print('train - mapping zero in Movie col')\n",
    "print(df_train['Movie'].min())\n",
    "mask = df_train['Movie'] == 0\n",
    "df_train.loc[mask, 'Movie'] = N_ITEMS\n",
    "print(df_train['Movie'].min())\n",
    "\n",
    "print('test - mapping zero in Movie col')\n",
    "print(df_test['Movie'].min())\n",
    "mask = df_test['Movie'] == 0\n",
    "df_test.loc[mask, 'Movie'] = N_ITEMS\n",
    "print(df_test['Movie'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_since_first_item_rating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/varunn/.virtualenvs/rasa/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "sqrt_days_since_first_item_rating\n",
      "\n",
      "\n",
      "rating_age_days_item\n",
      "\n",
      "\n",
      "rating_age_weeks_item\n",
      "\n",
      "\n",
      "rating_age_months_item\n",
      "\n",
      "\n",
      "mean_ratings_movie\n",
      "\n",
      "\n",
      "weighted_mean_ratings_movie\n",
      "\n",
      "\n",
      "num_ratings_movie\n",
      "\n",
      "\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# save item baseline dict to create hist features\n",
    "dense_movie_features = [\n",
    "    'days_since_first_item_rating',\n",
    "    'sqrt_days_since_first_item_rating',\n",
    "    'rating_age_days_item', 'rating_age_weeks_item',\n",
    "    'rating_age_months_item', 'mean_ratings_movie',\n",
    "    'weighted_mean_ratings_movie', 'num_ratings_movie']\n",
    "\n",
    "d = {}\n",
    "for col in dense_movie_features:\n",
    "    print(col)\n",
    "    d[col] = {}\n",
    "    tmp = df_train[['Movie', col]]\n",
    "    tmp.drop_duplicates(inplace=True)\n",
    "    d[col] = dict(zip(tmp['Movie'], tmp[col]))\n",
    "    del tmp\n",
    "    print('\\n')\n",
    "    \n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(469941, 2)\n",
      "(1419479, 21)\n"
     ]
    }
   ],
   "source": [
    "# filter by latest timestamp\n",
    "tmp = df_train.groupby(['User'])['Date'].max().rename(\n",
    "    'Date').reset_index()\n",
    "print(tmp.shape)\n",
    "df_train = pd.merge(df_train, tmp, on=['User', 'Date'],\n",
    "                    how='inner')\n",
    "print(df_train.shape)\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_since_first_item_rating \n",
      "\n",
      "Train\n",
      "\n",
      "\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "sqrt_days_since_first_item_rating \n",
      "\n",
      "Train\n",
      "\n",
      "\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "rating_age_days_item \n",
      "\n",
      "Train\n",
      "\n",
      "\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "rating_age_weeks_item \n",
      "\n",
      "Train\n",
      "\n",
      "\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "rating_age_months_item \n",
      "\n",
      "Train\n",
      "\n",
      "\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "mean_ratings_movie \n",
      "\n",
      "Train\n",
      "\n",
      "\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "weighted_mean_ratings_movie \n",
      "\n",
      "Train\n",
      "\n",
      "\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "num_ratings_movie \n",
      "\n",
      "Train\n",
      "\n",
      "\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create hist feature for item baseline features\n",
    "def create_hist_feats_movie_baseline(baseline_dct, col, inp_lst):\n",
    "    out_lst = []\n",
    "    for inp in inp_lst:\n",
    "        if inp == 0:\n",
    "            out_lst.append(0)\n",
    "        else:\n",
    "            out_lst.append(baseline_dct[col][inp])\n",
    "    return out_lst\n",
    "\n",
    "\n",
    "for col in dense_movie_features:\n",
    "    print(col, '\\n')\n",
    "    print('Train\\n')\n",
    "    df_train['hist_'+col] = df_train['histHighRatedMovieIds'].apply(\n",
    "        lambda x: create_hist_feats_movie_baseline(d, col, x))\n",
    "    print('\\n')\n",
    "    print('Test\\n')\n",
    "    df_test['hist_'+col] = df_test['histHighRatedMovieIds'].apply(\n",
    "        lambda x: create_hist_feats_movie_baseline(d, col, x))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1419479, 29), (240538, 29))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train.drop(dense_movie_features, axis=1, inplace=True)\n",
    "#df_test.drop(dense_movie_features, axis=1, inplace=True)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = ['User', 'Movie']\n",
    "dense_features = [\n",
    "'days_since_first_user_rating',\n",
    "'sqrt_days_since_first_user_rating',\n",
    "'rating_age_days_user', 'rating_age_weeks_user',\n",
    "'rating_age_months_user', 'mean_ratings_user',\n",
    "'num_ratings_user', 'days_since_first_item_rating',\n",
    "'sqrt_days_since_first_item_rating',\n",
    "'rating_age_days_item', 'rating_age_weeks_item',\n",
    "'rating_age_months_item', 'mean_ratings_movie',\n",
    "'weighted_mean_ratings_movie', 'num_ratings_movie']\n",
    "hist_features = ['hist_Movie']\n",
    "target = 'Rating'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### simple Transformation for dense features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/varunn/.virtualenvs/rasa/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.71 s, sys: 1.75 s, total: 5.46 s\n",
      "Wall time: 5.56 s\n",
      "Test\n",
      "CPU times: user 541 ms, sys: 275 ms, total: 816 ms\n",
      "Wall time: 820 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "print('Train')\n",
    "%time df_train[dense_features] = mms.fit_transform(df_train[dense_features])\n",
    "\n",
    "print('Test')\n",
    "%time df_test[dense_features] = mms.transform(df_test[dense_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.rename(columns={'histHighRatedMovieIds': 'hist_Movie'},\n",
    "                inplace=True)\n",
    "df_test.rename(columns={'histHighRatedMovieIds': 'hist_Movie'},\n",
    "               inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features_count = [N_USERS, N_ITEMS+1]\n",
    "feature_columns = [SparseFeat(\n",
    "    name=feat, vocabulary_size=sparse_features_count[i],\n",
    "    embedding_dim=70) for i, feat in enumerate(sparse_features)]\n",
    "\n",
    "feature_columns += [DenseFeat(feat, 1) for feat in dense_features]\n",
    "\n",
    "feature_columns += [VarLenSparseFeat(\n",
    "    SparseFeat(name='hist_Movie', vocabulary_size=N_ITEMS+1,\n",
    "               embedding_dim=70), HIST_LEN)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeat(name='User', vocabulary_size=480189, embedding_dim=70, use_hash=False, dtype='int32', embedding_name='User', group_name='default_group'),\n",
       " SparseFeat(name='Movie', vocabulary_size=17771, embedding_dim=70, use_hash=False, dtype='int32', embedding_name='Movie', group_name='default_group'),\n",
       " DenseFeat(name='days_since_first_user_rating', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='sqrt_days_since_first_user_rating', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='rating_age_days_user', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='rating_age_weeks_user', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='rating_age_months_user', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='mean_ratings_user', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='num_ratings_user', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='days_since_first_item_rating', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='sqrt_days_since_first_item_rating', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='rating_age_days_item', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='rating_age_weeks_item', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='rating_age_months_item', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='mean_ratings_movie', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='weighted_mean_ratings_movie', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='num_ratings_movie', dimension=1, dtype='float32'),\n",
       " VarLenSparseFeat(sparsefeat=SparseFeat(name='hist_Movie', vocabulary_size=17771, embedding_dim=70, use_hash=False, dtype='int32', embedding_name='hist_Movie', group_name='default_group'), maxlen=10, combiner='mean', length_name=None)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_feature_list = [\"Movie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = get_feature_names(feature_columns)\n",
    "train_model_input = {name: np.array(df_train[name].values.tolist())\n",
    "                     for name in feature_names}\n",
    "test_model_input = {name: np.array(df_test[name].values.tolist())\n",
    "                    for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18 (1419479, 10)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_model_input), len(test_model_input),\n",
    "      train_model_input['hist_Movie'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = df_train[target].values\n",
    "test_y = df_test[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2782, 3105, 2199, ...,    0,    0,    0],\n",
       "        [2782, 3105, 2199, ...,    0,    0,    0],\n",
       "        [2782, 3105, 2199, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [1541, 4305,    0, ...,    0,    0,    0],\n",
       "        [  32,  667, 3522, ..., 4379, 3934, 2289],\n",
       "        [3924, 1328, 3289, ...,  196, 2371, 3281]]),\n",
       " array([3., 3., 4., ..., 4., 2., 5.]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model_input['hist_Movie'], test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DIN(feature_columns, behavior_feature_list, device=device,\n",
    "            task='regression', l2_reg_embedding=1e-3,\n",
    "            att_activation='Dice', dnn_use_bn=True, l2_reg_dnn=1e-3,\n",
    "            dnn_dropout=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIN(\n",
       "  (embedding_dict): ModuleDict(\n",
       "    (Movie): Embedding(17771, 70)\n",
       "    (User): Embedding(480189, 70)\n",
       "    (hist_Movie): Embedding(17771, 70)\n",
       "  )\n",
       "  (linear_model): Linear(\n",
       "    (embedding_dict): ModuleDict()\n",
       "  )\n",
       "  (out): PredictionLayer()\n",
       "  (attention): AttentionSequencePoolingLayer(\n",
       "    (local_att): LocalActivationUnit(\n",
       "      (dnn): DNN(\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=280, out_features=64, bias=True)\n",
       "          (1): Linear(in_features=64, out_features=16, bias=True)\n",
       "        )\n",
       "        (activation_layers): ModuleList(\n",
       "          (0): Sigmoid()\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (dense): Linear(in_features=16, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn): DNN(\n",
       "    (dropout): Dropout(p=0.4, inplace=False)\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=225, out_features=256, bias=True)\n",
       "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (bn): ModuleList(\n",
       "      (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation_layers): ModuleList(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn_linear): Linear(in_features=128, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", \"mse\", metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 1419479 samples, validate on 240538 samples, 474 steps per epoch\n",
      "Epoch 1/3\n",
      "597s - loss:  1.7025 - mse:  1.7016 - val_mse:  0.8657\n",
      "Epoch 2/3\n",
      "572s - loss:  0.7874 - mse:  0.7875 - val_mse:  1.0144\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-a1966fe1fb0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit(train_model_input, train_y,\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           validation_data = (test_model_input, test_y), verbose=2)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time taken: %0.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/rasa/lib/python3.6/site-packages/deepctr_torch/models/basemodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, initial_epoch, validation_split, validation_data, shuffle, use_double)\u001b[0m\n\u001b[1;32m    223\u001b[0m                         \u001b[0mtotal_loss_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/rasa/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(train_model_input, train_y,\n",
    "          batch_size = 3000, epochs = 3,\n",
    "          validation_data = (test_model_input, test_y), verbose=2)\n",
    "print('time taken: %0.2f' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('mse', <function mean_squared_error at 0x1361df950>)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9304300081145277"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(0.8657)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
