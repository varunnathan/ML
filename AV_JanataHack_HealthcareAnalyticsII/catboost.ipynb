{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, joblib, time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "LOCAL_ROOT = '/Users/nathvaru/Documents/personal/AV/janatahack_healthcare_analytics_II/'\n",
    "DATA_DIR = os.path.join(LOCAL_ROOT, 'data')\n",
    "TRAIN_FN = os.path.join(DATA_DIR, 'Train_hMYJ020/train.csv')\n",
    "TEST_FN = os.path.join(DATA_DIR, 'test.csv')\n",
    "SUBMISSION_FN = os.path.join(DATA_DIR, 'sample_submission_lfbv3c3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_train = pd.read_csv(TRAIN_FN)\n",
    "df_test = pd.read_csv(TEST_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['Hospital_code', 'Hospital_type_code',\n",
    "            'City_Code_Hospital', 'Hospital_region_code',\n",
    "            'Department', 'Ward_Type', 'Ward_Facility_Code',\n",
    "            'Bed Grade', 'City_Code_Patient',\n",
    "            'Type of Admission', 'Severity of Illness', 'Age']\n",
    "num_vars = ['Available Extra Rooms in Hospital',\n",
    "            'Visitors with Patient', 'Admission_Deposit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in Bed Grade and City_Code_Patient\n",
    "# with separate category\n",
    "df_train.fillna({'Bed Grade': -999, 'City_Code_Patient': -999},\n",
    "                inplace=True)\n",
    "df_test.fillna({'Bed Grade': -999, 'City_Code_Patient': -999},\n",
    "                inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hospital_type_code\n",
      "Hospital_region_code\n",
      "Department\n",
      "Ward_Type\n",
      "Ward_Facility_Code\n",
      "Type of Admission\n",
      "Severity of Illness\n",
      "Age\n"
     ]
    }
   ],
   "source": [
    "# preprocess cat_vars\n",
    "for var in cat_vars:\n",
    "    if df_train[var].dtypes == object:\n",
    "        print(var)\n",
    "        df_train[var] = df_train[var].apply(\n",
    "            lambda x: str(x).strip().replace(\" \", \"-\"))\n",
    "        df_test[var] = df_test[var].apply(\n",
    "            lambda x: str(x).strip().replace(\" \", \"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode target\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train['Stay'].values)\n",
    "\n",
    "df_train['DV'] = le.transform(df_train['Stay'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add prefix to all features\n",
    "FEAT_PREFIX = 'JHA'\n",
    "cols = list(df_test.columns)\n",
    "new_cols = [FEAT_PREFIX + '_'+ col.replace(\" \", \"-\")\n",
    "            if col not in ('case_id', 'Stay', 'DV') else col for col in cols]\n",
    "rename_dct = dict(zip(cols, new_cols))\n",
    "df_train.rename(columns=rename_dct, inplace=True)\n",
    "df_test.rename(columns=rename_dct, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier treatment and scaling for num_vars\n",
    "from utility import LegacyOutlierScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "PREPROCESS = {\n",
    "    'exoutscaler': LegacyOutlierScaler(),\n",
    "    'stdscaler': StandardScaler()\n",
    "}\n",
    "STEPS = ['exoutscaler', 'stdscaler']\n",
    "\n",
    "\n",
    "def preprocess(train, test, steps, features):\n",
    "    \"\"\"\n",
    "    imputation, outlier treatment and scaling\n",
    "    \"\"\"\n",
    "    train = train.copy()\n",
    "    test = test.copy()\n",
    "    other_cols = list(set(list(test.columns)) - set(features))\n",
    "    classic_steps = steps\n",
    "    steps = list(zip(steps, map(PREPROCESS.get, steps)))\n",
    "    datapipe = Pipeline(steps=steps)\n",
    "\n",
    "    x_dev = train[features].values\n",
    "    \n",
    "    print('fit')\n",
    "    datapipe.fit(x_dev)\n",
    "    \n",
    "    print('transform dataframe using pipeline')\n",
    "    print('train data:')\n",
    "    train1 = datapipe.transform(train[features].values)\n",
    "    train1 = pd.DataFrame(train1, columns=features)\n",
    "    train1 = pd.concat([train1, train[other_cols+['Stay', 'DV']]], axis=1)\n",
    "    print('test data:')\n",
    "    test1 = datapipe.transform(test[features].values)\n",
    "    test1 = pd.DataFrame(test1, columns=features)\n",
    "    test1 = pd.concat([test1, test[other_cols]], axis=1)\n",
    "    \n",
    "    # Create \"classic\" datapipe and store list of features\n",
    "    classic_pipe = Pipeline([(name, datapipe.named_steps[name])\n",
    "                             for name in classic_steps])\n",
    "    classic_pipe.feature_names = features\n",
    "\n",
    "    return train1, test1, classic_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "transform dataframe using pipeline\n",
      "train data:\n",
      "test data:\n"
     ]
    }
   ],
   "source": [
    "num_vars = [FEAT_PREFIX + '_'+ col.replace(\" \", \"-\") for col in num_vars]\n",
    "df_train_pre, df_test_pre, pipeline = preprocess(df_train, df_test, STEPS, num_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JHA_Hospital_code', 'JHA_Hospital_type_code', 'JHA_City_Code_Hospital', 'JHA_Hospital_region_code', 'JHA_Department', 'JHA_Ward_Type', 'JHA_Ward_Facility_Code', 'JHA_Bed-Grade', 'JHA_City_Code_Patient', 'JHA_Type-of-Admission', 'JHA_Severity-of-Illness', 'JHA_Age']\n",
      "[3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "cat_feats = [FEAT_PREFIX + '_'+ col.replace(\" \", \"-\") for col in cat_vars]\n",
    "print(cat_feats)\n",
    "feat_cols = [col for col in list(df_train_pre.columns) if col.startswith(FEAT_PREFIX)]\n",
    "cat_feats_indices = [i for i, col in enumerate(feat_cols) if col in cat_feats]\n",
    "print(cat_feats_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JHA_Hospital_code\n",
      "\n",
      "\n",
      "JHA_Hospital_type_code\n",
      "\n",
      "\n",
      "JHA_City_Code_Hospital\n",
      "\n",
      "\n",
      "JHA_Hospital_region_code\n",
      "\n",
      "\n",
      "JHA_Department\n",
      "\n",
      "\n",
      "JHA_Ward_Type\n",
      "\n",
      "\n",
      "JHA_Ward_Facility_Code\n",
      "\n",
      "\n",
      "JHA_Bed-Grade\n",
      "\n",
      "\n",
      "JHA_City_Code_Patient\n",
      "\n",
      "\n",
      "JHA_Type-of-Admission\n",
      "\n",
      "\n",
      "JHA_Severity-of-Illness\n",
      "\n",
      "\n",
      "JHA_Age\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# encode cat_feats\n",
    "\n",
    "le_feats = []\n",
    "for feat in cat_feats:\n",
    "    print(feat)\n",
    "    le_feat = LabelEncoder()\n",
    "    le_feat.fit(df_train_pre[feat].values)\n",
    "    df_train_pre[feat] = le_feat.transform(df_train_pre[feat].values)\n",
    "    df_test_pre[feat] = le_feat.transform(df_test_pre[feat].values)\n",
    "    le_feats.append((feat, le_feat))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train_pre[feat_cols]\n",
    "y_train = df_train_pre['DV']\n",
    "x_test = df_test_pre[feat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def runCatboost(train_X, train_y, test_X, test_y=None, test_X2=None, **params):\n",
    "    \n",
    "    # init model class\n",
    "    model = CatBoostClassifier(\n",
    "        iterations = params['iterations'],\n",
    "        learning_rate = params['lr'],\n",
    "        random_strength = params['random_strength'],\n",
    "        random_seed = 2020,\n",
    "        l2_leaf_reg = 3.0,\n",
    "        early_stopping_rounds = 100,\n",
    "        classes_count = 11,\n",
    "        depth = params['depth'],\n",
    "        loss_function = 'MultiClass',\n",
    "        eval_metric = 'Accuracy',\n",
    "        leaf_estimation_method = 'Newton'\n",
    "    )\n",
    "    \n",
    "    # fit\n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y), plot=params['plot'],\n",
    "              cat_features=params['cat_feats'])\n",
    "    \n",
    "    # predict\n",
    "    pred_val = model.predict(test_X)\n",
    "    if test_X2 is not None:\n",
    "        pred_test = model.predict(test_X2)\n",
    "    else:\n",
    "        pred_test = None\n",
    "        \n",
    "    loss = metrics.accuracy_score(test_y, pred_val)\n",
    "    \n",
    "    return pred_val, loss, pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def trainModel(train_X, train_y, test_X, n_splits, model_name, feats, **params):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=2020)\n",
    "    cv_scores = []\n",
    "    pred_test_full = []\n",
    "    pred_val_full = np.zeros(train_X.shape[0])\n",
    "    for dev_index, val_index in kf.split(train_X):\n",
    "        dev_X, val_X = train_X.iloc[dev_index, :], train_X.iloc[val_index, :]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "\n",
    "        if model_name == \"XGB\":\n",
    "            pred_val, acc, pred_test = runXGB(\n",
    "             dev_X, dev_y, val_X, val_y, test_X, rounds=params['rounds'],\n",
    "             dep=params['depth'], eta=params['eta'], feature_names=feats)\n",
    "        elif model_name == \"LGB\":\n",
    "            pred_val, acc, pred_test = runLGB(\n",
    "             dev_X, dev_y, val_X, val_y, test_X, rounds=params['rounds'],\n",
    "             dep=params['depth'], eta=params['eta'])\n",
    "        elif model_name == \"Catboost\":\n",
    "            pred_val, acc, pred_test = runCatboost(dev_X, dev_y, val_X, val_y, test_X,\n",
    "                                                   **params)\n",
    "        \n",
    "        cv_scores.append(acc)\n",
    "        pred_val_full[val_index] = pred_val\n",
    "        if pred_test is not None:\n",
    "            pred_test_full.append(pred_test)\n",
    "\n",
    "    #pred_test_full = pred_test_full/n_splits\n",
    "    acc = metrics.accuracy_score(train_y, pred_val_full)\n",
    "    return pred_val_full, acc, pred_test_full, cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3760716\ttest: 0.3769902\tbest: 0.3769902 (0)\ttotal: 6.66s\tremaining: 55m 25s\n",
      "1:\tlearn: 0.3796469\ttest: 0.3798542\tbest: 0.3798542 (1)\ttotal: 14.9s\tremaining: 1h 1m 54s\n",
      "2:\tlearn: 0.3802546\ttest: 0.3800049\tbest: 0.3800049 (2)\ttotal: 23.4s\tremaining: 1h 4m 29s\n",
      "3:\tlearn: 0.3809093\ttest: 0.3807963\tbest: 0.3807963 (3)\ttotal: 31.7s\tremaining: 1h 5m 34s\n",
      "4:\tlearn: 0.3813615\ttest: 0.3816442\tbest: 0.3816442 (4)\ttotal: 40.9s\tremaining: 1h 7m 24s\n",
      "5:\tlearn: 0.3813521\ttest: 0.3815499\tbest: 0.3816442 (4)\ttotal: 51.9s\tremaining: 1h 11m 14s\n",
      "6:\tlearn: 0.3874663\ttest: 0.3874381\tbest: 0.3874381 (6)\ttotal: 1m 2s\tremaining: 1h 13m 2s\n",
      "7:\tlearn: 0.3904057\ttest: 0.3910746\tbest: 0.3910746 (7)\ttotal: 1m 18s\tremaining: 1h 20m 3s\n",
      "8:\tlearn: 0.3924218\ttest: 0.3928645\tbest: 0.3928645 (8)\ttotal: 1m 30s\tremaining: 1h 22m 13s\n",
      "9:\tlearn: 0.3962749\ttest: 0.3965482\tbest: 0.3965482 (9)\ttotal: 1m 40s\tremaining: 1h 22m 22s\n",
      "10:\tlearn: 0.3966565\ttest: 0.3966329\tbest: 0.3966329 (10)\ttotal: 1m 52s\tremaining: 1h 23m 11s\n",
      "11:\tlearn: 0.3988987\ttest: 0.3992331\tbest: 0.3992331 (11)\ttotal: 2m\tremaining: 1h 21m 32s\n",
      "12:\tlearn: 0.3993415\ttest: 0.4000810\tbest: 0.4000810 (12)\ttotal: 2m 10s\tremaining: 1h 21m 43s\n",
      "13:\tlearn: 0.4005803\ttest: 0.4008818\tbest: 0.4008818 (13)\ttotal: 2m 21s\tremaining: 1h 21m 59s\n",
      "14:\tlearn: 0.4009148\ttest: 0.4014471\tbest: 0.4014471 (14)\ttotal: 2m 30s\tremaining: 1h 21m 2s\n",
      "15:\tlearn: 0.4019322\ttest: 0.4023986\tbest: 0.4023986 (15)\ttotal: 2m 39s\tremaining: 1h 20m 30s\n",
      "16:\tlearn: 0.4036139\ttest: 0.4034537\tbest: 0.4034537 (16)\ttotal: 2m 48s\tremaining: 1h 19m 59s\n",
      "17:\tlearn: 0.4055075\ttest: 0.4062423\tbest: 0.4062423 (17)\ttotal: 3m 1s\tremaining: 1h 20m 53s\n",
      "18:\tlearn: 0.4073069\ttest: 0.4074294\tbest: 0.4074294 (18)\ttotal: 3m 13s\tremaining: 1h 21m 49s\n",
      "19:\tlearn: 0.4088331\ttest: 0.4089839\tbest: 0.4089839 (19)\ttotal: 3m 25s\tremaining: 1h 22m 15s\n",
      "20:\tlearn: 0.4095208\ttest: 0.4092476\tbest: 0.4092476 (20)\ttotal: 3m 38s\tremaining: 1h 23m 3s\n",
      "21:\tlearn: 0.4104158\ttest: 0.4102086\tbest: 0.4102086 (21)\ttotal: 3m 49s\tremaining: 1h 23m 6s\n",
      "22:\tlearn: 0.4114945\ttest: 0.4112166\tbest: 0.4112166 (22)\ttotal: 4m 1s\tremaining: 1h 23m 18s\n",
      "23:\tlearn: 0.4129312\ttest: 0.4122247\tbest: 0.4122247 (23)\ttotal: 4m 11s\tremaining: 1h 23m 3s\n",
      "24:\tlearn: 0.4136096\ttest: 0.4131479\tbest: 0.4131479 (24)\ttotal: 4m 23s\tremaining: 1h 23m 27s\n",
      "25:\tlearn: 0.4138027\ttest: 0.4142784\tbest: 0.4142784 (25)\ttotal: 4m 40s\tremaining: 1h 25m 5s\n",
      "26:\tlearn: 0.4145328\ttest: 0.4152865\tbest: 0.4152865 (26)\ttotal: 4m 51s\tremaining: 1h 25m 6s\n",
      "27:\tlearn: 0.4148720\ttest: 0.4159365\tbest: 0.4159365 (27)\ttotal: 4m 59s\tremaining: 1h 24m 4s\n",
      "28:\tlearn: 0.4152724\ttest: 0.4160967\tbest: 0.4160967 (28)\ttotal: 5m 12s\tremaining: 1h 24m 27s\n",
      "29:\tlearn: 0.4157481\ttest: 0.4162474\tbest: 0.4162474 (29)\ttotal: 5m 21s\tremaining: 1h 24m\n",
      "30:\tlearn: 0.4161297\ttest: 0.4166902\tbest: 0.4166902 (30)\ttotal: 5m 35s\tremaining: 1h 24m 42s\n",
      "31:\tlearn: 0.4163087\ttest: 0.4168692\tbest: 0.4168692 (31)\ttotal: 5m 46s\tremaining: 1h 24m 31s\n",
      "32:\tlearn: 0.4169540\ttest: 0.4176323\tbest: 0.4176323 (32)\ttotal: 5m 58s\tremaining: 1h 24m 38s\n",
      "33:\tlearn: 0.4171660\ttest: 0.4177736\tbest: 0.4177736 (33)\ttotal: 6m 13s\tremaining: 1h 25m 17s\n",
      "34:\tlearn: 0.4174156\ttest: 0.4179809\tbest: 0.4179809 (34)\ttotal: 6m 25s\tremaining: 1h 25m 15s\n",
      "35:\tlearn: 0.4177218\ttest: 0.4182447\tbest: 0.4182447 (35)\ttotal: 6m 35s\tremaining: 1h 24m 54s\n",
      "36:\tlearn: 0.4180092\ttest: 0.4185273\tbest: 0.4185273 (36)\ttotal: 6m 43s\tremaining: 1h 24m 8s\n",
      "37:\tlearn: 0.4180987\ttest: 0.4185838\tbest: 0.4185838 (37)\ttotal: 6m 57s\tremaining: 1h 24m 40s\n",
      "38:\tlearn: 0.4183577\ttest: 0.4189701\tbest: 0.4189701 (38)\ttotal: 7m 14s\tremaining: 1h 25m 32s\n",
      "39:\tlearn: 0.4188429\ttest: 0.4194223\tbest: 0.4194223 (39)\ttotal: 7m 28s\tremaining: 1h 25m 56s\n",
      "40:\tlearn: 0.4191161\ttest: 0.4197238\tbest: 0.4197238 (40)\ttotal: 7m 50s\tremaining: 1h 27m 49s\n",
      "41:\tlearn: 0.4191444\ttest: 0.4197991\tbest: 0.4197991 (41)\ttotal: 8m 5s\tremaining: 1h 28m 10s\n",
      "42:\tlearn: 0.4195354\ttest: 0.4200912\tbest: 0.4200912 (42)\ttotal: 8m 17s\tremaining: 1h 28m 10s\n",
      "43:\tlearn: 0.4196531\ttest: 0.4201854\tbest: 0.4201854 (43)\ttotal: 8m 28s\tremaining: 1h 27m 51s\n",
      "44:\tlearn: 0.4199970\ttest: 0.4201006\tbest: 0.4201854 (43)\ttotal: 8m 41s\tremaining: 1h 27m 57s\n",
      "45:\tlearn: 0.4203456\ttest: 0.4203550\tbest: 0.4203550 (45)\ttotal: 8m 53s\tremaining: 1h 27m 46s\n",
      "46:\tlearn: 0.4205387\ttest: 0.4204398\tbest: 0.4204398 (46)\ttotal: 9m 6s\tremaining: 1h 27m 50s\n",
      "47:\tlearn: 0.4207742\ttest: 0.4206753\tbest: 0.4206753 (47)\ttotal: 9m 22s\tremaining: 1h 28m 21s\n",
      "48:\tlearn: 0.4208684\ttest: 0.4206941\tbest: 0.4206941 (48)\ttotal: 9m 33s\tremaining: 1h 27m 59s\n",
      "49:\tlearn: 0.4210380\ttest: 0.4208166\tbest: 0.4208166 (49)\ttotal: 9m 49s\tremaining: 1h 28m 21s\n",
      "50:\tlearn: 0.4213065\ttest: 0.4210616\tbest: 0.4210616 (50)\ttotal: 10m\tremaining: 1h 28m 5s\n",
      "51:\tlearn: 0.4217728\ttest: 0.4212971\tbest: 0.4212971 (51)\ttotal: 10m 13s\tremaining: 1h 28m 6s\n",
      "52:\tlearn: 0.4220413\ttest: 0.4217022\tbest: 0.4217022 (52)\ttotal: 10m 24s\tremaining: 1h 27m 50s\n",
      "53:\tlearn: 0.4221732\ttest: 0.4216551\tbest: 0.4217022 (52)\ttotal: 10m 38s\tremaining: 1h 27m 52s\n",
      "54:\tlearn: 0.4223428\ttest: 0.4218058\tbest: 0.4218058 (54)\ttotal: 10m 52s\tremaining: 1h 27m 56s\n",
      "55:\tlearn: 0.4224323\ttest: 0.4216457\tbest: 0.4218058 (54)\ttotal: 11m 5s\tremaining: 1h 27m 55s\n",
      "56:\tlearn: 0.4227102\ttest: 0.4215232\tbest: 0.4218058 (54)\ttotal: 11m 15s\tremaining: 1h 27m 31s\n",
      "57:\tlearn: 0.4231153\ttest: 0.4216362\tbest: 0.4218058 (54)\ttotal: 11m 27s\tremaining: 1h 27m 21s\n",
      "58:\tlearn: 0.4232472\ttest: 0.4217587\tbest: 0.4218058 (54)\ttotal: 11m 37s\tremaining: 1h 26m 50s\n",
      "59:\tlearn: 0.4234168\ttest: 0.4219566\tbest: 0.4219566 (59)\ttotal: 11m 47s\tremaining: 1h 26m 25s\n",
      "60:\tlearn: 0.4235864\ttest: 0.4219848\tbest: 0.4219848 (60)\ttotal: 11m 55s\tremaining: 1h 25m 48s\n",
      "61:\tlearn: 0.4238502\ttest: 0.4220602\tbest: 0.4220602 (61)\ttotal: 12m 5s\tremaining: 1h 25m 22s\n",
      "62:\tlearn: 0.4242553\ttest: 0.4223711\tbest: 0.4223711 (62)\ttotal: 12m 15s\tremaining: 1h 25m 4s\n",
      "63:\tlearn: 0.4243495\ttest: 0.4225689\tbest: 0.4225689 (63)\ttotal: 12m 25s\tremaining: 1h 24m 41s\n",
      "64:\tlearn: 0.4245285\ttest: 0.4226066\tbest: 0.4226066 (64)\ttotal: 12m 39s\tremaining: 1h 24m 44s\n",
      "65:\tlearn: 0.4248300\ttest: 0.4229081\tbest: 0.4229081 (65)\ttotal: 12m 49s\tremaining: 1h 24m 22s\n",
      "66:\tlearn: 0.4248535\ttest: 0.4230305\tbest: 0.4230305 (66)\ttotal: 12m 59s\tremaining: 1h 23m 56s\n",
      "67:\tlearn: 0.4249854\ttest: 0.4233509\tbest: 0.4233509 (67)\ttotal: 13m 14s\tremaining: 1h 24m 7s\n",
      "68:\tlearn: 0.4251503\ttest: 0.4236429\tbest: 0.4236429 (68)\ttotal: 13m 24s\tremaining: 1h 23m 45s\n",
      "69:\tlearn: 0.4252680\ttest: 0.4237371\tbest: 0.4237371 (69)\ttotal: 13m 39s\tremaining: 1h 23m 56s\n",
      "70:\tlearn: 0.4256260\ttest: 0.4237371\tbest: 0.4237371 (69)\ttotal: 13m 54s\tremaining: 1h 24m 4s\n",
      "71:\tlearn: 0.4258945\ttest: 0.4234733\tbest: 0.4237371 (69)\ttotal: 14m 31s\tremaining: 1h 26m 23s\n",
      "72:\tlearn: 0.4261819\ttest: 0.4235393\tbest: 0.4237371 (69)\ttotal: 14m 48s\tremaining: 1h 26m 35s\n",
      "73:\tlearn: 0.4264174\ttest: 0.4234451\tbest: 0.4237371 (69)\ttotal: 15m 3s\tremaining: 1h 26m 42s\n",
      "74:\tlearn: 0.4264833\ttest: 0.4235487\tbest: 0.4237371 (69)\ttotal: 15m 14s\tremaining: 1h 26m 23s\n",
      "75:\tlearn: 0.4266152\ttest: 0.4236712\tbest: 0.4237371 (69)\ttotal: 15m 32s\tremaining: 1h 26m 41s\n",
      "76:\tlearn: 0.4266011\ttest: 0.4239538\tbest: 0.4239538 (76)\ttotal: 15m 47s\tremaining: 1h 26m 42s\n",
      "77:\tlearn: 0.4269214\ttest: 0.4241234\tbest: 0.4241234 (77)\ttotal: 15m 58s\tremaining: 1h 26m 23s\n",
      "78:\tlearn: 0.4271475\ttest: 0.4242741\tbest: 0.4242741 (78)\ttotal: 16m 13s\tremaining: 1h 26m 26s\n",
      "79:\tlearn: 0.4273265\ttest: 0.4241987\tbest: 0.4242741 (78)\ttotal: 16m 31s\tremaining: 1h 26m 43s\n",
      "80:\tlearn: 0.4273077\ttest: 0.4242082\tbest: 0.4242741 (78)\ttotal: 16m 43s\tremaining: 1h 26m 33s\n",
      "81:\tlearn: 0.4275008\ttest: 0.4240669\tbest: 0.4242741 (78)\ttotal: 16m 55s\tremaining: 1h 26m 18s\n",
      "82:\tlearn: 0.4274961\ttest: 0.4240951\tbest: 0.4242741 (78)\ttotal: 17m 5s\tremaining: 1h 25m 51s\n",
      "83:\tlearn: 0.4276562\ttest: 0.4243118\tbest: 0.4243118 (83)\ttotal: 17m 17s\tremaining: 1h 25m 38s\n",
      "84:\tlearn: 0.4277693\ttest: 0.4242930\tbest: 0.4243118 (83)\ttotal: 17m 31s\tremaining: 1h 25m 34s\n",
      "85:\tlearn: 0.4278918\ttest: 0.4245285\tbest: 0.4245285 (85)\ttotal: 17m 41s\tremaining: 1h 25m 10s\n",
      "86:\tlearn: 0.4279389\ttest: 0.4244437\tbest: 0.4245285 (85)\ttotal: 17m 55s\tremaining: 1h 25m 3s\n",
      "87:\tlearn: 0.4280519\ttest: 0.4245285\tbest: 0.4245285 (85)\ttotal: 18m 8s\tremaining: 1h 24m 54s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88:\tlearn: 0.4281838\ttest: 0.4244625\tbest: 0.4245285 (85)\ttotal: 18m 21s\tremaining: 1h 24m 48s\n",
      "89:\tlearn: 0.4282545\ttest: 0.4245379\tbest: 0.4245379 (89)\ttotal: 18m 33s\tremaining: 1h 24m 34s\n",
      "90:\tlearn: 0.4283110\ttest: 0.4247263\tbest: 0.4247263 (90)\ttotal: 18m 47s\tremaining: 1h 24m 26s\n",
      "91:\tlearn: 0.4284005\ttest: 0.4246698\tbest: 0.4247263 (90)\ttotal: 18m 58s\tremaining: 1h 24m 9s\n",
      "92:\tlearn: 0.4286549\ttest: 0.4249901\tbest: 0.4249901 (92)\ttotal: 19m 11s\tremaining: 1h 24m 1s\n",
      "93:\tlearn: 0.4288480\ttest: 0.4251032\tbest: 0.4251032 (93)\ttotal: 19m 25s\tremaining: 1h 23m 55s\n",
      "94:\tlearn: 0.4287773\ttest: 0.4253481\tbest: 0.4253481 (94)\ttotal: 19m 40s\tremaining: 1h 23m 50s\n",
      "95:\tlearn: 0.4288244\ttest: 0.4254517\tbest: 0.4254517 (95)\ttotal: 19m 52s\tremaining: 1h 23m 39s\n",
      "96:\tlearn: 0.4290317\ttest: 0.4256684\tbest: 0.4256684 (96)\ttotal: 20m 6s\tremaining: 1h 23m 34s\n",
      "97:\tlearn: 0.4291683\ttest: 0.4254235\tbest: 0.4256684 (96)\ttotal: 20m 20s\tremaining: 1h 23m 25s\n",
      "98:\tlearn: 0.4291448\ttest: 0.4255365\tbest: 0.4256684 (96)\ttotal: 20m 35s\tremaining: 1h 23m 25s\n",
      "99:\tlearn: 0.4292248\ttest: 0.4255648\tbest: 0.4256684 (96)\ttotal: 20m 48s\tremaining: 1h 23m 15s\n",
      "100:\tlearn: 0.4293379\ttest: 0.4254988\tbest: 0.4256684 (96)\ttotal: 21m\tremaining: 1h 22m 58s\n",
      "101:\tlearn: 0.4295263\ttest: 0.4254046\tbest: 0.4256684 (96)\ttotal: 21m 12s\tremaining: 1h 22m 44s\n",
      "102:\tlearn: 0.4295310\ttest: 0.4255271\tbest: 0.4256684 (96)\ttotal: 21m 22s\tremaining: 1h 22m 24s\n",
      "103:\tlearn: 0.4296770\ttest: 0.4256119\tbest: 0.4256684 (96)\ttotal: 21m 36s\tremaining: 1h 22m 16s\n",
      "104:\tlearn: 0.4297430\ttest: 0.4254706\tbest: 0.4256684 (96)\ttotal: 21m 50s\tremaining: 1h 22m 10s\n",
      "105:\tlearn: 0.4298560\ttest: 0.4254517\tbest: 0.4256684 (96)\ttotal: 22m 6s\tremaining: 1h 22m 9s\n",
      "106:\tlearn: 0.4299832\ttest: 0.4255836\tbest: 0.4256684 (96)\ttotal: 22m 20s\tremaining: 1h 22m 4s\n",
      "107:\tlearn: 0.4301245\ttest: 0.4256119\tbest: 0.4256684 (96)\ttotal: 22m 34s\tremaining: 1h 21m 56s\n",
      "108:\tlearn: 0.4301245\ttest: 0.4256119\tbest: 0.4256684 (96)\ttotal: 22m 47s\tremaining: 1h 21m 46s\n",
      "109:\tlearn: 0.4302941\ttest: 0.4254612\tbest: 0.4256684 (96)\ttotal: 23m 8s\tremaining: 1h 22m 3s\n",
      "110:\tlearn: 0.4303318\ttest: 0.4254988\tbest: 0.4256684 (96)\ttotal: 23m 21s\tremaining: 1h 21m 52s\n",
      "111:\tlearn: 0.4304354\ttest: 0.4254706\tbest: 0.4256684 (96)\ttotal: 23m 36s\tremaining: 1h 21m 46s\n",
      "112:\tlearn: 0.4307086\ttest: 0.4255836\tbest: 0.4256684 (96)\ttotal: 23m 51s\tremaining: 1h 21m 40s\n",
      "113:\tlearn: 0.4309442\ttest: 0.4256402\tbest: 0.4256684 (96)\ttotal: 24m 4s\tremaining: 1h 21m 31s\n",
      "114:\tlearn: 0.4309583\ttest: 0.4257061\tbest: 0.4257061 (114)\ttotal: 24m 19s\tremaining: 1h 21m 25s\n",
      "115:\tlearn: 0.4310949\ttest: 0.4256590\tbest: 0.4257061 (114)\ttotal: 24m 29s\tremaining: 1h 21m 2s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-62b78868767b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m           'cat_feats': cat_feats_indices}\n\u001b[1;32m      3\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m pred_val, acc, pred_test = trainModel(x_train, y_train, x_test, 3, 'Catboost', feat_cols,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                       **params)\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time taken: %0.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-5bed2d927249>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(train_X, train_y, test_X, n_splits, model_name, feats, **params)\u001b[0m\n\u001b[1;32m     20\u001b[0m              dep=params['depth'], eta=params['eta'])\n\u001b[1;32m     21\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Catboost\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             pred_val, acc, pred_test = runCatboost(dev_X, dev_y, val_X, val_y, test_X,\n\u001b[0m\u001b[1;32m     23\u001b[0m                                                    **params)\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-dc65650ba3e6>\u001b[0m in \u001b[0;36mrunCatboost\u001b[0;34m(train_X, train_y, test_X, test_y, test_X2, **params)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     model.fit(train_X, train_y, eval_set=(test_X, test_y), plot=params['plot'],\n\u001b[0m\u001b[1;32m     24\u001b[0m               cat_features=params['cat_feats'])\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/py38/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   4288\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_classification_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4290\u001b[0;31m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[1;32m   4291\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4292\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n",
      "\u001b[0;32m~/.virtualenvs/py38/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1800\u001b[0;31m             self._train(\n\u001b[0m\u001b[1;32m   1801\u001b[0m                 \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/py38/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {'iterations': 500, 'lr': 0.1, 'random_strength': 0.1, 'depth': 7, 'plot': False,\n",
    "          'cat_feats': cat_feats_indices}\n",
    "start = time.time()\n",
    "pred_val, acc, pred_test = trainModel(x_train, y_train, x_test, 3, 'Catboost', feat_cols,\n",
    "                                      **params)\n",
    "print('time taken: %0.2f' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318438,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
