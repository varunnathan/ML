{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, joblib, time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "LOCAL_ROOT = '/Users/nathvaru/Documents/personal/AV/janatahack_healthcare_analytics_II/'\n",
    "DATA_DIR = os.path.join(LOCAL_ROOT, 'data')\n",
    "TRAIN_FN = os.path.join(DATA_DIR, 'Train_hMYJ020/train.csv')\n",
    "TEST_FN = os.path.join(DATA_DIR, 'test.csv')\n",
    "SUBMISSION_FN = os.path.join(DATA_DIR, 'sample_submission_lfbv3c3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_train = pd.read_csv(TRAIN_FN)\n",
    "df_test = pd.read_csv(TEST_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['Hospital_code', 'Hospital_type_code',\n",
    "            'City_Code_Hospital', 'Hospital_region_code',\n",
    "            'Department', 'Ward_Type', 'Ward_Facility_Code',\n",
    "            'Bed Grade', 'City_Code_Patient',\n",
    "            'Type of Admission', 'Severity of Illness', 'Age']\n",
    "num_vars = ['Available Extra Rooms in Hospital',\n",
    "            'Visitors with Patient', 'Admission_Deposit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in Bed Grade and City_Code_Patient\n",
    "# with separate category\n",
    "df_train.fillna({'Bed Grade': 'missing', 'City_Code_Patient': 'missing'},\n",
    "                inplace=True)\n",
    "df_test.fillna({'Bed Grade': 'missing', 'City_Code_Patient': 'missing'},\n",
    "                inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCountVar(compute_df, count_df, var_name, count_var):\n",
    "    \"\"\"\n",
    "    compute_df : Data frame for which the count encoding should be done\n",
    "    count_df : Data frame from which the counts should be taken\n",
    "    var_name : categorical variable for count encoding\n",
    "    count_var : some other variable from the dataset (used as dummy variable to get count)\n",
    "    \"\"\"\n",
    "    grouped_df = count_df.groupby(var_name, as_index=False)[count_var].agg('count')\n",
    "    grouped_df.columns = [var_name, \"var_count\"]\n",
    "    merged_df = pd.merge(compute_df, grouped_df, how=\"left\", on=var_name)\n",
    "    merged_df.fillna(-1, inplace=True)\n",
    "    return list(merged_df[\"var_count\"])\n",
    "\n",
    "\n",
    "def getDVEncodeVar(compute_df, target_df, var_name, target_var):\n",
    "    if type(var_name) != type([]):\n",
    "        var_name = [var_name]\n",
    "    grouped_df = target_df.groupby(var_name)[target_var].agg([\"mean\"]).reset_index()\n",
    "    grouped_df.columns = var_name + [\"mean_value\"]\n",
    "    merged_df = pd.merge(compute_df, grouped_df, how=\"left\", on=var_name)\n",
    "    merged_df.fillna(-1, inplace=True)\n",
    "    return list(merged_df[\"mean_value\"])\n",
    "\n",
    "\n",
    "def do_target_encode(train_df, test_df, cols_to_encode, target_col, encode_type, n_splits=3):\n",
    "        \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True,\n",
    "                               random_state=2020)\n",
    "    for col in cols_to_encode:\n",
    "        train_enc_values = np.zeros(train_df.shape[0])\n",
    "        test_enc_values = 0\n",
    "        for dev_index, val_index in kf.split(train_df):\n",
    "            new_train_df = train_df[[col, target_col]]\n",
    "            dev_X, val_X = new_train_df.iloc[dev_index], new_train_df.iloc[val_index]\n",
    "            \n",
    "            if encode_type == 'dv':\n",
    "                train_enc_values[val_index] =  np.array( \n",
    "                    getDVEncodeVar(val_X[[col]], dev_X, col, target_col))\n",
    "                test_enc_values += np.array( \n",
    "                    getDVEncodeVar(test_df[[col]], dev_X, col, target_col))\n",
    "            elif encode_type == 'count':\n",
    "                train_enc_values[val_index] =  np.array( \n",
    "                    getCountVar(val_X[[col]], dev_X, col, target_col))\n",
    "                test_enc_values += np.array( \n",
    "                    getCountVar(test_df[[col]], dev_X, col, target_col))\n",
    "        \n",
    "        test_enc_values /= n_splits\n",
    "        train_df[col + \"_{}_enc_{}\".format(encode_type, target_col)] = train_enc_values\n",
    "        test_df[col + \"_{}_enc_{}\".format(encode_type, target_col)] = test_enc_values\n",
    "        \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hospital_type_code\n",
      "Hospital_region_code\n",
      "Department\n",
      "Ward_Type\n",
      "Ward_Facility_Code\n",
      "Bed Grade\n",
      "City_Code_Patient\n",
      "Type of Admission\n",
      "Severity of Illness\n",
      "Age\n"
     ]
    }
   ],
   "source": [
    "# preprocess cat_vars\n",
    "for var in cat_vars:\n",
    "    if df_train[var].dtypes == object:\n",
    "        print(var)\n",
    "        df_train[var] = df_train[var].apply(\n",
    "            lambda x: str(x).strip().replace(\" \", \"-\").replace(\".\", \"\"))\n",
    "        df_test[var] = df_test[var].apply(\n",
    "            lambda x: str(x).strip().replace(\" \", \"-\").replace(\".\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier treatment and scaling for num_vars\n",
    "from utility import LegacyOutlierScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "PREPROCESS = {\n",
    "    'exoutscaler': LegacyOutlierScaler(),\n",
    "    'stdscaler': StandardScaler()\n",
    "}\n",
    "STEPS = ['exoutscaler', 'stdscaler']\n",
    "\n",
    "\n",
    "def preprocess(train, test, steps, features):\n",
    "    \"\"\"\n",
    "    imputation, outlier treatment and scaling\n",
    "    \"\"\"\n",
    "    train = train.copy()\n",
    "    test = test.copy()\n",
    "    other_cols = list(set(list(test.columns)) - set(features))\n",
    "    classic_steps = steps\n",
    "    steps = list(zip(steps, map(PREPROCESS.get, steps)))\n",
    "    datapipe = Pipeline(steps=steps)\n",
    "\n",
    "    x_dev = train[features].values\n",
    "    \n",
    "    print('fit')\n",
    "    datapipe.fit(x_dev)\n",
    "    \n",
    "    print('transform dataframe using pipeline')\n",
    "    print('train data:')\n",
    "    train1 = datapipe.transform(train[features].values)\n",
    "    train1 = pd.DataFrame(train1, columns=features)\n",
    "    train1 = pd.concat([train1, train[other_cols+['Stay']]], axis=1)\n",
    "    print('test data:')\n",
    "    test1 = datapipe.transform(test[features].values)\n",
    "    test1 = pd.DataFrame(test1, columns=features)\n",
    "    test1 = pd.concat([test1, test[other_cols]], axis=1)\n",
    "    \n",
    "    # Create \"classic\" datapipe and store list of features\n",
    "    classic_pipe = Pipeline([(name, datapipe.named_steps[name])\n",
    "                             for name in classic_steps])\n",
    "    classic_pipe.feature_names = features\n",
    "\n",
    "    return train1, test1, classic_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "transform dataframe using pipeline\n",
      "train data:\n",
      "test data:\n"
     ]
    }
   ],
   "source": [
    "df_train_pre, df_test_pre, pipeline = preprocess(df_train, df_test, STEPS, num_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode target\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train_pre['Stay'].values)\n",
    "\n",
    "df_train_pre['DV'] = le.transform(df_train_pre['Stay'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Col: Available Extra Rooms in Hospital\n",
      "\n",
      "\n",
      "Target Col: Visitors with Patient\n",
      "\n",
      "\n",
      "Target Col: Admission_Deposit\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# feature engineering\n",
    "# mean of numeric vars by certain cat_vars\n",
    "cat_vars_enc = ['Bed Grade', 'Age', 'Hospital_code', 'City_Code_Patient']\n",
    "num_vars_enc = ['Available Extra Rooms in Hospital', 'Visitors with Patient',\n",
    "                'Admission_Deposit']\n",
    "\n",
    "for target_col in num_vars_enc:\n",
    "    print('Target Col: %s' % (target_col))\n",
    "    df_train_pre, df_test_pre = do_target_encode(df_train_pre, df_test_pre, cat_vars_enc,\n",
    "                                                 target_col, 'dv', 3)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Extra Rooms in Hospital_Bed Grade_dv_enc_Available Extra Rooms in Hospital\n",
      "Train\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "Available Extra Rooms in Hospital_Age_dv_enc_Available Extra Rooms in Hospital\n",
      "Train\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "Available Extra Rooms in Hospital_Hospital_code_dv_enc_Available Extra Rooms in Hospital\n",
      "Train\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "Available Extra Rooms in Hospital_City_Code_Patient_dv_enc_Available Extra Rooms in Hospital\n",
      "Train\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "Visitors with Patient_Bed Grade_dv_enc_Visitors with Patient\n",
      "Train\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "Visitors with Patient_Age_dv_enc_Visitors with Patient\n",
      "Train\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "Visitors with Patient_Hospital_code_dv_enc_Visitors with Patient\n",
      "Train\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "Visitors with Patient_City_Code_Patient_dv_enc_Visitors with Patient\n",
      "Train\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "Admission_Deposit_Bed Grade_dv_enc_Admission_Deposit\n",
      "Train\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "Admission_Deposit_Age_dv_enc_Admission_Deposit\n",
      "Train\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "Admission_Deposit_Hospital_code_dv_enc_Admission_Deposit\n",
      "Train\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "Admission_Deposit_City_Code_Patient_dv_enc_Admission_Deposit\n",
      "Train\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ratio features\n",
    "\n",
    "def get_ratio_cols(a, b):\n",
    "    mask = (a.notnull()) & (b.notnull()) & (b != 0)\n",
    "    series = pd.Series([-999]*len(a))\n",
    "    series[mask] = list(map(lambda x, y: 1.*x/y, a[mask], b[mask]))\n",
    "    return series\n",
    "\n",
    "\n",
    "f1_f2_lst = [('Available Extra Rooms in Hospital',\n",
    "              'Bed Grade_dv_enc_Available Extra Rooms in Hospital'),\n",
    "             ('Available Extra Rooms in Hospital',\n",
    "              'Age_dv_enc_Available Extra Rooms in Hospital'),\n",
    "             ('Available Extra Rooms in Hospital',\n",
    "              'Hospital_code_dv_enc_Available Extra Rooms in Hospital'),\n",
    "             ('Available Extra Rooms in Hospital',\n",
    "              'City_Code_Patient_dv_enc_Available Extra Rooms in Hospital'),\n",
    "             ('Visitors with Patient', 'Bed Grade_dv_enc_Visitors with Patient'),\n",
    "             ('Visitors with Patient', 'Age_dv_enc_Visitors with Patient'),\n",
    "             ('Visitors with Patient', 'Hospital_code_dv_enc_Visitors with Patient'),\n",
    "             ('Visitors with Patient', 'City_Code_Patient_dv_enc_Visitors with Patient'),\n",
    "             ('Admission_Deposit', 'Bed Grade_dv_enc_Admission_Deposit'),\n",
    "             ('Admission_Deposit', 'Age_dv_enc_Admission_Deposit'),\n",
    "             ('Admission_Deposit', 'Hospital_code_dv_enc_Admission_Deposit'),\n",
    "             ('Admission_Deposit', 'City_Code_Patient_dv_enc_Admission_Deposit')]\n",
    "\n",
    "for f1, f2 in f1_f2_lst:\n",
    "    print('{}_{}'.format(f1, f2))\n",
    "    \n",
    "    print('Train\\n')\n",
    "    a, b = df_train_pre[f1], df_train_pre[f2]\n",
    "    name = f1 + '_RATIO_' + f2\n",
    "    df_train_pre[name] = get_ratio_cols(a, b)\n",
    "    \n",
    "    print('Test\\n')\n",
    "    a, b = df_test_pre[f1], df_test_pre[f2]\n",
    "    df_test_pre[name] = get_ratio_cols(a, b)\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((318438, 43), (137057, 41))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pre.shape, df_test_pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get dummies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathvaru/.virtualenvs/py38/lib/python3.8/site-packages/pandas/core/frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# OHE cat_vars\n",
    "\n",
    "df_train_pre['sample'] = 'train'\n",
    "df_test_pre['sample'] = 'test'\n",
    "cols = ['case_id', 'sample'] + cat_vars\n",
    "other_cols = [col for col in list(df_test_pre.columns) if col not in cols]\n",
    "tmp = pd.concat([df_train_pre[cols], df_test_pre[cols]], axis=0)\n",
    "tmp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('get dummies')\n",
    "tmp = pd.get_dummies(tmp, prefix=cat_vars, columns=cat_vars,\n",
    "                     prefix_sep='_', drop_first=True)\n",
    "\n",
    "mask = tmp['sample'] == 'train'\n",
    "train = tmp.loc[mask, :]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "train.drop('sample', axis=1, inplace=True)\n",
    "df_train_pre = pd.merge(df_train_pre[['case_id', 'Stay', 'DV']+other_cols], train,\n",
    "                        on='case_id')\n",
    "del train\n",
    "\n",
    "mask = tmp['sample'] == 'test'\n",
    "test = tmp.loc[mask, :]\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "test.drop('sample', axis=1, inplace=True)\n",
    "df_test_pre = pd.merge(df_test_pre[['case_id']+other_cols], test, on='case_id')\n",
    "del test\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add prefix to all features\n",
    "FEAT_PREFIX = 'JHA'\n",
    "cols = list(df_test_pre.columns)\n",
    "new_cols = [FEAT_PREFIX + '_'+ col.replace(\" \", \"-\")\n",
    "            if col not in ('case_id', 'Stay', 'DV') else col for col in cols]\n",
    "rename_dct = dict(zip(cols, new_cols))\n",
    "df_train_pre.rename(columns=rename_dct, inplace=True)\n",
    "df_test_pre.rename(columns=rename_dct, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pre.drop('JHA_patientid', axis=1, inplace=True)\n",
    "df_test_pre.drop('JHA_patientid', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case_id', 'Stay', 'DV', 'JHA_Available-Extra-Rooms-in-Hospital',\n",
       "       'JHA_Visitors-with-Patient', 'JHA_Admission_Deposit',\n",
       "       'JHA_Bed-Grade_dv_enc_Available-Extra-Rooms-in-Hospital',\n",
       "       'JHA_Age_dv_enc_Available-Extra-Rooms-in-Hospital',\n",
       "       'JHA_Hospital_code_dv_enc_Available-Extra-Rooms-in-Hospital',\n",
       "       'JHA_City_Code_Patient_dv_enc_Available-Extra-Rooms-in-Hospital',\n",
       "       ...\n",
       "       'JHA_Severity-of-Illness_Moderate', 'JHA_Age_11-20', 'JHA_Age_21-30',\n",
       "       'JHA_Age_31-40', 'JHA_Age_41-50', 'JHA_Age_51-60', 'JHA_Age_61-70',\n",
       "       'JHA_Age_71-80', 'JHA_Age_81-90', 'JHA_Age_91-100'],\n",
       "      dtype='object', length=147)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pre.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JHA_Visitors-with-Patient_JHA_Admission_Deposit\n",
      "Train\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n",
      "JHA_Visitors-with-Patient_JHA_Available-Extra-Rooms-in-Hospital\n",
      "Train\n",
      "\n",
      "Test\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ratio of num visitors and admission deposit\n",
    "for f1, f2 in [('JHA_Visitors-with-Patient', 'JHA_Admission_Deposit'),\n",
    "               ('JHA_Visitors-with-Patient', 'JHA_Available-Extra-Rooms-in-Hospital')]:\n",
    "    print('{}_{}'.format(f1, f2))\n",
    "    \n",
    "    print('Train\\n')\n",
    "    a, b = df_train_pre[f1], df_train_pre[f2]\n",
    "    name = f1 + '_RATIO_' + f2\n",
    "    df_train_pre[name] = get_ratio_cols(a, b)\n",
    "    \n",
    "    print('Test\\n')\n",
    "    a, b = df_test_pre[f1], df_test_pre[f2]\n",
    "    df_test_pre[name] = get_ratio_cols(a, b)\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n"
     ]
    }
   ],
   "source": [
    "feat_cols = [x for x in list(df_train_pre.columns) if x.startswith(FEAT_PREFIX)]\n",
    "print(len(feat_cols))\n",
    "x_train = df_train_pre[feat_cols]\n",
    "y_train = df_train_pre['DV']\n",
    "x_test = df_test_pre[feat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/py38/lib/python3.8/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_rfe_single_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         scores = parallel(\n\u001b[0m\u001b[1;32m    551\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             for train, test in cv.split(X, y, groups))\n",
      "\u001b[0;32m~/.virtualenvs/py38/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/py38/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/py38/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "svc = SVC(kernel=\"linear\", C=1)\n",
    "rfe = RFECV(estimator=svc, min_features_to_select=60, step=5, verbose=1, n_jobs=-1, cv=3)\n",
    "%time rfe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelling\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "import operator\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "\n",
    "def create_feature_map(features):\n",
    "    outfile = open('../model/xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, test_X2=None,\n",
    "           feature_names=None, seed_val=0, rounds=500, dep=8, eta=0.05):\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"multi:softmax\"\n",
    "    params[\"num_class\"] = 11\n",
    "    params[\"nthread\"] = 8\n",
    "    params['eval_metric'] = \"merror\"\n",
    "    params[\"eta\"] = eta\n",
    "    params[\"subsample\"] = 0.7\n",
    "    params[\"min_child_weight\"] = 1\n",
    "    params[\"colsample_bytree\"] = 0.7\n",
    "    params[\"max_depth\"] = dep\n",
    "\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"seed\"] = seed_val\n",
    "    # params[\"max_delta_step\"] = 2\n",
    "    # params[\"gamma\"] = 0.5\n",
    "    num_rounds = rounds\n",
    "\n",
    "    plst = list(params.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [(xgtrain, 'train'), (xgtest, 'test')]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist,\n",
    "                          early_stopping_rounds=100, verbose_eval=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    if feature_names is not None:\n",
    "        create_feature_map(feature_names)\n",
    "        model.dump_model('../model/xgbmodel.txt', '../model/xgb.fmap',\n",
    "                         with_stats=True)\n",
    "        importance = model.get_fscore(fmap='../model/xgb.fmap')\n",
    "        importance = sorted(importance.items(), key=operator.itemgetter(1),\n",
    "                            reverse=True)\n",
    "        imp_df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "        imp_df['fscore'] = imp_df['fscore'] / imp_df['fscore'].sum()\n",
    "        imp_df.to_csv(\"imp_feat.txt\", index=False)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest,\n",
    "                                ntree_limit=model.best_ntree_limit)\n",
    "    if test_X2 is not None:\n",
    "        pred_test_y2 = model.predict(xgb.DMatrix(test_X2),\n",
    "                                     ntree_limit=model.best_ntree_limit)\n",
    "    else:\n",
    "        pred_test_y2 = None\n",
    "\n",
    "    loss = 0\n",
    "    if test_y is not None:\n",
    "        loss = metrics.accuracy_score(test_y, pred_test_y)\n",
    "\n",
    "    return pred_test_y, loss, pred_test_y2\n",
    "\n",
    "\n",
    "def runLGB(train_X, train_y, test_X, test_y=None, test_X2=None,\n",
    "           feature_names=None, seed_val=0, rounds=500, dep=8, eta=0.05):\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"multiclass\"\n",
    "    params[\"num_class\"] = 11\n",
    "    params['metric'] = \"multi_error\"\n",
    "    params['seed'] = seed_val\n",
    "    params[\"max_depth\"] = dep\n",
    "    params[\"num_leaves\"] = 40\n",
    "    params[\"min_data_in_leaf\"] = 10\n",
    "    params[\"learning_rate\"] = eta\n",
    "    params[\"bagging_fraction\"] = 0.7\n",
    "    params[\"feature_fraction\"] = 0.7\n",
    "    params[\"bagging_freq\"] = 5\n",
    "    params[\"bagging_seed\"] = seed_val\n",
    "    params[\"verbosity\"] = 0\n",
    "    num_rounds = rounds\n",
    "\n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        lgtest = lgb.Dataset(test_X, label=test_y)\n",
    "        model = lgb.train(params, lgtrain, num_rounds, valid_sets=[lgtest],\n",
    "                          early_stopping_rounds=100, verbose_eval=20)\n",
    "    else:\n",
    "        lgtest = lgb.DMatrix(test_X)\n",
    "        model = lgb.train(params, lgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(test_X,\n",
    "                                num_iteration=model.best_iteration)\n",
    "    pred_test_y = pred_test_y.argmax(axis=1)\n",
    "    \n",
    "    if test_X2 is not None:\n",
    "        pred_test_y2 = model.predict(test_X2,\n",
    "                                     num_iteration=model.best_iteration)\n",
    "        pred_test_y2 = pred_test_y2.argmax(axis=1)\n",
    "    else:\n",
    "        pred_test_y2 = None\n",
    "        \n",
    "    loss = 0\n",
    "    if test_y is not None:\n",
    "        loss = metrics.accuracy_score(test_y, pred_test_y)\n",
    "\n",
    "    return pred_test_y, loss, pred_test_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "\n",
    "def trainModel(train_X, train_y, test_X, n_splits, model_name, feats, \n",
    "               **params):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=2020)\n",
    "    cv_scores = []\n",
    "    pred_test_full = []\n",
    "    pred_val_full = np.zeros(train_X.shape[0])\n",
    "    for dev_index, val_index in kf.split(train_X):\n",
    "        dev_X, val_X = train_X.iloc[dev_index, :], train_X.iloc[val_index, :]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "\n",
    "        if model_name == \"XGB\":\n",
    "            pred_val, acc, pred_test = runXGB(\n",
    "             dev_X, dev_y, val_X, val_y, test_X, rounds=params['rounds'],\n",
    "             dep=params['depth'], eta=params['eta'], feature_names=feats)\n",
    "        elif model_name == \"LGB\":\n",
    "            pred_val, acc, pred_test = runLGB(\n",
    "             dev_X, dev_y, val_X, val_y, test_X, rounds=params['rounds'],\n",
    "             dep=params['depth'], eta=params['eta'])\n",
    "        \n",
    "        cv_scores.append(acc)\n",
    "        pred_val_full[val_index] = pred_val\n",
    "        if pred_test is not None:\n",
    "            pred_test_full.append(pred_test)\n",
    "\n",
    "    #pred_test_full = pred_test_full/n_splits\n",
    "    acc = metrics.accuracy_score(train_y, pred_val_full)\n",
    "    return pred_val_full, acc, pred_test_full, cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's multi_error: 0.586268\n",
      "[40]\tvalid_0's multi_error: 0.5807\n",
      "[60]\tvalid_0's multi_error: 0.579381\n",
      "[80]\tvalid_0's multi_error: 0.577733\n",
      "[100]\tvalid_0's multi_error: 0.577309\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[120]\tvalid_0's multi_error: 0.576819\n",
      "[140]\tvalid_0's multi_error: 0.576131\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[160]\tvalid_0's multi_error: 0.576536\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-265a97160932>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(train_X, train_y, test_X, n_splits, model_name, feats, **params)\u001b[0m\n\u001b[1;32m     16\u001b[0m              dep=params['depth'], eta=params['eta'], feature_names=feats)\n\u001b[1;32m     17\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"LGB\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             pred_val, acc, pred_test = runLGB(\n\u001b[0m\u001b[1;32m     19\u001b[0m              \u001b[0mdev_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rounds'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m              dep=params['depth'], eta=params['eta'])\n",
      "\u001b[0;32m<ipython-input-47-52fe994fdec7>\u001b[0m in \u001b[0;36mrunLGB\u001b[0;34m(train_X, train_y, test_X, test_y, test_X2, feature_names, seed_val, rounds, dep, eta)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mlgtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         model = lgb.train(params, lgtrain, num_rounds, valid_sets=[lgtest],\n\u001b[0m\u001b[1;32m     96\u001b[0m                           early_stopping_rounds=100, verbose_eval=20)\n\u001b[1;32m     97\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/py38/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/py38/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2368\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2369\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2370\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2371\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2372\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LGB\n",
    "params = {'rounds': 600, 'depth': 7, 'eta': 0.05}\n",
    "%time pred_val_full, acc, pred_test_full, cv_scores = trainModel(x_train, y_train, x_test, 3, \"LGB\", feat_cols, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
