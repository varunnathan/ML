{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "LOCAL_ROOT = \"/Users/varunn/Documents/ML\"\n",
    "PROJ_DIR = os.path.join(LOCAL_ROOT, \"AV_JanataHack_April10\")\n",
    "DATA_DIR = os.path.join(PROJ_DIR, \"data\")\n",
    "TRAIN_FN = os.path.join(DATA_DIR, \"train_8wry4cB.csv\")\n",
    "TEST_FN = os.path.join(DATA_DIR, \"test_Yix80N0.csv\")\n",
    "SUBMISSION_FN = os.path.join(DATA_DIR, \"sample_submission_opxHi4g.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10500, 5)\n",
      "  session_id       startTime         endTime  \\\n",
      "0     u16159  15/12/14 18:11  15/12/14 18:12   \n",
      "1     u10253  16/12/14 14:35  16/12/14 14:41   \n",
      "2     u19037  01/12/14 15:58  01/12/14 15:58   \n",
      "3     u14556   23/11/14 2:57   23/11/14 3:00   \n",
      "4     u24295  17/12/14 16:44  17/12/14 16:46   \n",
      "\n",
      "                                         ProductList  gender  \n",
      "0  A00002/B00003/C00006/D28435/;A00002/B00003/C00...  female  \n",
      "1  A00001/B00009/C00031/D29404/;A00001/B00009/C00...    male  \n",
      "2                       A00002/B00001/C00020/D16944/  female  \n",
      "3  A00002/B00004/C00018/D10284/;A00002/B00004/C00...  female  \n",
      "4  A00001/B00001/C00012/D30805/;A00001/B00001/C00...    male  \n",
      "(4500, 4)\n",
      "  session_id       startTime         endTime  \\\n",
      "0     u12112  08/12/14 13:36  08/12/14 13:36   \n",
      "1     u19725  19/12/14 13:52  19/12/14 13:52   \n",
      "2     u11795  01/12/14 10:44  01/12/14 10:44   \n",
      "3     u22639  08/12/14 20:19  08/12/14 20:22   \n",
      "4     u18034  15/12/14 19:33  15/12/14 19:33   \n",
      "\n",
      "                                         ProductList  \n",
      "0                       A00002/B00003/C00006/D19956/  \n",
      "1                       A00002/B00005/C00067/D02026/  \n",
      "2                       A00002/B00002/C00004/D12538/  \n",
      "3  A00002/B00003/C00079/D22781/;A00002/B00003/C00...  \n",
      "4                       A00002/B00001/C00010/D23419/  \n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "train_df = pd.read_csv(TRAIN_FN)\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "\n",
    "test_df = pd.read_csv(TEST_FN)\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "ID_COL = 'session_id'\n",
    "DATE_COLS = ['startTime', 'endTime']\n",
    "DV_COL = 'gender'\n",
    "FEAT_PREFIX = 'JH_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "train_df[DV_COL] = train_df[DV_COL].apply(lambda x: 1 if x=='male' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime\n",
      "endTime\n"
     ]
    }
   ],
   "source": [
    "# datetime conversion\n",
    "for col in DATE_COLS:\n",
    "    print(col)\n",
    "    train_df[col] = train_df[col].apply(lambda x: pd.to_datetime(x))\n",
    "    test_df[col] = test_df[col].apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_of_day(hour):\n",
    "    return (\n",
    "        \"morning\" if 5 <= hour <= 11\n",
    "        else\n",
    "        \"afternoon\" if 12 <= hour <= 17\n",
    "        else\n",
    "        \"evening\" if 18 <= hour <= 22\n",
    "        else\n",
    "        \"night\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime features\n",
    "\n",
    "# session duration\n",
    "train_df['session_duration_sec'] = list(map(lambda x, y: (x-y).seconds,\n",
    "                                            train_df['endTime'],\n",
    "                                            train_df['startTime']))\n",
    "test_df['session_duration_sec'] = list(map(lambda x, y: (x-y).seconds,\n",
    "                                           test_df['endTime'],\n",
    "                                           test_df['startTime']))\n",
    "\n",
    "# month of year\n",
    "train_df['session_start_month'] = train_df['startTime'].dt.month\n",
    "test_df['session_start_month'] = test_df['startTime'].dt.month\n",
    "train_df['session_end_month'] = train_df['endTime'].dt.month\n",
    "test_df['session_end_month'] = test_df['endTime'].dt.month\n",
    "\n",
    "# day of week\n",
    "train_df['session_start_dow'] = train_df['startTime'].dt.dayofweek\n",
    "test_df['session_start_dow'] = test_df['startTime'].dt.dayofweek\n",
    "train_df['session_end_dow'] = train_df['endTime'].dt.dayofweek\n",
    "test_df['session_end_dow'] = test_df['endTime'].dt.dayofweek\n",
    "\n",
    "# week of year\n",
    "train_df['session_start_woy'] = train_df['startTime'].dt.weekofyear\n",
    "test_df['session_start_woy'] = test_df['startTime'].dt.weekofyear\n",
    "train_df['session_end_woy'] = train_df['endTime'].dt.weekofyear\n",
    "test_df['session_end_woy'] = test_df['endTime'].dt.weekofyear\n",
    "\n",
    "# hour of the day\n",
    "train_df['session_start_hod'] = train_df['startTime'].dt.hour\n",
    "test_df['session_start_hod'] = test_df['startTime'].dt.hour\n",
    "train_df['session_end_hod'] = train_df['endTime'].dt.hour\n",
    "test_df['session_end_hod'] = test_df['endTime'].dt.hour\n",
    "\n",
    "# minute of the hour\n",
    "train_df['session_start_moh'] = train_df['startTime'].dt.minute\n",
    "test_df['session_start_moh'] = test_df['startTime'].dt.minute\n",
    "train_df['session_end_moh'] = train_df['endTime'].dt.minute\n",
    "test_df['session_end_moh'] = test_df['endTime'].dt.minute\n",
    "\n",
    "# part of the day\n",
    "train_df['session_start_part_of_day'] = train_df['session_start_hod'].apply(\n",
    "    lambda x: get_part_of_day(x))\n",
    "test_df['session_start_part_of_day'] = test_df['session_start_hod'].apply(\n",
    "    lambda x: get_part_of_day(x))\n",
    "train_df['session_end_part_of_day'] = train_df['session_end_hod'].apply(\n",
    "    lambda x: get_part_of_day(x))\n",
    "test_df['session_end_part_of_day'] = test_df['session_end_hod'].apply(\n",
    "    lambda x: get_part_of_day(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# productlist parsing\n",
    "\n",
    "def parse_product_list(productList):\n",
    "    out = [x.split('/') for x in productList.split(';')]\n",
    "    prods = list(set([x[0] for x in out]))\n",
    "    cats = list(set([x[1] for x in out]))\n",
    "    sub_cats = list(set([x[2] for x in out]))\n",
    "    sub_sub_cats = list(set([x[3] for x in out]))\n",
    "    return prods, cats, sub_cats, sub_sub_cats\n",
    "\n",
    "\n",
    "def get_prod_cat_lst(productlist):\n",
    "    return list(set(['/'.join(x.split('/')[:2])\n",
    "                     for x in productlist.split(';')]))\n",
    "\n",
    "\n",
    "def get_prod_cat_str(productlist):\n",
    "    return \";\".join(set(['/'.join(x.split('/')[:2])\n",
    "                         for x in productlist.split(';')]))\n",
    "\n",
    "\n",
    "def get_prod_cat_sub_cat_lst(productlist):\n",
    "    return list(set(['/'.join(x.split('/')[:3])\n",
    "                     for x in productlist.split(';')]))\n",
    "\n",
    "\n",
    "def get_prod_cat_sub_cat_str(productlist):\n",
    "    return \";\".join(set(['/'.join(x.split('/')[:3])\n",
    "                         for x in productlist.split(';')]))\n",
    "\n",
    "\n",
    "def get_prod_cat_sub_sub_cat_lst(productlist):\n",
    "    return list(set(['/'.join(x.split('/')[:4])\n",
    "                     for x in productlist.split(';')]))\n",
    "\n",
    "\n",
    "def get_prod_cat_sub_sub_cat_str(productlist):\n",
    "    return \";\".join(set(['/'.join(x.split('/')[:4])\n",
    "                         for x in productlist.split(';')]))\n",
    "\n",
    "\n",
    "def parse_product_list_df(data):\n",
    "    \n",
    "    parsed_prod_lists = data['ProductList'].apply(\n",
    "        lambda x: parse_product_list(x))\n",
    "    for idx, col in [(0, 'prod_lst'), (1, 'cat_lst'), (2, 'sub_cat_lst'),\n",
    "                     (3, 'sub_sub_cat_lst')]:\n",
    "        data[col] = parsed_prod_lists.apply(lambda x: x[idx])\n",
    "    \n",
    "    data['prod_str'] = data['prod_lst'].apply(lambda x: '/'.join(x))\n",
    "    data['cat_str'] = data['cat_lst'].apply(lambda x: '/'.join(x))\n",
    "    data['sub_cat_str'] = data['sub_cat_lst'].apply(lambda x: '/'.join(x))\n",
    "    data['sub_sub_cat_str'] = data['sub_sub_cat_lst'].apply(lambda x: '/'.join(x))\n",
    "    data['prod_cat_lst'] = data['ProductList'].apply(get_prod_cat_lst)\n",
    "    data['prod_cat_str'] = data['ProductList'].apply(get_prod_cat_str)\n",
    "    data['prod_cat_sub_cat_lst'] = data['ProductList'].apply(\n",
    "        get_prod_cat_sub_cat_lst)\n",
    "    data['prod_cat_sub_cat_str'] = data['ProductList'].apply(\n",
    "        get_prod_cat_sub_cat_str)\n",
    "    data['prod_cat_sub_sub_cat_lst'] = data['ProductList'].apply(\n",
    "        get_prod_cat_sub_sub_cat_lst)\n",
    "    data['prod_cat_sub_sub_cat_str'] = data['ProductList'].apply(\n",
    "        get_prod_cat_sub_sub_cat_str)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = parse_product_list_df(train_df)\n",
    "test_df = parse_product_list_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['session_duration_sec_bins'] = pd.qcut(\n",
    "    train_df['session_duration_sec'], q=5, duplicates='drop', labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7270\n",
       "1    1628\n",
       "2    1602\n",
       "Name: session_duration_sec_bins, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['session_duration_sec_bins'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.060835700078713965\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gender</th>\n",
       "      <th>session_start_part_of_day</th>\n",
       "      <th>#good</th>\n",
       "      <th>#bad</th>\n",
       "      <th>All</th>\n",
       "      <th>perc_good</th>\n",
       "      <th>perc_bad</th>\n",
       "      <th>WOE</th>\n",
       "      <th>IV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>3170</td>\n",
       "      <td>758</td>\n",
       "      <td>3928</td>\n",
       "      <td>0.386963</td>\n",
       "      <td>0.328423</td>\n",
       "      <td>0.164027</td>\n",
       "      <td>0.009602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>evening</td>\n",
       "      <td>1974</td>\n",
       "      <td>752</td>\n",
       "      <td>2726</td>\n",
       "      <td>0.240967</td>\n",
       "      <td>0.325823</td>\n",
       "      <td>-0.301696</td>\n",
       "      <td>0.025601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>morning</td>\n",
       "      <td>2601</td>\n",
       "      <td>600</td>\n",
       "      <td>3201</td>\n",
       "      <td>0.317505</td>\n",
       "      <td>0.259965</td>\n",
       "      <td>0.199945</td>\n",
       "      <td>0.011505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>night</td>\n",
       "      <td>447</td>\n",
       "      <td>198</td>\n",
       "      <td>645</td>\n",
       "      <td>0.054565</td>\n",
       "      <td>0.085789</td>\n",
       "      <td>-0.452485</td>\n",
       "      <td>0.014128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All</td>\n",
       "      <td>8192</td>\n",
       "      <td>2308</td>\n",
       "      <td>10500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "gender session_start_part_of_day  #good  #bad    All  perc_good  perc_bad  \\\n",
       "0                      afternoon   3170   758   3928   0.386963  0.328423   \n",
       "1                        evening   1974   752   2726   0.240967  0.325823   \n",
       "2                        morning   2601   600   3201   0.317505  0.259965   \n",
       "3                          night    447   198    645   0.054565  0.085789   \n",
       "4                            All   8192  2308  10500   1.000000  1.000000   \n",
       "\n",
       "gender       WOE        IV  \n",
       "0       0.164027  0.009602  \n",
       "1      -0.301696  0.025601  \n",
       "2       0.199945  0.011505  \n",
       "3      -0.452485  0.014128  \n",
       "4       0.000000  0.000000  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = get_woe(train_df, 'session_start_part_of_day')\n",
    "table['IV'] = list(map(lambda x,y,z: (x-y)*z, table['perc_good'],\n",
    "                       table['perc_bad'], table['WOE']))\n",
    "print(table['IV'].sum())\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['prod_str'] = train_df['prod_lst'].apply(lambda x: '/'.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8911977172630283\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gender</th>\n",
       "      <th>prod_str</th>\n",
       "      <th>#good</th>\n",
       "      <th>#bad</th>\n",
       "      <th>All</th>\n",
       "      <th>perc_good</th>\n",
       "      <th>perc_bad</th>\n",
       "      <th>WOE</th>\n",
       "      <th>IV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00001</td>\n",
       "      <td>301.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1482</td>\n",
       "      <td>0.036743</td>\n",
       "      <td>0.511698</td>\n",
       "      <td>-2.633783</td>\n",
       "      <td>1.250929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00001/A00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>-2.653071</td>\n",
       "      <td>0.004274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00001/A00009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00001/A00010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>-0.573630</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00001/A00011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A00002</td>\n",
       "      <td>5876.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>6559</td>\n",
       "      <td>0.717285</td>\n",
       "      <td>0.295927</td>\n",
       "      <td>0.885360</td>\n",
       "      <td>0.373053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A00002/A00001</td>\n",
       "      <td>74.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>134</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>0.025997</td>\n",
       "      <td>-1.057056</td>\n",
       "      <td>0.017931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A00002/A00003</td>\n",
       "      <td>124.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>129</td>\n",
       "      <td>0.015137</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>1.944067</td>\n",
       "      <td>0.025215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A00002/A00003/A00001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A00002/A00003/A00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A00002/A00003/A00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A00002/A00003/A00009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A00002/A00004</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.119518</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A00002/A00004/A00001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A00002/A00004/A00003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A00002/A00004/A00005</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A00002/A00004/A00008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A00002/A00005</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.679133</td>\n",
       "      <td>0.001144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A00002/A00006</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.524983</td>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A00002/A00007/A00006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A00002/A00008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>-1.266777</td>\n",
       "      <td>0.000394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A00002/A00009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A00002/A00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>-1.266777</td>\n",
       "      <td>0.000394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A00002/A00010/A00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A00002/A00011</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.679133</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A00003</td>\n",
       "      <td>1367.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1502</td>\n",
       "      <td>0.166870</td>\n",
       "      <td>0.058492</td>\n",
       "      <td>1.048322</td>\n",
       "      <td>0.113615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A00003/A00001</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>-1.266777</td>\n",
       "      <td>0.002365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A00003/A00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A00003/A00009</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>-0.573630</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A00003/A00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>-2.365389</td>\n",
       "      <td>0.002786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A00003/A00011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A00004</td>\n",
       "      <td>40.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>130</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.038995</td>\n",
       "      <td>-2.077707</td>\n",
       "      <td>0.070875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A00004/A00001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>-2.365389</td>\n",
       "      <td>0.002786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A00004/A00003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>A00004/A00011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A00005</td>\n",
       "      <td>153.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>182</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>0.012565</td>\n",
       "      <td>0.396365</td>\n",
       "      <td>0.002422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>A00005/A00001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A00005/A00009</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A00006</td>\n",
       "      <td>80.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>95</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.006499</td>\n",
       "      <td>0.407200</td>\n",
       "      <td>0.001330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A00006/A00001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>A00006/A00003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>A00006/A00005</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>A00006/A00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>A00007</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>-0.691413</td>\n",
       "      <td>0.001346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>A00007/A00001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>A00007/A00003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>A00007/A00004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>A00008</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>-1.066106</td>\n",
       "      <td>0.002726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>A00008/A00001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>A00009</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>-1.004412</td>\n",
       "      <td>0.002758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>A00010</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.009965</td>\n",
       "      <td>-1.629682</td>\n",
       "      <td>0.013057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>A00010/A00001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>A00011</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>-0.464430</td>\n",
       "      <td>0.000972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>A00011/A00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>All</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>10500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "gender              prod_str   #good    #bad    All  perc_good  perc_bad  \\\n",
       "0                     A00001   301.0  1181.0   1482   0.036743  0.511698   \n",
       "1              A00001/A00005     1.0     4.0      5   0.000122  0.001733   \n",
       "2              A00001/A00009     1.0     0.0      1   0.000122  0.000000   \n",
       "3              A00001/A00010     2.0     1.0      3   0.000244  0.000433   \n",
       "4              A00001/A00011     1.0     0.0      1   0.000122  0.000000   \n",
       "5                     A00002  5876.0   683.0   6559   0.717285  0.295927   \n",
       "6              A00002/A00001    74.0    60.0    134   0.009033  0.025997   \n",
       "7              A00002/A00003   124.0     5.0    129   0.015137  0.002166   \n",
       "8       A00002/A00003/A00001     1.0     0.0      1   0.000122  0.000000   \n",
       "9       A00002/A00003/A00004     1.0     0.0      1   0.000122  0.000000   \n",
       "10      A00002/A00003/A00005     1.0     0.0      1   0.000122  0.000000   \n",
       "11      A00002/A00003/A00009     1.0     0.0      1   0.000122  0.000000   \n",
       "12             A00002/A00004     4.0     1.0      5   0.000488  0.000433   \n",
       "13      A00002/A00004/A00001     2.0     0.0      2   0.000244  0.000000   \n",
       "14      A00002/A00004/A00003     1.0     0.0      1   0.000122  0.000000   \n",
       "15      A00002/A00004/A00005     2.0     0.0      2   0.000244  0.000000   \n",
       "16      A00002/A00004/A00008     0.0     1.0      1   0.000000  0.000433   \n",
       "17             A00002/A00005    28.0     4.0     32   0.003418  0.001733   \n",
       "18             A00002/A00006    12.0     2.0     14   0.001465  0.000867   \n",
       "19      A00002/A00007/A00006     1.0     0.0      1   0.000122  0.000000   \n",
       "20             A00002/A00008     1.0     1.0      2   0.000122  0.000433   \n",
       "21             A00002/A00009     1.0     0.0      1   0.000122  0.000000   \n",
       "22             A00002/A00010     1.0     1.0      2   0.000122  0.000433   \n",
       "23      A00002/A00010/A00005     1.0     0.0      1   0.000122  0.000000   \n",
       "24             A00002/A00011     7.0     1.0      8   0.000854  0.000433   \n",
       "25                    A00003  1367.0   135.0   1502   0.166870  0.058492   \n",
       "26             A00003/A00001     6.0     6.0     12   0.000732  0.002600   \n",
       "27             A00003/A00005     1.0     0.0      1   0.000122  0.000000   \n",
       "28             A00003/A00009     2.0     1.0      3   0.000244  0.000433   \n",
       "29             A00003/A00010     1.0     3.0      4   0.000122  0.001300   \n",
       "30             A00003/A00011     1.0     0.0      1   0.000122  0.000000   \n",
       "31                    A00004    40.0    90.0    130   0.004883  0.038995   \n",
       "32             A00004/A00001     1.0     3.0      4   0.000122  0.001300   \n",
       "33             A00004/A00003     0.0     1.0      1   0.000000  0.000433   \n",
       "34             A00004/A00011     0.0     1.0      1   0.000000  0.000433   \n",
       "35                    A00005   153.0    29.0    182   0.018677  0.012565   \n",
       "36             A00005/A00001     0.0     4.0      4   0.000000  0.001733   \n",
       "37             A00005/A00009     2.0     0.0      2   0.000244  0.000000   \n",
       "38                    A00006    80.0    15.0     95   0.009766  0.006499   \n",
       "39             A00006/A00001     0.0     5.0      5   0.000000  0.002166   \n",
       "40             A00006/A00003     1.0     0.0      1   0.000122  0.000000   \n",
       "41             A00006/A00005     2.0     0.0      2   0.000244  0.000000   \n",
       "42             A00006/A00010     1.0     0.0      1   0.000122  0.000000   \n",
       "43                    A00007    16.0     9.0     25   0.001953  0.003899   \n",
       "44             A00007/A00001     1.0     0.0      1   0.000122  0.000000   \n",
       "45             A00007/A00003     0.0     1.0      1   0.000000  0.000433   \n",
       "46             A00007/A00004     1.0     0.0      1   0.000122  0.000000   \n",
       "47                    A00008    11.0     9.0     20   0.001343  0.003899   \n",
       "48             A00008/A00001     1.0     0.0      1   0.000122  0.000000   \n",
       "49                    A00009    13.0    10.0     23   0.001587  0.004333   \n",
       "50                    A00010    16.0    23.0     39   0.001953  0.009965   \n",
       "51             A00010/A00001     0.0     5.0      5   0.000000  0.002166   \n",
       "52                    A00011    29.0    13.0     42   0.003540  0.005633   \n",
       "53             A00011/A00005     1.0     0.0      1   0.000122  0.000000   \n",
       "54                       All  8192.0  2308.0  10500   1.000000  1.000000   \n",
       "\n",
       "gender       WOE        IV  \n",
       "0      -2.633783  1.250929  \n",
       "1      -2.653071  0.004274  \n",
       "2            NaN       NaN  \n",
       "3      -0.573630  0.000108  \n",
       "4            NaN       NaN  \n",
       "5       0.885360  0.373053  \n",
       "6      -1.057056  0.017931  \n",
       "7       1.944067  0.025215  \n",
       "8            NaN       NaN  \n",
       "9            NaN       NaN  \n",
       "10           NaN       NaN  \n",
       "11           NaN       NaN  \n",
       "12      0.119518  0.000007  \n",
       "13           NaN       NaN  \n",
       "14           NaN       NaN  \n",
       "15           NaN       NaN  \n",
       "16           NaN       NaN  \n",
       "17      0.679133  0.001144  \n",
       "18      0.524983  0.000314  \n",
       "19           NaN       NaN  \n",
       "20     -1.266777  0.000394  \n",
       "21           NaN       NaN  \n",
       "22     -1.266777  0.000394  \n",
       "23           NaN       NaN  \n",
       "24      0.679133  0.000286  \n",
       "25      1.048322  0.113615  \n",
       "26     -1.266777  0.002365  \n",
       "27           NaN       NaN  \n",
       "28     -0.573630  0.000108  \n",
       "29     -2.365389  0.002786  \n",
       "30           NaN       NaN  \n",
       "31     -2.077707  0.070875  \n",
       "32     -2.365389  0.002786  \n",
       "33           NaN       NaN  \n",
       "34           NaN       NaN  \n",
       "35      0.396365  0.002422  \n",
       "36           NaN       NaN  \n",
       "37           NaN       NaN  \n",
       "38      0.407200  0.001330  \n",
       "39           NaN       NaN  \n",
       "40           NaN       NaN  \n",
       "41           NaN       NaN  \n",
       "42           NaN       NaN  \n",
       "43     -0.691413  0.001346  \n",
       "44           NaN       NaN  \n",
       "45           NaN       NaN  \n",
       "46           NaN       NaN  \n",
       "47     -1.066106  0.002726  \n",
       "48           NaN       NaN  \n",
       "49     -1.004412  0.002758  \n",
       "50     -1.629682  0.013057  \n",
       "51           NaN       NaN  \n",
       "52     -0.464430  0.000972  \n",
       "53           NaN       NaN  \n",
       "54      0.000000  0.000000  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = get_woe(train_df , 'prod_str')\n",
    "table['IV'] = list(map(lambda x,y,z: (x-y)*z, table['perc_good'],\n",
    "                       table['perc_bad'], table['WOE']))\n",
    "print(table['IV'].sum())\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "\n",
    "def _find_cats(data, id_col, cat_col, freq_thresh):\n",
    "    \"\"\"\n",
    "    identifies values of discrete variables that satisfy the frequency threshold\n",
    "    id_col: deal_id or the entity of choice\n",
    "    cat_col: discrete variable\n",
    "    \"\"\"\n",
    "    cats = data.groupby(cat_col)[id_col].nunique().to_dict()\n",
    "    freq_thresh = int(freq_thresh*data[id_col].nunique())\n",
    "    good_cats = [k for k, v in cats.items() if v >= freq_thresh]\n",
    "\n",
    "    return good_cats\n",
    "\n",
    "\n",
    "def _group_cats(data, cat_col, id_col=ID_COL, dv_col=DV_COL,\n",
    "                freq_thresh=0.003):\n",
    "\n",
    "    df = pd.DataFrame({id_col: np.repeat(data[id_col].values,\n",
    "                                         data[cat_col].str.len()),\n",
    "                       dv_col: np.repeat(data[dv_col].values,\n",
    "                                         data[cat_col].str.len()),\n",
    "                       cat_col: np.concatenate(data[cat_col].values)})\n",
    "    grouped_cats = _find_cats(df, id_col, cat_col, freq_thresh)\n",
    "    mask = df[cat_col].isin(grouped_cats)\n",
    "    df.loc[~mask, cat_col] = 'others'\n",
    "\n",
    "    return grouped_cats, df\n",
    "\n",
    "\n",
    "def _apply_grouping(test_data, cat_col, grouped_cats, id_col=ID_COL,\n",
    "                    dv_col=DV_COL):\n",
    "    \n",
    "    df = pd.DataFrame({id_col: np.repeat(test_data[id_col].values,\n",
    "                                         test_data[cat_col].str.len()),\n",
    "                       cat_col: np.concatenate(test_data[cat_col].values)})\n",
    "    mask = df[cat_col].isin(grouped_cats)\n",
    "    df.loc[~mask, cat_col] = 'others'\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_woe(data, cat_col, id_col=ID_COL, dv_col=DV_COL):\n",
    "    table = pd.pivot_table(data, index=cat_col, columns=dv_col,\n",
    "                           values=id_col,\n",
    "                           aggfunc=lambda x: len(x.unique()),\n",
    "                           margins=True)\n",
    "    table.fillna(value=0, inplace=True)\n",
    "    table.reset_index(inplace=True)\n",
    "    table.rename(columns={0: '#good', 1: '#bad'}, inplace=True)\n",
    "    total_good = table.loc[len(table)-1, '#good']\n",
    "    total_bad = table.loc[len(table)-1, '#bad']\n",
    "    table['perc_good'] = table['#good'].apply(lambda x: 1.*x/total_good)\n",
    "    table['perc_bad'] = table['#bad'].apply(lambda x: 1.*x/total_bad)\n",
    "    mask = (table['perc_good'] != 0) & (table['perc_bad'] != 0)\n",
    "    table.loc[mask, 'WOE'] = list(map(\n",
    "     lambda x, y: log(x / float(y)), table.loc[mask, 'perc_good'],\n",
    "     table.loc[mask, 'perc_bad']))\n",
    "    return table\n",
    "\n",
    "\n",
    "def get_counts(data, cat_col, id_col=ID_COL):\n",
    "    table = pd.DataFrame(data.groupby(cat_col)[id_col].nunique())\n",
    "    table.reset_index(inplace=True)\n",
    "    table.rename(columns={id_col: 'num_sessions'}, inplace=True)\n",
    "    return table\n",
    "\n",
    "\n",
    "def getDVEncodeVar(compute_df, target_df, cat_col, dv_col=DV_COL,\n",
    "                   encode_type='woe'):\n",
    "\n",
    "    if encode_type == 'woe':\n",
    "        assert dv_col in target_df\n",
    "        grouped_df = get_woe(target_df, cat_col)\n",
    "        return_col = 'WOE'\n",
    "    elif encode_type == 'count':\n",
    "        grouped_df = get_counts(target_df, cat_col)\n",
    "        return_col = 'num_sessions'\n",
    "    merged_df = pd.merge(compute_df, grouped_df, how=\"left\", on=cat_col)\n",
    "    merged_df.fillna(-999999, inplace=True)\n",
    "    return merged_df[return_col].tolist()\n",
    "\n",
    "\n",
    "def _aggregation(data, cat_col, id_col=ID_COL, dv_col=DV_COL,\n",
    "                 enc_prefix='_enc'):\n",
    "    if dv_col in data:\n",
    "        group_cols = [id_col, dv_col]\n",
    "    else:\n",
    "        group_cols = [id_col]\n",
    "    df = pd.DataFrame(data.groupby(group_cols).agg({\n",
    "        cat_col: lambda x: list(x), cat_col+enc_prefix: lambda x: list(x)}))\n",
    "    df.reset_index(inplace=True)\n",
    "    assert df.shape[0] == df[id_col].nunique()\n",
    "    return df\n",
    "\n",
    "\n",
    "def do_target_encode_woe(train_data, test_data, discrete_cols,\n",
    "                         id_col=ID_COL, dv_col=DV_COL,\n",
    "                         grouping_flag=True, agg_flag=True):\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=2020)\n",
    "    train_final = train_data.copy()\n",
    "    test_final = test_data.copy()\n",
    "    for col in discrete_cols:\n",
    "        print('Cat Col: ', col)\n",
    "        \n",
    "        if grouping_flag:\n",
    "            print('grouping')\n",
    "            grouped_cats, train_tmp = _group_cats(train_data, col)\n",
    "            test_tmp = _apply_grouping(test_data, col, grouped_cats)\n",
    "        else:\n",
    "            train_tmp = train_data.copy()\n",
    "            test_tmp = test_data.copy()\n",
    "        \n",
    "        print('encoding')\n",
    "        train_enc_values = np.zeros(train_tmp.shape[0])\n",
    "        test_enc_values = 0\n",
    "        for dev_index, val_index in kf.split(train_tmp):\n",
    "            dev_X, val_X = train_tmp.iloc[dev_index, :], train_tmp.iloc[val_index, :]\n",
    "            train_enc_values[val_index] =  np.array( \n",
    "                getDVEncodeVar(val_X[[col]], dev_X, col))\n",
    "            test_enc_values += np.array( \n",
    "                getDVEncodeVar(test_tmp[[col]], dev_X, col))\n",
    "        test_enc_values /= 5.\n",
    "        train_tmp[col + \"_enc\"] = train_enc_values\n",
    "        test_tmp[col + \"_enc\"] = test_enc_values\n",
    "        print(train_tmp[col + \"_enc\"].describe())\n",
    "        print(test_tmp[col + \"_enc\"].describe())\n",
    "        \n",
    "        if agg_flag:\n",
    "            print('aggregating')\n",
    "            train_tmp = _aggregation(train_tmp, col)\n",
    "            test_tmp = _aggregation(test_tmp, col)\n",
    "        \n",
    "        print('merge')\n",
    "        train_final.drop([col], axis=1, inplace=True)\n",
    "        group_cols = [id_col, dv_col]\n",
    "        needed_cols = [col, col+'_enc']\n",
    "        train_final = pd.merge(train_final,\n",
    "                               train_tmp[group_cols+needed_cols],\n",
    "                               on=group_cols, how='left')\n",
    "        test_final.drop([col], axis=1, inplace=True)\n",
    "        group_cols = [id_col]\n",
    "        test_final = pd.merge(test_final,\n",
    "                              test_tmp[group_cols+needed_cols],\n",
    "                              on=group_cols, how='left')\n",
    "    return train_final, test_final\n",
    "\n",
    "\n",
    "def do_target_encode_count(train_data, test_data, discrete_cols,\n",
    "                           id_col=ID_COL, prod_flag=True):\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=2020)\n",
    "    train_final = train_data.copy()\n",
    "    test_final = test_data.copy()\n",
    "    \n",
    "    for col in discrete_cols:\n",
    "        print('Cat Col: ', col)\n",
    "        \n",
    "        if prod_flag:\n",
    "            print('product col')\n",
    "            train_tmp = pd.DataFrame(\n",
    "                {id_col: np.repeat(train_data[id_col].values,\n",
    "                                   train_data[col].str.len()),\n",
    "                 col: np.concatenate(train_data[col].values)})\n",
    "            test_tmp = pd.DataFrame(\n",
    "                {id_col: np.repeat(test_data[id_col].values,\n",
    "                                   test_data[col].str.len()),\n",
    "                 col: np.concatenate(test_data[col].values)})\n",
    "        else:\n",
    "            train_tmp = train_data.copy()\n",
    "            test_tmp = test_data.copy()\n",
    "        \n",
    "        print('encoding')\n",
    "        train_enc_values = np.zeros(train_tmp.shape[0])\n",
    "        test_enc_values = 0\n",
    "        for dev_index, val_index in kf.split(train_tmp):\n",
    "            dev_X, val_X = train_tmp.iloc[dev_index, :], train_tmp.iloc[val_index, :]\n",
    "            train_enc_values[val_index] =  np.array( \n",
    "                getDVEncodeVar(val_X[[col]], dev_X, col,\n",
    "                               encode_type='count'))\n",
    "            test_enc_values += np.array( \n",
    "                getDVEncodeVar(test_tmp[[col]], dev_X, col,\n",
    "                               encode_type='count'))\n",
    "\n",
    "        test_enc_values = test_enc_values/5.\n",
    "        train_tmp[col + \"_count_enc\"] = train_enc_values\n",
    "        test_tmp[col + \"_count_enc\"] = test_enc_values\n",
    "        print(train_tmp[col + \"_count_enc\"].describe())\n",
    "        print(test_tmp[col + \"_count_enc\"].describe())\n",
    "        \n",
    "        if prod_flag:\n",
    "            print('aggregating')\n",
    "            train_tmp = _aggregation(train_tmp, col,\n",
    "                                     enc_prefix='_count_enc')\n",
    "            test_tmp = _aggregation(test_tmp, col,\n",
    "                                    enc_prefix='_count_enc')\n",
    "        \n",
    "        print('merge')\n",
    "        train_final.drop([col], axis=1, inplace=True)\n",
    "        group_cols = [id_col]\n",
    "        needed_cols = [col, col+'_count_enc']\n",
    "        train_final = pd.merge(train_final,\n",
    "                               train_tmp[group_cols+needed_cols],\n",
    "                               on=group_cols, how='left')\n",
    "        test_final.drop([col], axis=1, inplace=True)\n",
    "        test_final = pd.merge(test_final,\n",
    "                              test_tmp[group_cols+needed_cols],\n",
    "                              on=group_cols, how='left')\n",
    "    return train_final, test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOE encoding for prod_cols: \n",
      "\n",
      "Cat Col:  prod_lst\n",
      "grouping\n",
      "encoding\n",
      "count    10913.000000\n",
      "mean         0.275312\n",
      "std          1.222714\n",
      "min         -2.451351\n",
      "25%          0.810286\n",
      "50%          0.833387\n",
      "75%          0.834754\n",
      "max          1.111406\n",
      "Name: prod_lst_enc, dtype: float64\n",
      "count    4684.000000\n",
      "mean        0.301794\n",
      "std         1.204782\n",
      "min        -2.438680\n",
      "25%         0.826462\n",
      "50%         0.826462\n",
      "75%         0.826462\n",
      "max         1.032610\n",
      "Name: prod_lst_enc, dtype: float64\n",
      "aggregating\n",
      "merge\n",
      "Cat Col:  cat_lst\n",
      "grouping\n",
      "encoding\n",
      "count     12071.000000\n",
      "mean       -828.160644\n",
      "std       28771.737032\n",
      "min     -999999.000000\n",
      "25%          -0.584881\n",
      "50%           0.821218\n",
      "75%           1.154604\n",
      "max           1.979575\n",
      "Name: cat_lst_enc, dtype: float64\n",
      "count      5234.000000\n",
      "mean      -1298.891147\n",
      "std       16068.558899\n",
      "min     -199998.829785\n",
      "25%          -0.521898\n",
      "50%           0.777636\n",
      "75%           1.150759\n",
      "max           1.826891\n",
      "Name: cat_lst_enc, dtype: float64\n",
      "aggregating\n",
      "merge\n",
      "Cat Col:  sub_cat_lst\n",
      "grouping\n",
      "encoding\n",
      "count     14170.000000\n",
      "mean      -5080.849207\n",
      "std       71103.368229\n",
      "min     -999999.000000\n",
      "25%          -0.456437\n",
      "50%           0.763148\n",
      "75%           1.189838\n",
      "max           2.833067\n",
      "Name: sub_cat_lst_enc, dtype: float64\n",
      "count      6153.000000\n",
      "mean      -4647.821332\n",
      "std       30135.721623\n",
      "min     -200003.701816\n",
      "25%          -0.439448\n",
      "50%           0.779699\n",
      "75%           1.186193\n",
      "max           2.099846\n",
      "Name: sub_cat_lst_enc, dtype: float64\n",
      "aggregating\n",
      "merge\n",
      "Cat Col:  sub_sub_cat_lst\n",
      "grouping\n",
      "encoding\n",
      "count     23251.000000\n",
      "mean       -258.049857\n",
      "std       16062.297701\n",
      "min     -999999.000000\n",
      "25%          -0.004430\n",
      "50%          -0.003882\n",
      "75%          -0.003849\n",
      "max           2.539591\n",
      "Name: sub_sub_cat_lst_enc, dtype: float64\n",
      "count     10204.000000\n",
      "mean       -313.596946\n",
      "std        7913.731734\n",
      "min     -199998.172386\n",
      "25%          -0.004172\n",
      "50%          -0.004172\n",
      "75%          -0.004172\n",
      "max           2.055339\n",
      "Name: sub_sub_cat_lst_enc, dtype: float64\n",
      "aggregating\n",
      "merge\n",
      "WOE encoding for time_cols: \n",
      "\n",
      "Cat Col:  session_start_month\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean         0.004730\n",
      "std          0.126940\n",
      "min         -0.338828\n",
      "25%         -0.049325\n",
      "50%         -0.018324\n",
      "75%          0.008630\n",
      "max          0.717529\n",
      "Name: session_start_month_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean        0.007924\n",
      "std         0.124311\n",
      "min        -0.184038\n",
      "25%        -0.052688\n",
      "50%        -0.001707\n",
      "75%        -0.001707\n",
      "max         0.584348\n",
      "Name: session_start_month_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_end_month\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean         0.004617\n",
      "std          0.123289\n",
      "min         -0.330137\n",
      "25%         -0.050622\n",
      "50%         -0.024038\n",
      "75%          0.004456\n",
      "max          0.646886\n",
      "Name: session_end_month_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean        0.007046\n",
      "std         0.119242\n",
      "min        -0.166735\n",
      "25%        -0.052826\n",
      "50%        -0.006468\n",
      "75%        -0.006468\n",
      "max         0.525873\n",
      "Name: session_end_month_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_start_dow\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean         0.006161\n",
      "std          0.145487\n",
      "min         -0.285205\n",
      "25%         -0.048392\n",
      "50%          0.032346\n",
      "75%          0.077276\n",
      "max          0.309544\n",
      "Name: session_start_dow_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean        0.008088\n",
      "std         0.143511\n",
      "min        -0.264754\n",
      "25%        -0.119628\n",
      "50%         0.019289\n",
      "75%         0.063873\n",
      "max         0.258465\n",
      "Name: session_start_dow_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_end_dow\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean         0.006048\n",
      "std          0.144797\n",
      "min         -0.291290\n",
      "25%         -0.053119\n",
      "50%          0.029908\n",
      "75%          0.077276\n",
      "max          0.299184\n",
      "Name: session_end_dow_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean        0.007878\n",
      "std         0.142757\n",
      "min        -0.265787\n",
      "25%        -0.119504\n",
      "50%         0.023924\n",
      "75%         0.067901\n",
      "max         0.250845\n",
      "Name: session_end_dow_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_start_woy\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean         0.006921\n",
      "std          0.159090\n",
      "min         -0.338828\n",
      "25%         -0.091553\n",
      "50%          0.030074\n",
      "75%          0.053043\n",
      "max          0.717529\n",
      "Name: session_start_woy_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean        0.011516\n",
      "std         0.155132\n",
      "min        -0.249991\n",
      "25%        -0.021888\n",
      "50%         0.032297\n",
      "75%         0.090465\n",
      "max         0.584348\n",
      "Name: session_start_woy_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_end_woy\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean         0.007011\n",
      "std          0.158652\n",
      "min         -0.336155\n",
      "25%         -0.074797\n",
      "50%          0.025200\n",
      "75%          0.047028\n",
      "max          0.646886\n",
      "Name: session_end_woy_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean        0.010870\n",
      "std         0.153682\n",
      "min        -0.260702\n",
      "25%        -0.023312\n",
      "50%         0.033280\n",
      "75%         0.098782\n",
      "max         0.525873\n",
      "Name: session_end_woy_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_start_hod\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean         0.029919\n",
      "std          0.335187\n",
      "min         -1.478434\n",
      "25%         -0.284807\n",
      "50%          0.085107\n",
      "75%          0.321251\n",
      "max          0.735522\n",
      "Name: session_start_hod_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean        0.033397\n",
      "std         0.333324\n",
      "min        -1.161211\n",
      "25%        -0.295900\n",
      "50%         0.091891\n",
      "75%         0.339579\n",
      "max         0.651465\n",
      "Name: session_start_hod_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_end_hod\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean         0.029139\n",
      "std          0.330725\n",
      "min         -1.785919\n",
      "25%         -0.295972\n",
      "50%          0.098965\n",
      "75%          0.300195\n",
      "max          0.685659\n",
      "Name: session_end_hod_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean        0.030228\n",
      "std         0.330469\n",
      "min        -1.572949\n",
      "25%        -0.326742\n",
      "50%         0.114087\n",
      "75%         0.325258\n",
      "max         0.607791\n",
      "Name: session_end_hod_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_start_moh\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean         0.010730\n",
      "std          0.187594\n",
      "min         -0.427659\n",
      "25%         -0.120745\n",
      "50%          0.001280\n",
      "75%          0.116175\n",
      "max          0.633521\n",
      "Name: session_start_moh_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean        0.008989\n",
      "std         0.157649\n",
      "min        -0.316692\n",
      "25%        -0.113590\n",
      "50%         0.008455\n",
      "75%         0.113874\n",
      "max         0.468879\n",
      "Name: session_start_moh_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_end_moh\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean         0.009449\n",
      "std          0.189037\n",
      "min         -0.501976\n",
      "25%         -0.098146\n",
      "50%         -0.005217\n",
      "75%          0.134530\n",
      "max          0.554841\n",
      "Name: session_end_moh_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean        0.009362\n",
      "std         0.166768\n",
      "min        -0.393832\n",
      "25%        -0.070809\n",
      "50%         0.014821\n",
      "75%         0.104266\n",
      "max         0.367202\n",
      "Name: session_end_moh_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_start_part_of_day\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean         0.016273\n",
      "std          0.241475\n",
      "min         -0.547629\n",
      "25%         -0.297885\n",
      "50%          0.165644\n",
      "75%          0.191173\n",
      "max          0.207697\n",
      "Name: session_start_part_of_day_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean        0.017779\n",
      "std         0.240329\n",
      "min        -0.451400\n",
      "25%        -0.301721\n",
      "50%         0.163979\n",
      "75%         0.199968\n",
      "max         0.199968\n",
      "Name: session_start_part_of_day_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_end_part_of_day\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean         0.016097\n",
      "std          0.240628\n",
      "min         -0.547796\n",
      "25%         -0.293493\n",
      "50%          0.174919\n",
      "75%          0.179261\n",
      "max          0.200480\n",
      "Name: session_end_part_of_day_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean        0.017164\n",
      "std         0.239884\n",
      "min        -0.455570\n",
      "25%        -0.298748\n",
      "50%         0.171281\n",
      "75%         0.189826\n",
      "max         0.189826\n",
      "Name: session_end_part_of_day_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  prod_str\n",
      "encoding\n",
      "count     10500.000000\n",
      "mean      -5904.443860\n",
      "std       76618.840567\n",
      "min     -999999.000000\n",
      "25%           0.866913\n",
      "50%           0.886479\n",
      "75%           0.909148\n",
      "max           2.218310\n",
      "Name: prod_str_enc, dtype: float64\n",
      "count      4500.000000\n",
      "mean      -5288.546208\n",
      "std       70551.913866\n",
      "min     -999999.000000\n",
      "25%           0.885508\n",
      "50%           0.885508\n",
      "75%           0.885508\n",
      "max           1.967682\n",
      "Name: prod_str_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  cat_str\n",
      "encoding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     10500.000000\n",
      "mean     -69142.490559\n",
      "std      253708.819633\n",
      "min     -999999.000000\n",
      "25%          -0.677409\n",
      "50%           0.809038\n",
      "75%           1.200807\n",
      "max           2.382296\n",
      "Name: cat_str_enc, dtype: float64\n",
      "count      4500.000000\n",
      "mean     -74532.915964\n",
      "std      250148.290362\n",
      "min     -999999.000000\n",
      "25%          -0.657818\n",
      "50%           0.811030\n",
      "75%           1.234052\n",
      "max           1.951826\n",
      "Name: cat_str_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  sub_cat_str\n",
      "encoding\n",
      "count     10500.000000\n",
      "mean    -251618.502476\n",
      "std      433963.834059\n",
      "min     -999999.000000\n",
      "25%     -999999.000000\n",
      "50%           0.444606\n",
      "75%           1.130618\n",
      "max           2.850057\n",
      "Name: sub_cat_str_enc, dtype: float64\n",
      "count      4500.000000\n",
      "mean    -255066.101377\n",
      "std      424037.037958\n",
      "min     -999999.000000\n",
      "25%     -200002.168056\n",
      "50%           0.328750\n",
      "75%           1.113286\n",
      "max           2.099923\n",
      "Name: sub_cat_str_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  sub_sub_cat_str\n",
      "encoding\n",
      "count     10500.000000\n",
      "mean    -989903.778741\n",
      "std       99971.209670\n",
      "min     -999999.000000\n",
      "25%     -999999.000000\n",
      "50%     -999999.000000\n",
      "75%     -999999.000000\n",
      "max           1.572397\n",
      "Name: sub_sub_cat_str_enc, dtype: float64\n",
      "count      4500.000000\n",
      "mean    -989154.573308\n",
      "std       91940.947156\n",
      "min     -999999.000000\n",
      "25%     -999999.000000\n",
      "50%     -999999.000000\n",
      "75%     -999999.000000\n",
      "max          -0.631189\n",
      "Name: sub_sub_cat_str_enc, dtype: float64\n",
      "merge\n",
      "WOE encoding for prod_cat_lst: \n",
      "\n",
      "Cat Col:  prod_cat_lst\n",
      "grouping\n",
      "encoding\n",
      "count    12116.000000\n",
      "mean         0.314726\n",
      "std          1.320687\n",
      "min         -3.519733\n",
      "25%          0.393756\n",
      "50%          0.828392\n",
      "75%          1.169954\n",
      "max          2.275311\n",
      "Name: prod_cat_lst_enc, dtype: float64\n",
      "count    5254.000000\n",
      "mean        0.339083\n",
      "std         1.301905\n",
      "min        -3.325414\n",
      "25%         0.430566\n",
      "50%         0.778221\n",
      "75%         1.151463\n",
      "max         1.853763\n",
      "Name: prod_cat_lst_enc, dtype: float64\n",
      "aggregating\n",
      "merge\n",
      "Cat Col:  prod_cat_sub_cat_lst\n",
      "grouping\n",
      "encoding\n",
      "count     14221.000000\n",
      "mean      -4078.154392\n",
      "std       63734.775736\n",
      "min     -999999.000000\n",
      "25%          -0.440494\n",
      "50%           0.817709\n",
      "75%           1.207059\n",
      "max           3.019997\n",
      "Name: prod_cat_sub_cat_lst_enc, dtype: float64\n",
      "count      6189.000000\n",
      "mean      -3457.417615\n",
      "std       26071.035125\n",
      "min     -200003.720283\n",
      "25%          -0.441636\n",
      "50%           0.797984\n",
      "75%           1.232215\n",
      "max           2.592368\n",
      "Name: prod_cat_sub_cat_lst_enc, dtype: float64\n",
      "aggregating\n",
      "merge\n",
      "Cat Col:  prod_cat_sub_sub_cat_lst\n",
      "grouping\n",
      "encoding\n",
      "count     23251.000000\n",
      "mean       -817.166621\n",
      "std       28575.074395\n",
      "min     -999999.000000\n",
      "25%          -0.004430\n",
      "50%          -0.003857\n",
      "75%          -0.003849\n",
      "max           2.146820\n",
      "Name: prod_cat_sub_sub_cat_lst_enc, dtype: float64\n",
      "count     10204.000000\n",
      "mean       -980.003613\n",
      "std       13966.279541\n",
      "min     -199998.378168\n",
      "25%          -0.004074\n",
      "50%          -0.004074\n",
      "75%          -0.004074\n",
      "max          -0.004074\n",
      "Name: prod_cat_sub_sub_cat_lst_enc, dtype: float64\n",
      "aggregating\n",
      "merge\n",
      "WOE encoding for prod_cat_str: \n",
      "\n",
      "Cat Col:  prod_cat_str\n",
      "encoding\n",
      "count     10500.000000\n",
      "mean     -75332.924401\n",
      "std      263940.841685\n",
      "min     -999999.000000\n",
      "25%          -0.092139\n",
      "50%           0.822750\n",
      "75%           1.200807\n",
      "max           2.382296\n",
      "Name: prod_cat_str_enc, dtype: float64\n",
      "count      4500.000000\n",
      "mean     -80399.551213\n",
      "std      259323.130589\n",
      "min     -999999.000000\n",
      "25%          -1.290356\n",
      "50%           0.811030\n",
      "75%           1.234052\n",
      "max           1.951826\n",
      "Name: prod_cat_str_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  prod_cat_sub_cat_str\n",
      "encoding\n",
      "count     10500.000000\n",
      "mean    -273618.462485\n",
      "std      445836.705399\n",
      "min     -999999.000000\n",
      "25%     -999999.000000\n",
      "50%           0.487175\n",
      "75%           1.148867\n",
      "max           2.850057\n",
      "Name: prod_cat_sub_cat_str_enc, dtype: float64\n",
      "count      4500.000000\n",
      "mean    -276532.727932\n",
      "std      431016.055387\n",
      "min     -999999.000000\n",
      "25%     -999999.000000\n",
      "50%           0.144513\n",
      "75%           1.113286\n",
      "max           2.099923\n",
      "Name: prod_cat_sub_cat_str_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  prod_cat_sub_sub_cat_str\n",
      "encoding\n",
      "count     10500.000000\n",
      "mean    -989999.016555\n",
      "std       99503.317358\n",
      "min     -999999.000000\n",
      "25%     -999999.000000\n",
      "50%     -999999.000000\n",
      "75%     -999999.000000\n",
      "max           1.572397\n",
      "Name: prod_cat_sub_sub_cat_str_enc, dtype: float64\n",
      "count      4500.000000\n",
      "mean    -989154.573308\n",
      "std       91940.947156\n",
      "min     -999999.000000\n",
      "25%     -999999.000000\n",
      "50%     -999999.000000\n",
      "75%     -999999.000000\n",
      "max          -0.631189\n",
      "Name: prod_cat_sub_sub_cat_str_enc, dtype: float64\n",
      "merge\n",
      "Count encoding for prod_cols: \n",
      "\n",
      "Cat Col:  prod_lst\n",
      "product col\n",
      "encoding\n",
      "count    10913.000000\n",
      "mean      3899.487767\n",
      "std       2140.199209\n",
      "min         22.000000\n",
      "25%       1329.000000\n",
      "50%       5508.000000\n",
      "75%       5524.000000\n",
      "max       5537.000000\n",
      "Name: prod_lst_count_enc, dtype: float64\n",
      "count    4684.000000\n",
      "mean     3882.888301\n",
      "std      2138.261939\n",
      "min        24.800000\n",
      "25%      1328.800000\n",
      "50%      5518.400000\n",
      "75%      5518.400000\n",
      "max      5518.400000\n",
      "Name: prod_lst_count_enc, dtype: float64\n",
      "aggregating\n",
      "merge\n",
      "Cat Col:  cat_lst\n",
      "product col\n",
      "encoding\n",
      "count    12071.000000\n",
      "mean      1027.167095\n",
      "std        738.691101\n",
      "min         23.000000\n",
      "25%        342.000000\n",
      "50%        700.000000\n",
      "75%       1339.000000\n",
      "max       2188.000000\n",
      "Name: cat_lst_count_enc, dtype: float64\n",
      "count    5234.000000\n",
      "mean     1026.715017\n",
      "std       740.549267\n",
      "min        26.400000\n",
      "25%       340.800000\n",
      "50%       677.600000\n",
      "75%      1326.400000\n",
      "max      2162.400000\n",
      "Name: cat_lst_count_enc, dtype: float64\n",
      "aggregating\n",
      "merge\n",
      "Cat Col:  sub_cat_lst\n",
      "product col\n",
      "encoding\n",
      "count    14170.000000\n",
      "mean       384.765138\n",
      "std        366.388820\n",
      "min         21.000000\n",
      "25%         99.000000\n",
      "50%        255.000000\n",
      "75%        519.000000\n",
      "max       1175.000000\n",
      "Name: sub_cat_lst_count_enc, dtype: float64\n",
      "count    6153.000000\n",
      "mean      392.360930\n",
      "std       371.996362\n",
      "min        25.600000\n",
      "25%       103.200000\n",
      "50%       256.000000\n",
      "75%       520.000000\n",
      "max      1147.600000\n",
      "Name: sub_cat_lst_count_enc, dtype: float64\n",
      "aggregating\n",
      "merge\n",
      "Cat Col:  sub_sub_cat_lst\n",
      "product col\n",
      "encoding\n",
      "count    23251.000000\n",
      "mean      9217.331685\n",
      "std        575.719917\n",
      "min         25.000000\n",
      "25%       9237.000000\n",
      "50%       9255.000000\n",
      "75%       9256.000000\n",
      "max       9284.000000\n",
      "Name: sub_sub_cat_lst_count_enc, dtype: float64\n",
      "count    10204.000000\n",
      "mean      9208.249745\n",
      "std        643.450576\n",
      "min         28.800000\n",
      "25%       9253.400000\n",
      "50%       9253.400000\n",
      "75%       9253.400000\n",
      "max       9253.400000\n",
      "Name: sub_sub_cat_lst_count_enc, dtype: float64\n",
      "aggregating\n",
      "merge\n",
      "Count encoding for time_cols: \n",
      "\n",
      "Cat Col:  session_start_month\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean      2495.446857\n",
      "std       1238.943069\n",
      "min         62.000000\n",
      "25%       3155.000000\n",
      "50%       3180.000000\n",
      "75%       3209.000000\n",
      "max       3234.000000\n",
      "Name: session_start_month_count_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean     2484.977244\n",
      "std      1246.316092\n",
      "min        67.200000\n",
      "25%      3184.000000\n",
      "50%      3184.000000\n",
      "75%      3200.000000\n",
      "max      3200.000000\n",
      "Name: session_start_month_count_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_end_month\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean      2492.821143\n",
      "std       1238.521135\n",
      "min         61.000000\n",
      "25%       3129.000000\n",
      "50%       3186.000000\n",
      "75%       3201.000000\n",
      "max       3233.000000\n",
      "Name: session_end_month_count_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean     2482.932444\n",
      "std      1245.135670\n",
      "min        67.200000\n",
      "25%      3175.200000\n",
      "50%      3175.200000\n",
      "75%      3204.800000\n",
      "max      3204.800000\n",
      "Name: session_end_month_count_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_start_dow\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean      1241.163429\n",
      "std        236.065274\n",
      "min        928.000000\n",
      "25%       1040.000000\n",
      "50%       1196.000000\n",
      "75%       1383.000000\n",
      "max       1655.000000\n",
      "Name: session_start_dow_count_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean     1233.681067\n",
      "std       231.412595\n",
      "min       951.200000\n",
      "25%      1057.600000\n",
      "50%      1191.200000\n",
      "75%      1381.600000\n",
      "max      1633.600000\n",
      "Name: session_start_dow_count_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_end_dow\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean      1241.108381\n",
      "std        236.536810\n",
      "min        924.000000\n",
      "25%       1037.000000\n",
      "50%       1194.000000\n",
      "75%       1380.000000\n",
      "max       1657.000000\n",
      "Name: session_end_dow_count_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean     1234.153067\n",
      "std       231.546602\n",
      "min       948.000000\n",
      "25%      1056.800000\n",
      "50%      1188.000000\n",
      "75%      1379.200000\n",
      "max      1636.000000\n",
      "Name: session_end_dow_count_enc, dtype: float64\n",
      "merge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Col:  session_start_woy\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean      1085.043048\n",
      "std        658.388318\n",
      "min         62.000000\n",
      "25%        354.000000\n",
      "50%       1157.500000\n",
      "75%       1248.000000\n",
      "max       2082.000000\n",
      "Name: session_start_woy_count_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean     1076.533867\n",
      "std       654.154100\n",
      "min        67.200000\n",
      "25%       352.000000\n",
      "50%      1180.000000\n",
      "75%      1229.600000\n",
      "max      2068.000000\n",
      "Name: session_start_woy_count_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_end_woy\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean      1086.201714\n",
      "std        663.958600\n",
      "min         61.000000\n",
      "25%        355.000000\n",
      "50%       1122.000000\n",
      "75%       1236.000000\n",
      "max       2093.000000\n",
      "Name: session_end_woy_count_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean     1078.175289\n",
      "std       659.325398\n",
      "min        67.200000\n",
      "25%       353.600000\n",
      "50%      1176.000000\n",
      "75%      1216.800000\n",
      "max      2080.800000\n",
      "Name: session_end_woy_count_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_start_hod\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean       495.425524\n",
      "std        147.298574\n",
      "min         19.000000\n",
      "25%        423.000000\n",
      "50%        553.000000\n",
      "75%        605.000000\n",
      "max        652.000000\n",
      "Name: session_start_hod_count_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean      495.744889\n",
      "std       146.115098\n",
      "min        24.000000\n",
      "25%       419.200000\n",
      "50%       536.000000\n",
      "75%       598.400000\n",
      "max       640.000000\n",
      "Name: session_start_hod_count_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_end_hod\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean       496.619619\n",
      "std        149.097717\n",
      "min         17.000000\n",
      "25%        424.000000\n",
      "50%        553.000000\n",
      "75%        608.000000\n",
      "max        662.000000\n",
      "Name: session_end_hod_count_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean      496.511467\n",
      "std       148.460395\n",
      "min        22.400000\n",
      "25%       418.400000\n",
      "50%       558.400000\n",
      "75%       597.600000\n",
      "max       644.000000\n",
      "Name: session_end_hod_count_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_start_moh\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean       140.017905\n",
      "std         12.049880\n",
      "min        109.000000\n",
      "25%        132.000000\n",
      "50%        140.000000\n",
      "75%        148.000000\n",
      "max        179.000000\n",
      "Name: session_start_moh_count_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean      139.783289\n",
      "std        10.745530\n",
      "min       116.800000\n",
      "25%       132.000000\n",
      "50%       139.200000\n",
      "75%       147.200000\n",
      "max       168.000000\n",
      "Name: session_start_moh_count_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_end_moh\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean       139.823429\n",
      "std         11.637509\n",
      "min        103.000000\n",
      "25%        132.000000\n",
      "50%        139.000000\n",
      "75%        147.000000\n",
      "max        174.000000\n",
      "Name: session_end_moh_count_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean      139.958044\n",
      "std         9.954924\n",
      "min       116.800000\n",
      "25%       132.800000\n",
      "50%       139.200000\n",
      "75%       146.400000\n",
      "max       165.600000\n",
      "Name: session_end_moh_count_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_start_part_of_day\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean      2553.724762\n",
      "std        648.910155\n",
      "min        501.000000\n",
      "25%       2183.000000\n",
      "50%       2562.000000\n",
      "75%       3130.000000\n",
      "max       3174.000000\n",
      "Name: session_start_part_of_day_count_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean     2562.188444\n",
      "std       651.815823\n",
      "min       516.000000\n",
      "25%      2180.800000\n",
      "50%      2560.800000\n",
      "75%      3142.400000\n",
      "max      3142.400000\n",
      "Name: session_start_part_of_day_count_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  session_end_part_of_day\n",
      "encoding\n",
      "count    10500.000000\n",
      "mean      2553.116571\n",
      "std        656.053489\n",
      "min        507.000000\n",
      "25%       2180.000000\n",
      "50%       2548.000000\n",
      "75%       3144.000000\n",
      "max       3184.000000\n",
      "Name: session_end_part_of_day_count_enc, dtype: float64\n",
      "count    4500.000000\n",
      "mean     2559.305956\n",
      "std       659.628002\n",
      "min       522.400000\n",
      "25%      2176.800000\n",
      "50%      2544.000000\n",
      "75%      3156.800000\n",
      "max      3156.800000\n",
      "Name: session_end_part_of_day_count_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  prod_str\n",
      "encoding\n",
      "count     10500.000000\n",
      "mean       1528.643048\n",
      "std       45942.337825\n",
      "min     -999999.000000\n",
      "25%        1190.000000\n",
      "50%        5201.000000\n",
      "75%        5252.000000\n",
      "max        5292.000000\n",
      "Name: prod_str_count_enc, dtype: float64\n",
      "count      4500.000000\n",
      "mean       1426.720044\n",
      "std       43285.300044\n",
      "min     -999999.000000\n",
      "25%        1201.600000\n",
      "50%        5247.200000\n",
      "75%        5247.200000\n",
      "max        5247.200000\n",
      "Name: prod_str_count_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  cat_str\n",
      "encoding\n",
      "count     10500.000000\n",
      "mean     -26135.317333\n",
      "std      161794.474151\n",
      "min     -999999.000000\n",
      "25%         130.000000\n",
      "50%         541.000000\n",
      "75%        1027.000000\n",
      "max        1772.000000\n",
      "Name: cat_str_count_enc, dtype: float64\n",
      "count      4500.000000\n",
      "mean     -27902.704711\n",
      "std      161028.846152\n",
      "min     -999999.000000\n",
      "25%         132.000000\n",
      "50%         562.400000\n",
      "75%        1012.800000\n",
      "max        1761.600000\n",
      "Name: cat_str_count_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  sub_cat_str\n",
      "encoding\n",
      "count     10500.000000\n",
      "mean    -128260.358667\n",
      "std      334575.367082\n",
      "min     -999999.000000\n",
      "25%           7.000000\n",
      "50%          57.000000\n",
      "75%         176.000000\n",
      "max         611.000000\n",
      "Name: sub_cat_str_count_enc, dtype: float64\n",
      "count      4500.000000\n",
      "mean    -131387.465289\n",
      "std      327137.079908\n",
      "min     -999999.000000\n",
      "25%           5.600000\n",
      "50%          60.800000\n",
      "75%         172.000000\n",
      "max         599.200000\n",
      "Name: sub_cat_str_count_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  sub_sub_cat_str\n",
      "encoding\n",
      "count     10500.000000\n",
      "mean    -852570.111810\n",
      "std      354550.278343\n",
      "min     -999999.000000\n",
      "25%     -999999.000000\n",
      "50%     -999999.000000\n",
      "75%     -999999.000000\n",
      "max          23.000000\n",
      "Name: sub_sub_cat_str_count_enc, dtype: float64\n",
      "count      4500.000000\n",
      "mean    -847154.214711\n",
      "std      340271.777085\n",
      "min     -999999.000000\n",
      "25%     -999999.000000\n",
      "50%     -999999.000000\n",
      "75%     -999999.000000\n",
      "max          20.000000\n",
      "Name: sub_sub_cat_str_count_enc, dtype: float64\n",
      "merge\n",
      "Count encoding for prod_cat_lst: \n",
      "\n",
      "Cat Col:  prod_cat_lst\n",
      "product col\n",
      "encoding\n",
      "count    12116.000000\n",
      "mean       924.841614\n",
      "std        752.812019\n",
      "min         24.000000\n",
      "25%        287.000000\n",
      "50%        662.000000\n",
      "75%       1295.000000\n",
      "max       2179.000000\n",
      "Name: prod_cat_lst_count_enc, dtype: float64\n",
      "count    5254.000000\n",
      "mean      928.629311\n",
      "std       756.528308\n",
      "min        26.400000\n",
      "25%       287.200000\n",
      "50%       677.600000\n",
      "75%      1272.800000\n",
      "max      2162.400000\n",
      "Name: prod_cat_lst_count_enc, dtype: float64\n",
      "aggregating\n",
      "merge\n",
      "Cat Col:  prod_cat_sub_cat_lst\n",
      "product col\n",
      "encoding\n",
      "count    14221.000000\n",
      "mean       476.352577\n",
      "std        523.513054\n",
      "min         22.000000\n",
      "25%         85.000000\n",
      "50%        250.000000\n",
      "75%        530.000000\n",
      "max       1587.000000\n",
      "Name: prod_cat_sub_cat_lst_count_enc, dtype: float64\n",
      "count    6189.000000\n",
      "mean      488.528228\n",
      "std       531.566453\n",
      "min        25.600000\n",
      "25%        88.800000\n",
      "50%       256.000000\n",
      "75%       956.000000\n",
      "max      1550.800000\n",
      "Name: prod_cat_sub_cat_lst_count_enc, dtype: float64\n",
      "aggregating\n",
      "merge\n",
      "Cat Col:  prod_cat_sub_sub_cat_lst\n",
      "product col\n",
      "encoding\n",
      "count    23251.000000\n",
      "mean      9217.128726\n",
      "std        575.681877\n",
      "min         24.000000\n",
      "25%       9237.000000\n",
      "50%       9254.000000\n",
      "75%       9255.000000\n",
      "max       9284.000000\n",
      "Name: prod_cat_sub_sub_cat_lst_count_enc, dtype: float64\n",
      "count    10204.000000\n",
      "mean      9208.050725\n",
      "std        643.436609\n",
      "min         28.800000\n",
      "25%       9253.200000\n",
      "50%       9253.200000\n",
      "75%       9253.200000\n",
      "max       9253.200000\n",
      "Name: prod_cat_sub_sub_cat_lst_count_enc, dtype: float64\n",
      "aggregating\n",
      "merge\n",
      "Count encoding for prod_cat_str: \n",
      "\n",
      "Cat Col:  prod_cat_str\n",
      "encoding\n",
      "count     10500.000000\n",
      "mean     -30206.926286\n",
      "std      173055.790228\n",
      "min     -999999.000000\n",
      "25%         118.000000\n",
      "50%         459.000000\n",
      "75%         941.000000\n",
      "max        1772.000000\n",
      "Name: prod_cat_str_count_enc, dtype: float64\n",
      "count      4500.000000\n",
      "mean     -34593.781822\n",
      "std      179858.286031\n",
      "min     -999999.000000\n",
      "25%         120.000000\n",
      "50%         456.000000\n",
      "75%         934.400000\n",
      "max        1761.600000\n",
      "Name: prod_cat_str_count_enc, dtype: float64\n",
      "merge\n",
      "Cat Col:  prod_cat_sub_cat_str\n",
      "encoding\n",
      "count     10500.000000\n",
      "mean    -137888.336095\n",
      "std      344960.724366\n",
      "min     -999999.000000\n",
      "25%           5.000000\n",
      "50%          43.000000\n",
      "75%         151.000000\n",
      "max         611.000000\n",
      "Name: prod_cat_sub_cat_str_count_enc, dtype: float64\n",
      "count      4500.000000\n",
      "mean    -141663.354578\n",
      "std      336981.427058\n",
      "min     -999999.000000\n",
      "25%           4.800000\n",
      "50%          44.800000\n",
      "75%         153.600000\n",
      "max         599.200000\n",
      "Name: prod_cat_sub_cat_str_count_enc, dtype: float64\n",
      "merge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Col:  prod_cat_sub_sub_cat_str\n",
      "encoding\n",
      "count     10500.000000\n",
      "mean    -852284.403714\n",
      "std      354834.181098\n",
      "min     -999999.000000\n",
      "25%     -999999.000000\n",
      "50%     -999999.000000\n",
      "75%     -999999.000000\n",
      "max          23.000000\n",
      "Name: prod_cat_sub_sub_cat_str_count_enc, dtype: float64\n",
      "count      4500.000000\n",
      "mean    -847865.332400\n",
      "std      339753.995654\n",
      "min     -999999.000000\n",
      "25%     -999999.000000\n",
      "50%     -999999.000000\n",
      "75%     -999999.000000\n",
      "max          20.000000\n",
      "Name: prod_cat_sub_sub_cat_str_count_enc, dtype: float64\n",
      "merge\n"
     ]
    }
   ],
   "source": [
    "print('WOE encoding for prod_cols: \\n')\n",
    "prod_cols = ['prod_lst', 'cat_lst', 'sub_cat_lst', 'sub_sub_cat_lst']\n",
    "train_df1, test_df1 = do_target_encode_woe(train_df, test_df,\n",
    "                                           prod_cols)\n",
    "\n",
    "print('WOE encoding for time_cols: \\n')\n",
    "time_cols = ['session_start_month', 'session_end_month',\n",
    "             'session_start_dow', 'session_end_dow',\n",
    "             'session_start_woy', 'session_end_woy',\n",
    "             'session_start_hod', 'session_end_hod',\n",
    "             'session_start_moh', 'session_end_moh',\n",
    "             'session_start_part_of_day', 'session_end_part_of_day',\n",
    "             'prod_str', 'cat_str', 'sub_cat_str', 'sub_sub_cat_str']\n",
    "train_df1, test_df1 = do_target_encode_woe(train_df1, test_df1,\n",
    "                                           time_cols,\n",
    "                                           grouping_flag=False,\n",
    "                                           agg_flag=False)\n",
    "\n",
    "print('WOE encoding for prod_cat_lst: \\n')\n",
    "train_df1, test_df1 = do_target_encode_woe(train_df1, test_df1,\n",
    "                                           ['prod_cat_lst',\n",
    "                                            'prod_cat_sub_cat_lst',\n",
    "                                            'prod_cat_sub_sub_cat_lst'])\n",
    "\n",
    "print('WOE encoding for prod_cat_str: \\n')\n",
    "train_df1, test_df1 = do_target_encode_woe(train_df1, test_df1,\n",
    "                                           ['prod_cat_str',\n",
    "                                            'prod_cat_sub_cat_str',\n",
    "                                            'prod_cat_sub_sub_cat_str'],\n",
    "                                           grouping_flag=False,\n",
    "                                           agg_flag=False)\n",
    "\n",
    "print('Count encoding for prod_cols: \\n')\n",
    "train_df1, test_df1 = do_target_encode_count(train_df1, test_df1,\n",
    "                                             prod_cols)\n",
    "\n",
    "print('Count encoding for time_cols: \\n')\n",
    "train_df1, test_df1 = do_target_encode_count(train_df1, test_df1,\n",
    "                                             time_cols, prod_flag=False)\n",
    "\n",
    "print('Count encoding for prod_cat_lst: \\n')\n",
    "train_df1, test_df1 = do_target_encode_count(train_df1, test_df1,\n",
    "                                             ['prod_cat_lst',\n",
    "                                              'prod_cat_sub_cat_lst',\n",
    "                                              'prod_cat_sub_sub_cat_lst'])\n",
    "\n",
    "print('Count encoding for prod_cat_str: \\n')\n",
    "train_df1, test_df1 = do_target_encode_count(train_df1, test_df1,\n",
    "                                             ['prod_cat_str',\n",
    "                                              'prod_cat_sub_cat_str',\n",
    "                                              'prod_cat_sub_sub_cat_str'],\n",
    "                                             prod_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10500, 85)\n",
      "Index(['session_id', 'startTime', 'endTime', 'ProductList', 'gender',\n",
      "       'session_duration_sec', 'session_duration_sec_bins', 'prod_lst_enc',\n",
      "       'cat_lst_enc', 'sub_cat_lst_enc', 'sub_sub_cat_lst_enc',\n",
      "       'session_start_month_enc', 'session_end_month_enc',\n",
      "       'session_start_dow_enc', 'session_end_dow_enc', 'session_start_woy_enc',\n",
      "       'session_end_woy_enc', 'session_start_hod_enc', 'session_end_hod_enc',\n",
      "       'session_start_moh_enc', 'session_end_moh_enc',\n",
      "       'session_start_part_of_day_enc', 'session_end_part_of_day_enc',\n",
      "       'prod_str_enc', 'cat_str_enc', 'sub_cat_str_enc', 'sub_sub_cat_str_enc',\n",
      "       'prod_cat_lst_enc', 'prod_cat_sub_cat_lst_enc',\n",
      "       'prod_cat_sub_sub_cat_lst_enc', 'prod_cat_str_enc',\n",
      "       'prod_cat_sub_cat_str_enc', 'prod_cat_sub_sub_cat_str_enc', 'prod_lst',\n",
      "       'prod_lst_count_enc', 'cat_lst', 'cat_lst_count_enc', 'sub_cat_lst',\n",
      "       'sub_cat_lst_count_enc', 'sub_sub_cat_lst', 'sub_sub_cat_lst_count_enc',\n",
      "       'session_start_month', 'session_start_month_count_enc',\n",
      "       'session_end_month', 'session_end_month_count_enc', 'session_start_dow',\n",
      "       'session_start_dow_count_enc', 'session_end_dow',\n",
      "       'session_end_dow_count_enc', 'session_start_woy',\n",
      "       'session_start_woy_count_enc', 'session_end_woy',\n",
      "       'session_end_woy_count_enc', 'session_start_hod',\n",
      "       'session_start_hod_count_enc', 'session_end_hod',\n",
      "       'session_end_hod_count_enc', 'session_start_moh',\n",
      "       'session_start_moh_count_enc', 'session_end_moh',\n",
      "       'session_end_moh_count_enc', 'session_start_part_of_day',\n",
      "       'session_start_part_of_day_count_enc', 'session_end_part_of_day',\n",
      "       'session_end_part_of_day_count_enc', 'prod_str', 'prod_str_count_enc',\n",
      "       'cat_str', 'cat_str_count_enc', 'sub_cat_str', 'sub_cat_str_count_enc',\n",
      "       'sub_sub_cat_str', 'sub_sub_cat_str_count_enc', 'prod_cat_lst',\n",
      "       'prod_cat_lst_count_enc', 'prod_cat_sub_cat_lst',\n",
      "       'prod_cat_sub_cat_lst_count_enc', 'prod_cat_sub_sub_cat_lst',\n",
      "       'prod_cat_sub_sub_cat_lst_count_enc', 'prod_cat_str',\n",
      "       'prod_cat_str_count_enc', 'prod_cat_sub_cat_str',\n",
      "       'prod_cat_sub_cat_str_count_enc', 'prod_cat_sub_sub_cat_str',\n",
      "       'prod_cat_sub_sub_cat_str_count_enc'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_df1.shape)\n",
    "print(train_df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ratio_feats(numerator, denominator, err_value=0):\n",
    "    if (denominator) and (denominator != 0):\n",
    "        return 1.*numerator/denominator\n",
    "    else:\n",
    "        return err_value\n",
    "    \n",
    "    \n",
    "def mean_encode_mapping(data, group_col, agg_col):\n",
    "    table = pd.DataFrame(data.groupby(group_col)[agg_col].mean())\n",
    "    table.reset_index(inplace=True)\n",
    "    map_dct = dict(zip(table[group_col], table[agg_col]))\n",
    "    return map_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMER_LST = ['prod_cat_lst_enc_mean', 'prod_cat_lst_enc_mean']\n",
    "DENOM_LST = ['prod_lst_enc_mean', 'cat_lst_enc_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_features(train_data, test_data, id_col=ID_COL, dv_col=DV_COL,\n",
    "                  feat_prefix=FEAT_PREFIX):\n",
    "    \n",
    "    train_df = train_data.copy()\n",
    "    test_df = test_data.copy()\n",
    "    \n",
    "    prod_cols = ['prod_lst', 'cat_lst', 'sub_cat_lst', 'sub_sub_cat_lst']\n",
    "    prod_cols_str = ['prod_str', 'cat_str', 'sub_cat_str',\n",
    "                     'sub_sub_cat_str']\n",
    "    prod_cols_enc = [x+'_enc' for x in prod_cols]\n",
    "    prod_cols_count_enc = [x+'_count_enc' for x in prod_cols]\n",
    "    prod_cat_cols = ['prod_cat_lst', 'prod_cat_sub_cat_lst',\n",
    "                     'prod_cat_sub_sub_cat_lst',\n",
    "                     'prod_cat_str', 'prod_cat_sub_cat_str',\n",
    "                     'prod_cat_sub_sub_cat_str']\n",
    "    prod_cat_cols_enc = ['prod_cat_lst_enc', 'prod_cat_sub_cat_lst_enc',\n",
    "                         'prod_cat_sub_sub_cat_lst_enc']\n",
    "    prod_cat_cols_count_enc = ['prod_cat_lst_count_enc',\n",
    "                               'prod_cat_sub_cat_lst_count_enc',\n",
    "                               'prod_cat_sub_sub_cat_lst_count_enc']\n",
    "    drop_cols = [id_col, dv_col, 'startTime', 'endTime', 'ProductList']\n",
    "    time_cols = ['session_start_month', 'session_end_month',\n",
    "                 'session_start_dow', 'session_end_dow',\n",
    "                 'session_start_woy', 'session_end_woy',\n",
    "                 'session_start_hod', 'session_end_hod',\n",
    "                 'session_start_moh', 'session_end_moh',\n",
    "                 'session_start_part_of_day', 'session_end_part_of_day']\n",
    "    drop_cols = (drop_cols + prod_cols + prod_cols_str + prod_cols_enc +\n",
    "                 prod_cols_count_enc + prod_cat_cols + prod_cat_cols_enc +\n",
    "                 prod_cat_cols_count_enc + time_cols)\n",
    "    \n",
    "    print('count of prod_cols')\n",
    "    for col in prod_cols + ['prod_cat_lst', 'prod_cat_sub_cat_lst']:\n",
    "        train_df['num_'+col] = train_df[col].apply(lambda x: len(set(x)))\n",
    "        test_df['num_'+col] = test_df[col].apply(lambda x: len(set(x)))\n",
    "    \n",
    "    print('interaction between time_cols')\n",
    "    p1, p2, p3 = 'session_start_', 'session_end_', 'session_equal_'\n",
    "    for _name, col1, col2 in [\n",
    "        (p3+'part_of_day', p1+'part_of_day', p2+'part_of_day'),\n",
    "        (p3+'dow', p1+'dow', p2+'dow'),\n",
    "        (p3+'woy', p1+'woy', p2+'woy'),\n",
    "        (p3+'month', p1+'month', p2+'month')]:\n",
    "        train_df[_name] = list(\n",
    "            map(lambda x,y: 1 if x!=y else 0,\n",
    "                train_df[col1],\n",
    "                train_df[col2]))\n",
    "        test_df[_name] = list(\n",
    "            map(lambda x,y: 1 if x!=y else 0,\n",
    "                test_df[col1],\n",
    "                test_df[col2]))\n",
    "    \n",
    "    print('aggregating product encodings')\n",
    "    for col in prod_cols_enc:\n",
    "        print(col)\n",
    "        for _name, _func in [('_min', lambda x: np.nanmin(x)),\n",
    "                             ('_max', lambda x: np.nanmax(x)),\n",
    "                             ('_mean', lambda x: np.nanmean(x)),\n",
    "                             ('_std', lambda x: np.nanstd(x))]:\n",
    "            train_df[col+_name] = train_df[col].apply(lambda x: _func(x))\n",
    "            test_df[col+_name] = test_df[col].apply(lambda x: _func(x))\n",
    "            \n",
    "    for col in prod_cols_count_enc:\n",
    "        print(col)\n",
    "        for _name, _func in [('_min', lambda x: np.nanmin(x)),\n",
    "                             ('_max', lambda x: np.nanmax(x)),\n",
    "                             ('_mean', lambda x: np.nanmean(x)),\n",
    "                             ('_std', lambda x: np.nanstd(x))]:\n",
    "            train_df[col+_name] = train_df[col].apply(lambda x: _func(x))\n",
    "            test_df[col+_name] = test_df[col].apply(lambda x: _func(x))\n",
    "            \n",
    "    for col in prod_cat_cols_enc:\n",
    "        print(col)\n",
    "        for _name, _func in [('_min', lambda x: np.nanmin(x)),\n",
    "                             ('_max', lambda x: np.nanmax(x)),\n",
    "                             ('_mean', lambda x: np.nanmean(x)),\n",
    "                             ('_std', lambda x: np.nanstd(x))]:\n",
    "            train_df[col+_name] = train_df[col].apply(lambda x: _func(x))\n",
    "            test_df[col+_name] = test_df[col].apply(lambda x: _func(x))\n",
    "            \n",
    "    for col in prod_cat_cols_count_enc:\n",
    "        print(col)\n",
    "        for _name, _func in [('_min', lambda x: np.nanmin(x)),\n",
    "                             ('_max', lambda x: np.nanmax(x)),\n",
    "                             ('_mean', lambda x: np.nanmean(x)),\n",
    "                             ('_std', lambda x: np.nanstd(x))]:\n",
    "            train_df[col+_name] = train_df[col].apply(lambda x: _func(x))\n",
    "            test_df[col+_name] = test_df[col].apply(lambda x: _func(x))\n",
    "            \n",
    "    print('Ratio of encodings')\n",
    "    for _name, num, denom in [\n",
    "        ('ratio_prod_lst_enc_mean_min', 'prod_lst_enc_mean',\n",
    "         'prod_lst_enc_min'),\n",
    "        ('ratio_prod_lst_enc_mean_max', 'prod_lst_enc_mean',\n",
    "         'prod_lst_enc_max'),\n",
    "        ('ratio_cat_lst_enc_mean_min', 'cat_lst_enc_mean',\n",
    "         'cat_lst_enc_min'),\n",
    "        ('ratio_cat_lst_enc_mean_max', 'cat_lst_enc_mean',\n",
    "         'cat_lst_enc_max'),\n",
    "        ('ratio_sub_cat_lst_enc_mean_min', 'sub_cat_lst_enc_mean',\n",
    "         'sub_cat_lst_enc_min'),\n",
    "        ('ratio_sub_cat_lst_enc_mean_max', 'sub_cat_lst_enc_mean',\n",
    "         'sub_cat_lst_enc_max'),\n",
    "        ('ratio_sub_sub_cat_lst_enc_mean_min', 'sub_sub_cat_lst_enc_mean',\n",
    "         'sub_sub_cat_lst_enc_min'),\n",
    "        ('ratio_sub_sub_cat_lst_enc_mean_max', 'sub_sub_cat_lst_enc_mean',\n",
    "         'sub_sub_cat_lst_enc_max'),\n",
    "        ('ratio_prod_cat_lst_enc_mean_min', 'prod_cat_lst_enc_mean',\n",
    "         'prod_cat_lst_enc_min'),\n",
    "        ('ratio_prod_cat_lst_enc_mean_max', 'prod_cat_lst_enc_mean',\n",
    "         'prod_cat_lst_enc_max'),\n",
    "        ('ratio_prod_cat_sub_cat_lst_enc_mean_min', 'prod_cat_sub_cat_lst_enc_mean',\n",
    "         'prod_cat_sub_cat_lst_enc_min'),\n",
    "        ('ratio_prod_cat_sub_cat_lst_enc_mean_max', 'prod_cat_sub_cat_lst_enc_mean',\n",
    "         'prod_cat_sub_cat_lst_enc_max')]:\n",
    "        print(_name)\n",
    "        train_df[_name] = list(\n",
    "            map(lambda x, y: calc_ratio_feats(x, y),\n",
    "                train_df[num], train_df[denom]))\n",
    "        test_df[_name] = list(\n",
    "            map(lambda x, y: calc_ratio_feats(x, y),\n",
    "                test_df[num], test_df[denom]))\n",
    "    \n",
    "    print('MI of encodings')\n",
    "    for _name, col1, col2, col3 in [\n",
    "        ('prod_cat_lst_enc_mi', 'prod_cat_lst_enc_mean', 'prod_lst_enc_mean',\n",
    "         'cat_lst_enc_mean'),\n",
    "        ('prod_cat_sub_cat_lst_enc_mi', 'prod_cat_sub_cat_lst_enc_mean',\n",
    "         'prod_cat_lst_enc_mean', 'sub_cat_lst_enc_mean'),\n",
    "        ('prod_cat_sub_sub_cat_lst_enc_mi', 'prod_cat_sub_sub_cat_lst_enc_mean',\n",
    "         'prod_cat_sub_cat_lst_enc_mean', 'sub_sub_cat_lst_enc_mean')]:\n",
    "        print(_name)\n",
    "        train_df[_name] = list(map(lambda x,y,z: 1.*x/(y*z),\n",
    "                                      train_df[col1],\n",
    "                                      train_df[col2],\n",
    "                                      train_df[col3]))\n",
    "        test_df[_name] = list(map(lambda x,y,z: 1.*x/(y*z),\n",
    "                                      test_df[col1],\n",
    "                                      test_df[col2],\n",
    "                                      test_df[col3]))\n",
    "        \n",
    "    print('mean encodings by time_cols')\n",
    "    for col1 in ['session_start_part_of_day', 'session_end_part_of_day']:\n",
    "        for col2 in ['prod_str_enc', 'cat_str_enc', 'sub_cat_str_enc',\n",
    "                     'sub_sub_cat_str_enc', 'prod_cat_lst_enc_mean',\n",
    "                     'prod_cat_sub_cat_lst_enc_mean']:\n",
    "            map_dct = mean_encode_mapping(train_df, col1, col2)\n",
    "            train_df[col1+'_meanenc_'+col2] = train_df[col1].apply(\n",
    "                lambda x: map_dct[x])\n",
    "            \n",
    "            map_dct = mean_encode_mapping(test_df, col1, col2)\n",
    "            test_df[col1+'_meanenc_'+col2] = test_df[col1].apply(\n",
    "                lambda x: map_dct[x])\n",
    "    \n",
    "    \n",
    "    feat_cols = [x for x in list(train_df.columns)\n",
    "                 if x not in drop_cols]\n",
    "    print(feat_cols)\n",
    "    feat_cols_renamed = [feat_prefix+x for x in feat_cols]\n",
    "    rename_dct = dict(zip(feat_cols, feat_cols_renamed))\n",
    "    train_df.rename(columns=rename_dct, inplace=True)\n",
    "    test_df.rename(columns=rename_dct, inplace=True)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of prod_cols\n",
      "interaction between time_cols\n",
      "aggregating product encodings\n",
      "prod_lst_enc\n",
      "cat_lst_enc\n",
      "sub_cat_lst_enc\n",
      "sub_sub_cat_lst_enc\n",
      "prod_lst_count_enc\n",
      "cat_lst_count_enc\n",
      "sub_cat_lst_count_enc\n",
      "sub_sub_cat_lst_count_enc\n",
      "prod_cat_lst_enc\n",
      "prod_cat_sub_cat_lst_enc\n",
      "prod_cat_sub_sub_cat_lst_enc\n",
      "prod_cat_lst_count_enc\n",
      "prod_cat_sub_cat_lst_count_enc\n",
      "prod_cat_sub_sub_cat_lst_count_enc\n",
      "Ratio of encodings\n",
      "ratio_prod_lst_enc_mean_min\n",
      "ratio_prod_lst_enc_mean_max\n",
      "ratio_cat_lst_enc_mean_min\n",
      "ratio_cat_lst_enc_mean_max\n",
      "ratio_sub_cat_lst_enc_mean_min\n",
      "ratio_sub_cat_lst_enc_mean_max\n",
      "ratio_sub_sub_cat_lst_enc_mean_min\n",
      "ratio_sub_sub_cat_lst_enc_mean_max\n",
      "ratio_prod_cat_lst_enc_mean_min\n",
      "ratio_prod_cat_lst_enc_mean_max\n",
      "ratio_prod_cat_sub_cat_lst_enc_mean_min\n",
      "ratio_prod_cat_sub_cat_lst_enc_mean_max\n",
      "MI of encodings\n",
      "prod_cat_lst_enc_mi\n",
      "prod_cat_sub_cat_lst_enc_mi\n",
      "prod_cat_sub_sub_cat_lst_enc_mi\n",
      "mean encodings by time_cols\n",
      "['session_duration_sec', 'session_duration_sec_bins', 'session_start_month_enc', 'session_end_month_enc', 'session_start_dow_enc', 'session_end_dow_enc', 'session_start_woy_enc', 'session_end_woy_enc', 'session_start_hod_enc', 'session_end_hod_enc', 'session_start_moh_enc', 'session_end_moh_enc', 'session_start_part_of_day_enc', 'session_end_part_of_day_enc', 'prod_str_enc', 'cat_str_enc', 'sub_cat_str_enc', 'sub_sub_cat_str_enc', 'prod_cat_str_enc', 'prod_cat_sub_cat_str_enc', 'prod_cat_sub_sub_cat_str_enc', 'session_start_month_count_enc', 'session_end_month_count_enc', 'session_start_dow_count_enc', 'session_end_dow_count_enc', 'session_start_woy_count_enc', 'session_end_woy_count_enc', 'session_start_hod_count_enc', 'session_end_hod_count_enc', 'session_start_moh_count_enc', 'session_end_moh_count_enc', 'session_start_part_of_day_count_enc', 'session_end_part_of_day_count_enc', 'prod_str_count_enc', 'cat_str_count_enc', 'sub_cat_str_count_enc', 'sub_sub_cat_str_count_enc', 'prod_cat_str_count_enc', 'prod_cat_sub_cat_str_count_enc', 'prod_cat_sub_sub_cat_str_count_enc', 'num_prod_lst', 'num_cat_lst', 'num_sub_cat_lst', 'num_sub_sub_cat_lst', 'num_prod_cat_lst', 'num_prod_cat_sub_cat_lst', 'session_equal_part_of_day', 'session_equal_dow', 'session_equal_woy', 'session_equal_month', 'prod_lst_enc_min', 'prod_lst_enc_max', 'prod_lst_enc_mean', 'prod_lst_enc_std', 'cat_lst_enc_min', 'cat_lst_enc_max', 'cat_lst_enc_mean', 'cat_lst_enc_std', 'sub_cat_lst_enc_min', 'sub_cat_lst_enc_max', 'sub_cat_lst_enc_mean', 'sub_cat_lst_enc_std', 'sub_sub_cat_lst_enc_min', 'sub_sub_cat_lst_enc_max', 'sub_sub_cat_lst_enc_mean', 'sub_sub_cat_lst_enc_std', 'prod_lst_count_enc_min', 'prod_lst_count_enc_max', 'prod_lst_count_enc_mean', 'prod_lst_count_enc_std', 'cat_lst_count_enc_min', 'cat_lst_count_enc_max', 'cat_lst_count_enc_mean', 'cat_lst_count_enc_std', 'sub_cat_lst_count_enc_min', 'sub_cat_lst_count_enc_max', 'sub_cat_lst_count_enc_mean', 'sub_cat_lst_count_enc_std', 'sub_sub_cat_lst_count_enc_min', 'sub_sub_cat_lst_count_enc_max', 'sub_sub_cat_lst_count_enc_mean', 'sub_sub_cat_lst_count_enc_std', 'prod_cat_lst_enc_min', 'prod_cat_lst_enc_max', 'prod_cat_lst_enc_mean', 'prod_cat_lst_enc_std', 'prod_cat_sub_cat_lst_enc_min', 'prod_cat_sub_cat_lst_enc_max', 'prod_cat_sub_cat_lst_enc_mean', 'prod_cat_sub_cat_lst_enc_std', 'prod_cat_sub_sub_cat_lst_enc_min', 'prod_cat_sub_sub_cat_lst_enc_max', 'prod_cat_sub_sub_cat_lst_enc_mean', 'prod_cat_sub_sub_cat_lst_enc_std', 'prod_cat_lst_count_enc_min', 'prod_cat_lst_count_enc_max', 'prod_cat_lst_count_enc_mean', 'prod_cat_lst_count_enc_std', 'prod_cat_sub_cat_lst_count_enc_min', 'prod_cat_sub_cat_lst_count_enc_max', 'prod_cat_sub_cat_lst_count_enc_mean', 'prod_cat_sub_cat_lst_count_enc_std', 'prod_cat_sub_sub_cat_lst_count_enc_min', 'prod_cat_sub_sub_cat_lst_count_enc_max', 'prod_cat_sub_sub_cat_lst_count_enc_mean', 'prod_cat_sub_sub_cat_lst_count_enc_std', 'ratio_prod_lst_enc_mean_min', 'ratio_prod_lst_enc_mean_max', 'ratio_cat_lst_enc_mean_min', 'ratio_cat_lst_enc_mean_max', 'ratio_sub_cat_lst_enc_mean_min', 'ratio_sub_cat_lst_enc_mean_max', 'ratio_sub_sub_cat_lst_enc_mean_min', 'ratio_sub_sub_cat_lst_enc_mean_max', 'ratio_prod_cat_lst_enc_mean_min', 'ratio_prod_cat_lst_enc_mean_max', 'ratio_prod_cat_sub_cat_lst_enc_mean_min', 'ratio_prod_cat_sub_cat_lst_enc_mean_max', 'prod_cat_lst_enc_mi', 'prod_cat_sub_cat_lst_enc_mi', 'prod_cat_sub_sub_cat_lst_enc_mi', 'session_start_part_of_day_meanenc_prod_str_enc', 'session_start_part_of_day_meanenc_cat_str_enc', 'session_start_part_of_day_meanenc_sub_cat_str_enc', 'session_start_part_of_day_meanenc_sub_sub_cat_str_enc', 'session_start_part_of_day_meanenc_prod_cat_lst_enc_mean', 'session_start_part_of_day_meanenc_prod_cat_sub_cat_lst_enc_mean', 'session_end_part_of_day_meanenc_prod_str_enc', 'session_end_part_of_day_meanenc_cat_str_enc', 'session_end_part_of_day_meanenc_sub_cat_str_enc', 'session_end_part_of_day_meanenc_sub_sub_cat_str_enc', 'session_end_part_of_day_meanenc_prod_cat_lst_enc_mean', 'session_end_part_of_day_meanenc_prod_cat_sub_cat_lst_enc_mean']\n"
     ]
    }
   ],
   "source": [
    "train_final, test_final = calc_features(train_df1, test_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    }
   ],
   "source": [
    "feat_cols = [x for x in list(train_final.columns)\n",
    "             if x.startswith(FEAT_PREFIX)]\n",
    "feat_cols.remove('JH_session_duration_sec_bins')\n",
    "print(len(feat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JH_session_duration_sec\n",
      "AUC:  0.5176278945684847\n",
      "JH_session_start_month_enc\n",
      "AUC:  0.5141465634985648\n",
      "JH_session_end_month_enc\n",
      "AUC:  0.5116660185868447\n",
      "JH_session_start_dow_enc\n",
      "AUC:  0.5265313847639326\n",
      "JH_session_end_dow_enc\n",
      "AUC:  0.5267566965192402\n",
      "JH_session_start_woy_enc\n",
      "AUC:  0.524423767830305\n",
      "JH_session_end_woy_enc\n",
      "AUC:  0.5255241989056407\n",
      "JH_session_start_hod_enc\n",
      "AUC:  0.580850320217721\n",
      "JH_session_end_hod_enc\n",
      "AUC:  0.5790015737973218\n",
      "JH_session_start_moh_enc\n",
      "AUC:  0.5158243427243555\n",
      "JH_session_end_moh_enc\n",
      "AUC:  0.5099542839275076\n",
      "JH_session_start_part_of_day_enc\n",
      "AUC:  0.5597604259048012\n",
      "JH_session_end_part_of_day_enc\n",
      "AUC:  0.5576321818386454\n",
      "JH_prod_str_enc\n",
      "AUC:  0.784861572900306\n",
      "JH_cat_str_enc\n",
      "AUC:  0.758253444625352\n",
      "JH_sub_cat_str_enc\n",
      "AUC:  0.6817213088222351\n",
      "JH_sub_sub_cat_str_enc\n",
      "AUC:  0.5004399132687256\n",
      "JH_prod_cat_str_enc\n",
      "AUC:  0.7727071937283362\n",
      "JH_prod_cat_sub_cat_str_enc\n",
      "AUC:  0.6850959870389677\n",
      "JH_prod_cat_sub_sub_cat_str_enc\n",
      "AUC:  0.5002252588652243\n",
      "JH_session_start_month_count_enc\n",
      "AUC:  0.5126549044762783\n",
      "JH_session_end_month_count_enc\n",
      "AUC:  0.5094933468506282\n",
      "JH_session_start_dow_count_enc\n",
      "AUC:  0.5042585244005227\n",
      "JH_session_end_dow_count_enc\n",
      "AUC:  0.5058133870724789\n",
      "JH_session_start_woy_count_enc\n",
      "AUC:  0.5059666096441048\n",
      "JH_session_end_woy_count_enc\n",
      "AUC:  0.5063913963489762\n",
      "JH_session_start_hod_count_enc\n",
      "AUC:  0.5570279126357371\n",
      "JH_session_end_hod_count_enc\n",
      "AUC:  0.5553562422145798\n",
      "JH_session_start_moh_count_enc\n",
      "AUC:  0.5007076164258828\n",
      "JH_session_end_moh_count_enc\n",
      "AUC:  0.5015577716265436\n",
      "JH_session_start_part_of_day_count_enc\n",
      "AUC:  0.5565311954174339\n",
      "JH_session_end_part_of_day_count_enc\n",
      "AUC:  0.5570475348566806\n",
      "JH_prod_str_count_enc\n",
      "AUC:  0.7289962900779896\n",
      "JH_cat_str_count_enc\n",
      "AUC:  0.6064091621279923\n",
      "JH_sub_cat_str_count_enc\n",
      "AUC:  0.6093364695742391\n",
      "JH_sub_sub_cat_str_count_enc\n",
      "AUC:  0.5004787081449036\n",
      "JH_prod_cat_str_count_enc\n",
      "AUC:  0.6572842920260371\n",
      "JH_prod_cat_sub_cat_str_count_enc\n",
      "AUC:  0.6172889431799718\n",
      "JH_prod_cat_sub_sub_cat_str_count_enc\n",
      "AUC:  0.5010790370365983\n",
      "JH_num_prod_lst\n",
      "AUC:  0.5063219781145066\n",
      "JH_num_cat_lst\n",
      "AUC:  0.5076643813214228\n",
      "JH_num_sub_cat_lst\n",
      "AUC:  0.5026823734699957\n",
      "JH_num_sub_sub_cat_lst\n",
      "AUC:  0.5027070202488626\n",
      "JH_num_prod_cat_lst\n",
      "AUC:  0.5086696366916702\n",
      "JH_num_prod_cat_sub_cat_lst\n",
      "AUC:  0.50415163354196\n",
      "JH_session_equal_part_of_day\n",
      "AUC:  0.5023272694500108\n",
      "JH_session_equal_dow\n",
      "AUC:  0.5014761622278487\n",
      "JH_session_equal_woy\n",
      "AUC:  0.5016807410704615\n",
      "JH_session_equal_month\n",
      "AUC:  0.5013299740373158\n",
      "JH_prod_lst_enc_min\n",
      "AUC:  0.7843814102781088\n",
      "JH_prod_lst_enc_max\n",
      "AUC:  0.7750965561362652\n",
      "JH_prod_lst_enc_mean\n",
      "AUC:  0.7877891712420115\n",
      "JH_prod_lst_enc_std\n",
      "AUC:  0.5067809053682165\n",
      "JH_cat_lst_enc_min\n",
      "AUC:  0.7883849251414916\n",
      "JH_cat_lst_enc_max\n",
      "AUC:  0.7845098274006174\n",
      "JH_cat_lst_enc_mean\n",
      "AUC:  0.7947391662068756\n",
      "JH_cat_lst_enc_std\n",
      "AUC:  0.5105780695711927\n",
      "JH_sub_cat_lst_enc_min\n",
      "AUC:  0.7892894249028515\n",
      "JH_sub_cat_lst_enc_max\n",
      "AUC:  0.790187472074036\n",
      "JH_sub_cat_lst_enc_mean\n",
      "AUC:  0.798982140922877\n",
      "JH_sub_cat_lst_enc_std\n",
      "AUC:  0.5043161745914346\n",
      "JH_sub_sub_cat_lst_enc_min\n",
      "AUC:  0.5181914648522123\n",
      "JH_sub_sub_cat_lst_enc_max\n",
      "AUC:  0.5069496247342803\n",
      "JH_sub_sub_cat_lst_enc_mean\n",
      "AUC:  0.5079311324570787\n",
      "JH_sub_sub_cat_lst_enc_std\n",
      "AUC:  0.5212264829533144\n",
      "JH_prod_lst_count_enc_min\n",
      "AUC:  0.705091373965893\n",
      "JH_prod_lst_count_enc_max\n",
      "AUC:  0.7031467642693214\n",
      "JH_prod_lst_count_enc_mean\n",
      "AUC:  0.7125871681464607\n",
      "JH_prod_lst_count_enc_std\n",
      "AUC:  0.5062026580863437\n",
      "JH_cat_lst_count_enc_min\n",
      "AUC:  0.6269255692665456\n",
      "JH_cat_lst_count_enc_max\n",
      "AUC:  0.6286023700257934\n",
      "JH_cat_lst_count_enc_mean\n",
      "AUC:  0.6335191379593398\n",
      "JH_cat_lst_count_enc_std\n",
      "AUC:  0.5068890920338226\n",
      "JH_sub_cat_lst_count_enc_min\n",
      "AUC:  0.602152383100222\n",
      "JH_sub_cat_lst_count_enc_max\n",
      "AUC:  0.5987220116256635\n",
      "JH_sub_cat_lst_count_enc_mean\n",
      "AUC:  0.6054479377521799\n",
      "JH_sub_cat_lst_count_enc_std\n",
      "AUC:  0.5040696274676397\n",
      "JH_sub_sub_cat_lst_count_enc_min\n",
      "AUC:  0.5183033273786151\n",
      "JH_sub_sub_cat_lst_count_enc_max\n",
      "AUC:  0.5012048625450201\n",
      "JH_sub_sub_cat_lst_count_enc_mean\n",
      "AUC:  0.5107296789952747\n",
      "JH_sub_sub_cat_lst_count_enc_std\n",
      "AUC:  0.5172753557175449\n",
      "JH_prod_cat_lst_enc_min\n",
      "AUC:  0.8126079486602307\n",
      "JH_prod_cat_lst_enc_max\n",
      "AUC:  0.807627765516681\n",
      "JH_prod_cat_lst_enc_mean\n",
      "AUC:  0.8165184298669032\n",
      "JH_prod_cat_lst_enc_std\n",
      "AUC:  0.5103950169925259\n",
      "JH_prod_cat_sub_cat_lst_enc_min\n",
      "AUC:  0.8048067406930378\n",
      "JH_prod_cat_sub_cat_lst_enc_max\n",
      "AUC:  0.8043180098773288\n",
      "JH_prod_cat_sub_cat_lst_enc_mean\n",
      "AUC:  0.8118812124691968\n",
      "JH_prod_cat_sub_cat_lst_enc_std\n",
      "AUC:  0.503978577189057\n",
      "JH_prod_cat_sub_sub_cat_lst_enc_min\n",
      "AUC:  0.513786910931407\n",
      "JH_prod_cat_sub_sub_cat_lst_enc_max\n",
      "AUC:  0.5101051000003385\n",
      "JH_prod_cat_sub_sub_cat_lst_enc_mean\n",
      "AUC:  0.5019940619245559\n",
      "JH_prod_cat_sub_sub_cat_lst_enc_std\n",
      "AUC:  0.5189444080795738\n",
      "JH_prod_cat_lst_count_enc_min\n",
      "AUC:  0.6880178732516654\n",
      "JH_prod_cat_lst_count_enc_max\n",
      "AUC:  0.6987984853972595\n",
      "JH_prod_cat_lst_count_enc_mean\n",
      "AUC:  0.70225948023011\n",
      "JH_prod_cat_lst_count_enc_std\n",
      "AUC:  0.5056506707308817\n",
      "JH_prod_cat_sub_cat_lst_count_enc_min\n",
      "AUC:  0.5920786204743014\n",
      "JH_prod_cat_sub_cat_lst_count_enc_max\n",
      "AUC:  0.5822126365410394\n",
      "JH_prod_cat_sub_cat_lst_count_enc_mean\n",
      "AUC:  0.588103190245207\n",
      "JH_prod_cat_sub_cat_lst_count_enc_std\n",
      "AUC:  0.5044197333747428\n",
      "JH_prod_cat_sub_sub_cat_lst_count_enc_min\n",
      "AUC:  0.5148949317337117\n",
      "JH_prod_cat_sub_sub_cat_lst_count_enc_max\n",
      "AUC:  0.502497734188827\n",
      "JH_prod_cat_sub_sub_cat_lst_count_enc_mean\n",
      "AUC:  0.5081241812615088\n",
      "JH_prod_cat_sub_sub_cat_lst_count_enc_std\n",
      "AUC:  0.5174064966793489\n",
      "JH_ratio_prod_lst_enc_mean_min\n",
      "AUC:  0.5216962791191643\n",
      "JH_ratio_prod_lst_enc_mean_max\n",
      "AUC:  0.5035020375375732\n",
      "JH_ratio_cat_lst_enc_mean_min\n",
      "AUC:  0.5466668775217991\n",
      "JH_ratio_cat_lst_enc_mean_max\n",
      "AUC:  0.5590141732729907\n",
      "JH_ratio_sub_cat_lst_enc_mean_min\n",
      "AUC:  0.5750305863352334\n",
      "JH_ratio_sub_cat_lst_enc_mean_max\n",
      "AUC:  0.5934587078656439\n",
      "JH_ratio_sub_sub_cat_lst_enc_mean_min\n",
      "AUC:  0.5207839780705021\n",
      "JH_ratio_sub_sub_cat_lst_enc_mean_max\n",
      "AUC:  0.5150796767950471\n",
      "JH_ratio_prod_cat_lst_enc_mean_min\n",
      "AUC:  0.568079374898451\n",
      "JH_ratio_prod_cat_lst_enc_mean_max\n",
      "AUC:  0.5516149563847216\n",
      "JH_ratio_prod_cat_sub_cat_lst_enc_mean_min\n",
      "AUC:  0.5797804331655518\n",
      "JH_ratio_prod_cat_sub_cat_lst_enc_mean_max\n",
      "AUC:  0.6041151076503603\n",
      "JH_prod_cat_lst_enc_mi\n",
      "AUC:  0.7338598241425882\n",
      "JH_prod_cat_sub_cat_lst_enc_mi\n",
      "AUC:  0.7313787503300341\n",
      "JH_prod_cat_sub_sub_cat_lst_enc_mi\n",
      "AUC:  0.7124609988524967\n",
      "JH_session_start_part_of_day_meanenc_prod_str_enc\n",
      "AUC:  0.5547535597141735\n",
      "JH_session_start_part_of_day_meanenc_cat_str_enc\n",
      "AUC:  0.5301028669810172\n",
      "JH_session_start_part_of_day_meanenc_sub_cat_str_enc\n",
      "AUC:  0.5576470703971241\n",
      "JH_session_start_part_of_day_meanenc_sub_sub_cat_str_enc\n",
      "AUC:  0.5264239385594941\n",
      "JH_session_start_part_of_day_meanenc_prod_cat_lst_enc_mean\n",
      "AUC:  0.5576470703971241\n",
      "JH_session_start_part_of_day_meanenc_prod_cat_sub_cat_lst_enc_mean\n",
      "AUC:  0.5613259988186471\n",
      "JH_session_end_part_of_day_meanenc_prod_str_enc\n",
      "AUC:  0.5028512515063096\n",
      "JH_session_end_part_of_day_meanenc_cat_str_enc\n",
      "AUC:  0.5284176831435496\n",
      "JH_session_end_part_of_day_meanenc_sub_cat_str_enc\n",
      "AUC:  0.5603302901084543\n",
      "JH_session_end_part_of_day_meanenc_sub_sub_cat_str_enc\n",
      "AUC:  0.526528766704804\n",
      "JH_session_end_part_of_day_meanenc_prod_cat_lst_enc_mean\n",
      "AUC:  0.5584413736697086\n",
      "JH_session_end_part_of_day_meanenc_prod_cat_sub_cat_lst_enc_mean\n",
      "AUC:  0.5603302901084544\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "def get_auc(actual, pred):\n",
    "    auc = roc_auc_score(actual, pred)\n",
    "    return max(auc, 1-auc)\n",
    "\n",
    "selected_feat_cols = []\n",
    "for col in feat_cols:\n",
    "    print(col)\n",
    "    auc = get_auc(train_final[DV_COL], train_final[col])\n",
    "    print('AUC: ', auc)\n",
    "    if auc >= 0.6:\n",
    "        selected_feat_cols.append(col)\n",
    "        \n",
    "print(len(selected_feat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JH_prod_str_enc',\n",
       " 'JH_cat_str_enc',\n",
       " 'JH_sub_cat_str_enc',\n",
       " 'JH_prod_cat_str_enc',\n",
       " 'JH_prod_cat_sub_cat_str_enc',\n",
       " 'JH_prod_str_count_enc',\n",
       " 'JH_cat_str_count_enc',\n",
       " 'JH_sub_cat_str_count_enc',\n",
       " 'JH_prod_cat_str_count_enc',\n",
       " 'JH_prod_cat_sub_cat_str_count_enc',\n",
       " 'JH_prod_lst_enc_min',\n",
       " 'JH_prod_lst_enc_max',\n",
       " 'JH_prod_lst_enc_mean',\n",
       " 'JH_cat_lst_enc_min',\n",
       " 'JH_cat_lst_enc_max',\n",
       " 'JH_cat_lst_enc_mean',\n",
       " 'JH_sub_cat_lst_enc_min',\n",
       " 'JH_sub_cat_lst_enc_max',\n",
       " 'JH_sub_cat_lst_enc_mean',\n",
       " 'JH_prod_lst_count_enc_min',\n",
       " 'JH_prod_lst_count_enc_max',\n",
       " 'JH_prod_lst_count_enc_mean',\n",
       " 'JH_cat_lst_count_enc_min',\n",
       " 'JH_cat_lst_count_enc_max',\n",
       " 'JH_cat_lst_count_enc_mean',\n",
       " 'JH_sub_cat_lst_count_enc_min',\n",
       " 'JH_sub_cat_lst_count_enc_mean',\n",
       " 'JH_prod_cat_lst_enc_min',\n",
       " 'JH_prod_cat_lst_enc_max',\n",
       " 'JH_prod_cat_lst_enc_mean',\n",
       " 'JH_prod_cat_sub_cat_lst_enc_min',\n",
       " 'JH_prod_cat_sub_cat_lst_enc_max',\n",
       " 'JH_prod_cat_sub_cat_lst_enc_mean',\n",
       " 'JH_prod_cat_lst_count_enc_min',\n",
       " 'JH_prod_cat_lst_count_enc_max',\n",
       " 'JH_prod_cat_lst_count_enc_mean',\n",
       " 'JH_ratio_prod_cat_sub_cat_lst_enc_mean_max',\n",
       " 'JH_prod_cat_lst_enc_mi',\n",
       " 'JH_prod_cat_sub_cat_lst_enc_mi',\n",
       " 'JH_prod_cat_sub_sub_cat_lst_enc_mi']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import operator, joblib, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_feature_map(features, fmap_fn):\n",
    "    outfile = open(fmap_fn, 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "\n",
    "def runXGB(fmap_fn, imp_fn, train_X, train_y, test_X, test_y=None,\n",
    "           test_X2=None, feature_names=None, seed_val=0, rounds=500, dep=8,\n",
    "           eta=0.05):\n",
    "    # define hyperparameters\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"binary:logistic\"\n",
    "    params['eval_metric'] = 'auc'\n",
    "    params[\"eta\"] = eta\n",
    "    params[\"subsample\"] = 0.7\n",
    "    params[\"min_child_weight\"] = 1\n",
    "    params[\"colsample_bytree\"] = 0.7\n",
    "    params[\"max_depth\"] = dep\n",
    "\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"seed\"] = seed_val\n",
    "    # params[\"max_delta_step\"] = 2\n",
    "    # params[\"gamma\"] = 0.5\n",
    "    num_rounds = rounds\n",
    "\n",
    "    plst = list(params.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [(xgtrain, 'train'), (xgtest, 'test')]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist,\n",
    "                          early_stopping_rounds=100, verbose_eval=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    if feature_names is not None:\n",
    "        create_feature_map(feature_names, fmap_fn)\n",
    "        importance = model.get_fscore()\n",
    "        importance = sorted(importance.items(), key=operator.itemgetter(1),\n",
    "                            reverse=True)\n",
    "        imp_df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "        imp_df['fscore'] = imp_df['fscore'] / imp_df['fscore'].sum()\n",
    "        imp_df.to_csv(imp_fn, index=False, encoding='utf-8')\n",
    "\n",
    "    pred_test_y = model.predict(xgtest, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "    if test_X2 is not None:\n",
    "        pred_test_y2 = model.predict(xgb.DMatrix(test_X2),\n",
    "                                     ntree_limit=model.best_ntree_limit)\n",
    "    else:\n",
    "        pred_test_y2 = None\n",
    "\n",
    "    loss = 0\n",
    "    if test_y is not None:\n",
    "        loss = metrics.roc_auc_score(test_y, pred_test_y)\n",
    "\n",
    "    return pred_test_y, loss, pred_test_y2, model\n",
    "\n",
    "\n",
    "def runLGB(train_X, train_y, test_X, test_y=None, test_X2=None,\n",
    "           feature_names=None, seed_val=0, rounds=500, dep=8, eta=0.05):\n",
    "    params = {}\n",
    "    params['boosting_type'] = 'gbdt'\n",
    "    params[\"objective\"] = \"binary\"\n",
    "    params['metric'] = 'binary_error'\n",
    "    params[\"max_depth\"] = dep\n",
    "    params[\"min_data_in_leaf\"] = 10\n",
    "    params[\"learning_rate\"] = eta\n",
    "    params[\"bagging_fraction\"] = 0.8\n",
    "    params[\"feature_fraction\"] = 0.8\n",
    "    params[\"bagging_freq\"] = 5\n",
    "    params[\"bagging_seed\"] = seed_val\n",
    "    params[\"verbosity\"] = 0\n",
    "    num_rounds = rounds\n",
    "\n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        lgtest = lgb.Dataset(test_X, label=test_y)\n",
    "        model = lgb.train(params, lgtrain, num_rounds, valid_sets=[lgtest],\n",
    "                          early_stopping_rounds=100, verbose_eval=20)\n",
    "    else:\n",
    "        lgtest = lgb.DMatrix(test_X)\n",
    "        model = lgb.train(params, lgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    pred_test_y2 = model.predict(test_X2, num_iteration=model.best_iteration)\n",
    "    pred_class_y = np.where(pred_test_y > 0.5, 1, 0)\n",
    "    loss = 0\n",
    "    if test_y is not None:\n",
    "        loss = get_accuracy(test_y, pred_class_y)\n",
    "\n",
    "    return pred_test_y, pred_class_y, loss, pred_test_y2, model\n",
    "\n",
    "\n",
    "def runRF(train_X, train_y, test_X, test_y=None, test_X2=None,\n",
    "          dep=20, num_trees=1000, leaf=10, feat=0.2):\n",
    "    model = ensemble.RandomForestClassifier(\n",
    "            n_estimators = num_trees,\n",
    "                    max_depth = dep,\n",
    "                    min_samples_split = 2,\n",
    "                    min_samples_leaf = leaf,\n",
    "                    max_features =  feat,\n",
    "                    n_jobs = 4,\n",
    "                    random_state = 0)\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_train_class_y = model.predict(train_X)\n",
    "    pred_test_class_y = model.predict(test_X)\n",
    "    pred_test_y = model.predict_proba(test_X)[:,1]\n",
    "    pred_test_class_y2 = model.predict(test_X2)\n",
    "    pred_test_y2 = model.predict_proba(test_X2)[:,1]\n",
    "    test_loss = 0\n",
    "    \n",
    "    train_loss = get_accuracy(train_y, pred_train_class_y)\n",
    "    test_loss = get_accuracy(test_y, pred_test_class_y)\n",
    "    print(\"Train and Test accuracy: \", train_loss, test_loss)\n",
    "    return pred_test_y, pred_test_class_y, test_loss, pred_test_y2, pred_test_class_y2, model\n",
    "\n",
    "\n",
    "def xgb_predict(data, model):\n",
    "    xgtest = xgb.DMatrix(data)\n",
    "    probs = list(model.predict(xgtest, ntree_limit=model.best_ntree_limit))\n",
    "    return probs\n",
    "\n",
    "\n",
    "def xgb_persist(model, model_fn):\n",
    "    joblib.dump(model, model_fn)\n",
    "\n",
    "\n",
    "def xgb_load(model_fn):\n",
    "    return joblib.load(model_fn)\n",
    "\n",
    "\n",
    "def get_auc(actual, pred):\n",
    "    return roc_auc_score(actual, pred)\n",
    "\n",
    "\n",
    "def get_accuracy(actual, pred):\n",
    "    return 100.*(actual==pred).mean()\n",
    "\n",
    "\n",
    "def get_prec_rec_f_score(actual, pred, pos_class=1):\n",
    "\n",
    "    if pos_class == 1:\n",
    "        tn, fp, fn, tp = confusion_matrix(actual, pred, labels=[0,1]).ravel()\n",
    "    elif pos_class == 0:\n",
    "        tp, fn, fp, tn = confusion_matrix(actual, pred, labels=[0,1]).ravel()\n",
    "    prec = 100.*(tp/float(tp+fp+0.000000001))\n",
    "    rec = 100.*(tp/float(tp+fn+0.000000001))\n",
    "    f_score = 2.*prec*rec/(prec+rec+0.000000001)\n",
    "    return prec, rec, f_score\n",
    "\n",
    "\n",
    "def calc_metrics(data, dv_col, score_col, pred_class_col, id_col='deal_id'):\n",
    "\n",
    "    df = data.copy()\n",
    "\n",
    "    assert df.shape[0] == df[id_col].nunique()\n",
    "\n",
    "    feats = ['num_deals', 'dv_rate', 'auc', 'accuracy',\n",
    "             'prec_win', 'rec_win', 'f_score_win', 'prec_lost',\n",
    "             'rec_lost', 'f_score_lost']\n",
    "    actual = df[dv_col]\n",
    "    pred = df[pred_class_col]\n",
    "    score = df[score_col]\n",
    "    prec_good, rec_good, f_score_good = get_prec_rec_f_score(actual, pred, 1)\n",
    "    prec_bad, rec_bad, f_score_bad = get_prec_rec_f_score(actual, pred, 0)\n",
    "    feat_values = [df.shape[0], round(df[dv_col].mean(), 4),\n",
    "                   get_auc(actual, score),\n",
    "                   get_accuracy(actual, pred),\n",
    "                   prec_good, rec_good, f_score_good,\n",
    "                   prec_bad, rec_bad, f_score_bad]\n",
    "    return dict(zip(feats, feat_values))\n",
    "\n",
    "\n",
    "def find_optimal_threshold(data, dv_col, score_col, prob_thresholds,\n",
    "                           id_col='deal_id'):\n",
    "\n",
    "    df = data[[id_col, dv_col, score_col]]\n",
    "\n",
    "    accs = []\n",
    "    max_acc = 0\n",
    "    for prob_threshold in prob_thresholds:\n",
    "        print(prob_threshold)\n",
    "        df['pred_class'] = df[score_col].apply(\n",
    "            lambda x: 1 if x >= prob_threshold else 0)\n",
    "        acc = get_accuracy(df[dv_col], df['pred_class'])\n",
    "        accs.append(acc)\n",
    "        if acc > max_acc:\n",
    "            max_acc = acc\n",
    "\n",
    "    max_idx = np.argmax(accs)\n",
    "    return prob_thresholds[max_idx], max_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'lgb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model building..\n",
      "Iteration:  1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's binary_error: 0.120476\n",
      "[40]\tvalid_0's binary_error: 0.111905\n",
      "[60]\tvalid_0's binary_error: 0.110952\n",
      "[80]\tvalid_0's binary_error: 0.11\n",
      "[100]\tvalid_0's binary_error: 0.110952\n",
      "[120]\tvalid_0's binary_error: 0.112857\n",
      "[140]\tvalid_0's binary_error: 0.112381\n",
      "[160]\tvalid_0's binary_error: 0.112857\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's binary_error: 0.109524\n",
      "[89.04761904761904]\n",
      "mean cv score:  89.04761904761904\n",
      "Iteration:  2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's binary_error: 0.130476\n",
      "[40]\tvalid_0's binary_error: 0.127143\n",
      "[60]\tvalid_0's binary_error: 0.128571\n",
      "[80]\tvalid_0's binary_error: 0.129048\n",
      "[100]\tvalid_0's binary_error: 0.128571\n",
      "[120]\tvalid_0's binary_error: 0.127619\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's binary_error: 0.12619\n",
      "[89.04761904761904, 87.38095238095238]\n",
      "mean cv score:  88.21428571428571\n",
      "Iteration:  3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's binary_error: 0.134286\n",
      "[40]\tvalid_0's binary_error: 0.127143\n",
      "[60]\tvalid_0's binary_error: 0.126667\n",
      "[80]\tvalid_0's binary_error: 0.124762\n",
      "[100]\tvalid_0's binary_error: 0.12619\n",
      "[120]\tvalid_0's binary_error: 0.127143\n",
      "[140]\tvalid_0's binary_error: 0.127619\n",
      "[160]\tvalid_0's binary_error: 0.127619\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's binary_error: 0.124762\n",
      "[89.04761904761904, 87.38095238095238, 87.52380952380953]\n",
      "mean cv score:  87.98412698412699\n",
      "Iteration:  4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's binary_error: 0.138095\n",
      "[40]\tvalid_0's binary_error: 0.13619\n",
      "[60]\tvalid_0's binary_error: 0.135714\n",
      "[80]\tvalid_0's binary_error: 0.135238\n",
      "[100]\tvalid_0's binary_error: 0.134762\n",
      "[120]\tvalid_0's binary_error: 0.135238\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's binary_error: 0.133333\n",
      "[89.04761904761904, 87.38095238095238, 87.52380952380953, 86.66666666666667]\n",
      "mean cv score:  87.65476190476191\n",
      "Iteration:  5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's binary_error: 0.142857\n",
      "[40]\tvalid_0's binary_error: 0.130476\n",
      "[60]\tvalid_0's binary_error: 0.131429\n",
      "[80]\tvalid_0's binary_error: 0.131429\n",
      "[100]\tvalid_0's binary_error: 0.129524\n",
      "[120]\tvalid_0's binary_error: 0.129524\n",
      "[140]\tvalid_0's binary_error: 0.129048\n",
      "[160]\tvalid_0's binary_error: 0.130952\n",
      "[180]\tvalid_0's binary_error: 0.129524\n",
      "[200]\tvalid_0's binary_error: 0.127619\n",
      "[220]\tvalid_0's binary_error: 0.128095\n",
      "[240]\tvalid_0's binary_error: 0.128095\n",
      "[260]\tvalid_0's binary_error: 0.127143\n",
      "[280]\tvalid_0's binary_error: 0.126667\n",
      "[300]\tvalid_0's binary_error: 0.12619\n",
      "[320]\tvalid_0's binary_error: 0.125714\n",
      "[340]\tvalid_0's binary_error: 0.126667\n",
      "[360]\tvalid_0's binary_error: 0.12619\n",
      "[380]\tvalid_0's binary_error: 0.126667\n",
      "[400]\tvalid_0's binary_error: 0.125714\n",
      "Early stopping, best iteration is:\n",
      "[316]\tvalid_0's binary_error: 0.125714\n",
      "[89.04761904761904, 87.38095238095238, 87.52380952380953, 86.66666666666667, 87.42857142857143]\n",
      "mean cv score:  87.60952380952382\n",
      "87.60952380952382\n"
     ]
    }
   ],
   "source": [
    "print(\"Model building..\")\n",
    "feat_cols = [x for x in list(train_final.columns)\n",
    "             if (x.startswith(FEAT_PREFIX))]\n",
    "if 'JH_session_duration_sec_bins' in feat_cols:\n",
    "    feat_cols.remove('JH_session_duration_sec_bins')\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2020)\n",
    "cv_scores = []\n",
    "models = []\n",
    "pred_test_full = 0\n",
    "pred_val_full = np.zeros(train_final.shape[0])\n",
    "pred_class_val_full = np.zeros(train_final.shape[0])\n",
    "count = 0\n",
    "for dev_index, val_index in kf.split(train_final):\n",
    "    print('Iteration: ', count+1)\n",
    "    dev_X, val_X = (train_final.loc[dev_index, feat_cols],\n",
    "                    train_final.loc[val_index, feat_cols])\n",
    "    dev_y, val_y = (train_final.loc[dev_index, DV_COL],\n",
    "                    train_final.loc[val_index, DV_COL])\n",
    "\n",
    "    if MODEL_NAME == 'xgb':\n",
    "        pred_val, loss, pred_test, model = runXGB(\n",
    "            fmap_fn=os.path.join(DATA_DIR, 'xgb_feat_map_fname'),\n",
    "            imp_fn=os.path.join(DATA_DIR, 'xgb_feat_imp_fname'),\n",
    "            train_X=dev_X, train_y=dev_y, test_X=val_X, test_y=val_y,\n",
    "            test_X2=test_final[feat_cols], rounds=5000, dep=8,\n",
    "            feature_names=feat_cols)\n",
    "    elif MODEL_NAME == 'lgb':\n",
    "        pred_val, pred_class, loss, pred_test, model = runLGB(\n",
    "            train_X=dev_X, train_y=dev_y, test_X=val_X, test_y=val_y,\n",
    "            test_X2=test_final[feat_cols], rounds=5000, dep=8,\n",
    "            feature_names=feat_cols)\n",
    "    elif MODEL_NAME == 'rf':\n",
    "        pred_val, pred_class, loss, pred_test, pred_test_class, model = runRF(\n",
    "            train_X=dev_X, train_y=dev_y, test_X=val_X, test_y=val_y,\n",
    "            test_X2=test_final[feat_cols], num_trees=1000, dep=20,\n",
    "            feat=0.7)\n",
    "    pred_val_full[val_index] = pred_val\n",
    "    pred_class_val_full[val_index] = pred_class\n",
    "    pred_test_full = pred_test_full + pred_test\n",
    "    cv_scores.append(loss)\n",
    "    models.append(model)\n",
    "    print(cv_scores)\n",
    "    print('mean cv score: ', np.mean(cv_scores))\n",
    "    count += 1\n",
    "\n",
    "pred_test_full /= 5.\n",
    "print(get_accuracy(train_final[DV_COL], pred_class_val_full))\n",
    "train_final['pred_prob'] = pred_val_full\n",
    "train_final['pred_class'] = pred_class_val_full\n",
    "\n",
    "test_final['pred_prob'] = pred_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
